{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device= torch.device(\"cuda\")\n",
    "#device= torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 3, 32, 32])\n",
      "torch.Size([10000, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "from utils import check_cifar_dataset_exists\n",
    "data_path=check_cifar_dataset_exists()\n",
    "\n",
    "train_data=torch.load(data_path+'cifar/train_data.pt')\n",
    "train_label=torch.load(data_path+'cifar/train_label.pt')\n",
    "test_data=torch.load(data_path+'cifar/test_data.pt')\n",
    "test_label=torch.load(data_path+'cifar/test_label.pt')\n",
    "\n",
    "print(train_data.size())\n",
    "print(test_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stem(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Stem, self).__init__()\n",
    "        \n",
    "        #----------------------- stem block start ----------------------------\n",
    "        \n",
    "        #3 x 32 x 32 --> 16 x 30 x 30  , VALID Padding \n",
    "        #self.conv1a = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=0 ) \n",
    "        \n",
    "        #3 x 32 x 32 --> 16 x 30 x 30  , VALID Padding \n",
    "        self.conv1a = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=0 )\n",
    "        self.bn1a = nn.BatchNorm2d(16,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #16 x 30 x 30 --> 32 x 30 x 30  , SAME Padding \n",
    "        self.conv1b = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1 )\n",
    "        self.bn1b = nn.BatchNorm2d(32,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #======================== Filter concat 1 =============================\n",
    "        \n",
    "        #32 x 30 x 30 --> 32 x 28 x 28, kernel size = 3, VALID Padding  \n",
    "        self.pool1  = nn.MaxPool2d(kernel_size=3, stride=1, padding=0 )\n",
    "        \n",
    "        #32 x 30 x 30 --> 48 x 28 x 28  , VALID Padding\n",
    "        self.conv2a = nn.Conv2d(32, 48, kernel_size=3, stride=1, padding=0 )\n",
    "        self.bn2a = nn.BatchNorm2d(48,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #======================== Filter concat 1 =============================\n",
    "        \n",
    "        #======================== Filter concat 2 =============================       \n",
    "        \n",
    "        #80 x 28 x 28 --> 32 x 28 x 28  , SAME Padding   \n",
    "        self.conv3a = nn.Conv2d(80, 32, stride=1, kernel_size=1, padding=0 )\n",
    "        self.bn3a = nn.BatchNorm2d(32,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #32 x 28 x 28 --> 48 x 26 x 26  , VALID Padding   \n",
    "        self.conv3b = nn.Conv2d(32, 48, stride=1, kernel_size=3, padding=0 )\n",
    "        self.bn3b = nn.BatchNorm2d(48,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #80 x 28 x 28 --> 32 x 28 x 28  , SAME Padding   Might be combined with self.conv1e1\n",
    "        self.conv4a = nn.Conv2d(80, 32, stride=1, kernel_size=1, padding=0 )\n",
    "        self.bn4a = nn.BatchNorm2d(32,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #32 x 28 x 28 --> 32 x 28 x 28  , SAME Padding   Find out the size of output\n",
    "        self.conv4b = nn.Conv2d(32, 32, stride=1, kernel_size=[7,1], padding=[3,0] )\n",
    "        self.bn4b = nn.BatchNorm2d(32,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #32 x 28 x 28 --> 32 x 28 x 28  , SAME Padding   Find out the size of output\n",
    "        self.conv4c = nn.Conv2d(32, 32, stride=1, kernel_size=[1,7], padding=[0,3] )\n",
    "        self.bn4c = nn.BatchNorm2d(32,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #32 x 28 x 28 --> 48 x 26 x 26  , VALID Padding   Might be combined with self.conv1e2\n",
    "        self.conv4d = nn.Conv2d(32, 48, stride=1, kernel_size=3, padding=0 )\n",
    "        self.bn4d = nn.BatchNorm2d(48,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #======================== Filter concat 2 ============================= \n",
    "        \n",
    "        #======================== Filter concat 3 =============================\n",
    "        \n",
    "        #96 x 26 x 26 --> 192 x 26 x 26  , SAME Padding \n",
    "        self.conv5a = nn.Conv2d(96, 192, kernel_size=3, stride=1, padding=1 )\n",
    "        self.bn5a = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "         \n",
    "        #192 x 71 x 71 --> 192 x 35 x 35, kernel size = 3, VALID Padding\n",
    "        #self.pool2  = nn.MaxPool2d(3, stride=2, padding=0 )\n",
    "        \n",
    "        #======================== Filter concat 3 =============================\n",
    "        \n",
    "        #----------------------- stem block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1: \n",
    "        x = self.conv1a(x)\n",
    "        x = self.bn1a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv1b(x)\n",
    "        x = self.bn1b(x)\n",
    "        x = F.relu(x)\n",
    "        #x = self.conv1c(x)\n",
    "        #x = F.relu(x)\n",
    "        \n",
    "        xP = self.pool1(x)\n",
    "        xC = self.conv2a(x)\n",
    "        x = self.bn2a(xC)\n",
    "        xC = F.relu(xC)\n",
    "        xFC1 = torch.cat((xP, xC), 1)\n",
    "       \n",
    "        y = self.conv3a(xFC1)\n",
    "        y = self.bn3a(y)\n",
    "        y = F.relu(y)\n",
    "        y = self.conv3b(y)\n",
    "        y = self.bn3b(y)\n",
    "        y = F.relu(y)\n",
    "       \n",
    "        z = self.conv4a(xFC1)\n",
    "        z = self.bn4a(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.conv4b(z)\n",
    "        z = self.bn4b(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.conv4c(z)\n",
    "        z = self.bn4c(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.conv4d(z)\n",
    "        z = self.bn4d(z)\n",
    "        z = F.relu(z)\n",
    "        \n",
    "        # Above code or this one?\n",
    "        #z = self.conv3a(xFC1)\n",
    "        #z = F.relu(z)\n",
    "        #z = self.conv4b(z)\n",
    "        #z = F.relu(z)\n",
    "        #z = self.conv4c(xFC1)\n",
    "        #z = F.relu(z)\n",
    "        #z = self.conv3b(z)\n",
    "        #z = F.relu(z)\n",
    "        \n",
    "        xFC2 = torch.cat((y, z), 1)\n",
    "        \n",
    "        #xP = self.pool2(xFC2)\n",
    "        xC = self.conv5a(xFC2)\n",
    "        xC = self.bn5a(xC)\n",
    "        xC = F.relu(xC)\n",
    "        #xFC3 = torch.cat((xP, xC), 1)   \n",
    "        \n",
    "        return xC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionA(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(InceptionA, self).__init__()\n",
    "        \n",
    "        #----------------------- InceptionA block start ----------------------------\n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #block 1\n",
    "        #192 x 26 x 26 --> 192 x 26 x 26  , kernel size = 3, SAME Padding\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=3, stride=1, padding=1 )\n",
    "        \n",
    "        #192 x 26 x 26 --> 48 x 26 x 26  , SAME Padding \n",
    "        self.conv1a = nn.Conv2d(192, 48, kernel_size=1, padding=0 ) \n",
    "        self.bn1a = nn.BatchNorm2d(48,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 2\n",
    "        #192 x 26 x 26 --> 48 x 26 x 26  , SAME Padding \n",
    "        self.conv2a = nn.Conv2d(192, 48, kernel_size=1, padding=0 ) \n",
    "        self.bn2a = nn.BatchNorm2d(48,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 3\n",
    "        #192 x 26 x 26 --> 32 x 26 x 26  , SAME Padding \n",
    "        self.conv3a = nn.Conv2d(192, 32, kernel_size=1, padding=0 )\n",
    "        self.bn3a = nn.BatchNorm2d(32,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #32 x 26 x 26 --> 48 x 26 x 26  , SAME Padding \n",
    "        self.conv3b = nn.Conv2d(32, 48, kernel_size=3, padding=1 )\n",
    "        self.bn3b = nn.BatchNorm2d(48,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 4\n",
    "        #192 x 26 x 26 --> 32 x 26 x 26  , SAME Padding \n",
    "        self.conv4a = nn.Conv2d(192, 32, kernel_size=1, padding=0 )\n",
    "        self.bn4a = nn.BatchNorm2d(32,affine=True, eps=0.001,momentum=0.1)\n",
    "\n",
    "        #32 x 26 x 26 --> 48 x 26 x 26  , SAME Padding \n",
    "        self.conv4b = nn.Conv2d(32, 48, kernel_size=3, padding=1 )\n",
    "        self.bn4b = nn.BatchNorm2d(48,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #48 x 26 x 26 --> 48 x 26 x 26  , SAME Padding \n",
    "        self.conv4c = nn.Conv2d(48, 48, kernel_size=3, padding=1 )\n",
    "        self.bn4c = nn.BatchNorm2d(48,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #----------------------- InceptionA block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1:\n",
    "        y = self.pool1(x)\n",
    "        y = self.conv1a(y)\n",
    "        y = self.bn1a(y)\n",
    "        y = F.relu(y)   # Do we need Relu here (after last operation)?\n",
    "        \n",
    "        # block 2:\n",
    "        z = self.conv2a(x)\n",
    "        z = self.bn2a(z)\n",
    "        z = F.relu(z) \n",
    "        \n",
    "        #block 3:\n",
    "        w = self.conv3a(x)\n",
    "        w = self.bn3a(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv3b(w)\n",
    "        w = self.bn3b(w)\n",
    "        w = F.relu(w)\n",
    "        \n",
    "        #block 4:\n",
    "        v = self.conv4a(x)\n",
    "        v = self.bn4a(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4b(v)\n",
    "        v = self.bn4b(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4c(v)\n",
    "        v = self.bn4c(v)\n",
    "        v = F.relu(v)\n",
    "        \n",
    "        xFC = torch.cat((y, z, w, v), 1)\n",
    "        #print('InceptionA Done')\n",
    "        \n",
    "        return xFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionB(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(InceptionB, self).__init__()\n",
    "        \n",
    "        #----------------------- InceptionB block start ----------------------------\n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #block 1\n",
    "        #512 x 12 x 12 --> 512 12 x 12  , kernel size = 1, SAME Padding\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=3, stride=1, padding=1 )\n",
    "        \n",
    "        #512 x 12 x 12 --> 64 x 12 x 12  , SAME Padding \n",
    "        self.conv1a = nn.Conv2d(512, 64, kernel_size=1, padding=0 ) \n",
    "        self.bn1a = nn.BatchNorm2d(64,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 2\n",
    "        #512 x 12 x 12 --> 192 x 12 x 12  , SAME Padding \n",
    "        self.conv2a = nn.Conv2d(512, 192, kernel_size=1, padding=0 ) \n",
    "        self.bn2a = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 3\n",
    "        #512 x 12 x 12 --> 96 x 12 x 12  , SAME Padding \n",
    "        self.conv3a = nn.Conv2d(512, 96, kernel_size=1, padding=0 )\n",
    "        self.bn3a = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #96 x 12 x 12 --> 112 x 12 x 12  , SAME Padding \n",
    "        self.conv3b = nn.Conv2d(96, 112, kernel_size=[7,1], padding=[3,0] )\n",
    "        self.bn3b = nn.BatchNorm2d(112,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #112 x 12 x 12 --> 128 x 12 x 12  , SAME Padding \n",
    "        self.conv3c = nn.Conv2d(112, 128, kernel_size=[1,7], padding=[0,3] )\n",
    "        self.bn3c = nn.BatchNorm2d(128,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 4\n",
    "        #512 x 12 x 12 --> 96 x 12 x 12  , SAME Padding \n",
    "        self.conv4a = nn.Conv2d(512, 96, kernel_size=1, padding=0 )\n",
    "        self.bn4a = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #96 x 12 x 12 --> 96 x 12 x 12  , SAME Padding \n",
    "        self.conv4b = nn.Conv2d(96, 96, kernel_size=[1,7], padding=[0,3] )\n",
    "        self.bn4b = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #96 x 12 x 12 --> 112 x 12 x 12  , SAME Padding \n",
    "        self.conv4c = nn.Conv2d(96, 112, kernel_size=[7,1], padding=[3,0] )\n",
    "        self.bn4c = nn.BatchNorm2d(112,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #112 x 12 x 12 --> 112 x 12 x 12  , SAME Padding \n",
    "        self.conv4d = nn.Conv2d(112, 112, kernel_size=[1,7], padding=[0,3] )\n",
    "        self.bn4d = nn.BatchNorm2d(112,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #112 x 12 x 12 --> 128 x 12 x 12  , SAME Padding \n",
    "        self.conv4e = nn.Conv2d(112, 128, kernel_size=[7,1], padding=[3,0] )\n",
    "        self.bn4e = nn.BatchNorm2d(128,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #----------------------- InceptionB block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # block 1:\n",
    "        y = self.pool1(x)\n",
    "        y = self.conv1a(y)\n",
    "        y = self.bn1a(y)\n",
    "        y = F.relu(y)\n",
    "        \n",
    "        # block 2:\n",
    "        z = self.conv2a(x)\n",
    "        z = self.bn2a(z)\n",
    "        z = F.relu(z) \n",
    "        \n",
    "        #block 3:\n",
    "        w = self.conv3a(x)\n",
    "        w = self.bn3a(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv3b(w)\n",
    "        w = self.bn3b(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv3c(w)\n",
    "        w = self.bn3c(w)\n",
    "        w = F.relu(w)\n",
    "        \n",
    "        #block 4:\n",
    "        v = self.conv4a(x)\n",
    "        v = self.bn4a(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4b(v)\n",
    "        v = self.bn4b(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4c(v)\n",
    "        v = self.bn4c(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4d(v)\n",
    "        v = self.bn4d(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4e(v)\n",
    "        v = self.bn4e(v)\n",
    "        v = F.relu(v)\n",
    "        \n",
    "        xFC = torch.cat((y, z, w, v), 1)\n",
    "        #print('InceptionB Done')\n",
    "        \n",
    "        return xFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionC(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(InceptionC, self).__init__()\n",
    "        \n",
    "        #----------------------- InceptionC block start ----------------------------\n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #block 1\n",
    "        #768 x 5 x 5 --> 768 x 5 x 5  , kernel size = 3, SAME Padding\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=3, stride=1, padding=1 )\n",
    "        \n",
    "        #768 x 5 x 5 --> 128 x 5 x 5  , SAME Padding \n",
    "        self.conv1a = nn.Conv2d(768, 128, kernel_size=1, padding=0 ) \n",
    "        self.bn1a = nn.BatchNorm2d(128,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 2\n",
    "        #768 x 5 x 5 --> 128 x 5 x 5  , SAME Padding \n",
    "        self.conv2a = nn.Conv2d(768, 128, kernel_size=1, padding=0 ) \n",
    "        self.bn2a = nn.BatchNorm2d(128,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 3\n",
    "        #768 x 5 x 5 --> 192 x 5 x 5  , SAME Padding \n",
    "        self.conv3a = nn.Conv2d(768, 192, kernel_size=1, padding=0 )\n",
    "        self.bn3a = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #192 x 5 x 5 --> 128 x 5 x 5  , SAME Padding \n",
    "        self.conv3b = nn.Conv2d(192, 128, kernel_size=[1,3], padding=[0,1] )\n",
    "        self.bn3b = nn.BatchNorm2d(128,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #192 x 5 x 5 --> 128 x 5 x 5  , SAME Padding \n",
    "        self.conv3c = nn.Conv2d(192, 128, kernel_size=[3,1], padding=[1,0] )\n",
    "        self.bn3c = nn.BatchNorm2d(128,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 4\n",
    "        #768 x 5 x 5--> 192 x 5 x 5  , SAME Padding \n",
    "        self.conv4a = nn.Conv2d(768, 192, kernel_size=1, padding=0 )\n",
    "        self.bn4a = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #192 x 5 x 5 --> 224 x 5 x 5  , SAME Padding \n",
    "        self.conv4b = nn.Conv2d(192, 224, kernel_size=[1,3], padding=[0,1] )\n",
    "        self.bn4b = nn.BatchNorm2d(224,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #224 x 5 x 5 --> 256 x 5 x 5  , SAME Padding \n",
    "        self.conv4c = nn.Conv2d(224, 256, kernel_size=[3,1], padding=[1,0] )\n",
    "        self.bn4c = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #256 x 5 x 5 --> 128 x 5 x 5  , SAME Padding \n",
    "        self.conv4d = nn.Conv2d(256, 128, kernel_size=[3,1], padding=[1,0])\n",
    "        self.bn4d = nn.BatchNorm2d(128,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #256 x 5 x 5 --> 128 x 5 x 5  , SAME Padding \n",
    "        self.conv4e = nn.Conv2d(256, 128, kernel_size=[1,3], padding=[0,1] )\n",
    "        self.bn4e = nn.BatchNorm2d(128,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #----------------------- InceptionC block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # block 1:\n",
    "        y = self.pool1(x)\n",
    "        y = self.conv1a(y)\n",
    "        y = self.bn1a(y)\n",
    "        y = F.relu(y)\n",
    "        \n",
    "        # block 2:\n",
    "        z = self.conv2a(x)\n",
    "        z = self.bn2a(z)\n",
    "        z = F.relu(z) \n",
    "        \n",
    "        #block 3:\n",
    "        w = self.conv3a(x)\n",
    "        w = self.bn3a(w)\n",
    "        w = F.relu(w)\n",
    "        w1 = self.conv3b(w)\n",
    "        w1 = self.bn3b(w1)\n",
    "        w1 = F.relu(w1)\n",
    "        w2 = self.conv3c(w)\n",
    "        w2 = self.bn3c(w2)\n",
    "        w2 = F.relu(w2)\n",
    "        \n",
    "        #block 4:\n",
    "        v = self.conv4a(x)\n",
    "        v = self.bn4a(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4b(v)\n",
    "        v = self.bn4b(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4c(v)\n",
    "        v = self.bn4c(v)\n",
    "        v = F.relu(v)\n",
    "        v1 = self.conv4d(v)\n",
    "        v1 = self.bn4d(v1)\n",
    "        v1 = F.relu(v1)\n",
    "        v2 = self.conv4e(v)\n",
    "        v2 = self.bn4e(v2)\n",
    "        v2 = F.relu(v2)\n",
    "        \n",
    "        xFC = torch.cat((y, z, w1, w2, v1, v2), 1)\n",
    "        \n",
    "        return xFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReductionA(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(ReductionA, self).__init__()\n",
    "        \n",
    "        #----------------------- ReductionA block start ----------------------------\n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #block 1\n",
    "        #192 x 26 x 26 --> 192 x 12 x 12  , kernel size = 3, VALID Padding\n",
    "        self.pool1  = nn.MaxPool2d(kernel_size=3, stride=2, padding=0 )\n",
    "        \n",
    "        #block 2\n",
    "        #192 x 26 x 26 --> 192 x 12 x 12  , VALID Padding -- \n",
    "        self.conv1a = nn.Conv2d(192, 192, kernel_size=3, stride=2, padding=0 ) \n",
    "        self.bn1a = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 3\n",
    "        #192 x 26 x 26 --> 96 x 26 x 26  , SAME Padding \n",
    "        self.conv2a = nn.Conv2d(192, 96, kernel_size=1, padding=0 )\n",
    "        self.bn2a = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #96 x 26 x 26 --> 112 x 26 x 26  , SAME Padding \n",
    "        self.conv2b = nn.Conv2d(96, 112, kernel_size=3, padding=1 )\n",
    "        self.bn2b = nn.BatchNorm2d(112,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #112 x 26 x 26 --> 128 x 12 x 12  , VALID Padding \n",
    "        self.conv2c = nn.Conv2d(112, 128, kernel_size=3, stride=2, padding=0 )\n",
    "        self.bn2c = nn.BatchNorm2d(128,affine=True, eps=0.001,momentum=0.1)\n",
    "                \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #----------------------- ReductionA block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1:\n",
    "        y = self.pool1(x)\n",
    "        \n",
    "        # block 2:\n",
    "        z = self.conv1a(x)\n",
    "        z = self.bn1a(z)\n",
    "        z = F.relu(z) \n",
    "        \n",
    "        #block 3:\n",
    "        w = self.conv2a(x)\n",
    "        w = self.bn2a(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv2b(w)\n",
    "        w = self.bn2b(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv2c(w)\n",
    "        w = self.bn2c(w)\n",
    "        w = F.relu(w)\n",
    "                \n",
    "        xFC = torch.cat((y, z, w), 1)\n",
    "        \n",
    "        return xFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReductionB(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(ReductionB, self).__init__()\n",
    "        \n",
    "        #----------------------- ReductionB block start ----------------------------\n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #block 1\n",
    "        #512 x 12 x 12 --> 512 x 5 x 5  , kernel size = 3, VALID Padding\n",
    "        self.pool1  = nn.MaxPool2d(kernel_size=3, stride=2, padding=0 )\n",
    "        \n",
    "        #block 2\n",
    "        #512 x 12 x 12 --> 96 x 12 x 12  , SAME Padding -- \n",
    "        self.conv1a = nn.Conv2d(512, 96, kernel_size=1, padding=0 ) \n",
    "        self.bn1a = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #96 x 12 x 12 --> 96 x 5 x 5  , VALID Padding -- \n",
    "        self.conv1b = nn.Conv2d(96, 96, kernel_size=3, stride=2, padding=0 ) \n",
    "        self.bn1b = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 3\n",
    "        #512 x 12 x 12 --> 128 x 12 x 12  , SAME Padding \n",
    "        self.conv2a = nn.Conv2d(512, 128, kernel_size=1, padding=0 )\n",
    "        self.bn2a = nn.BatchNorm2d(128,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #128 x 12 x 12 --> 128 x 12 x 12  , SAME Padding \n",
    "        self.conv2b = nn.Conv2d(128, 128, kernel_size=[1, 7], padding=[0,3] )\n",
    "        self.bn2b = nn.BatchNorm2d(128,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #128 x 12 x 12 --> 160 x 12 x 12  , SAME Padding \n",
    "        self.conv2c = nn.Conv2d(128, 160, kernel_size=[7, 1], padding=[3,0] )\n",
    "        self.bn2c = nn.BatchNorm2d(160,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #160 x 12 x 12 --> 160 x 5 x 5  , VALID Padding \n",
    "        self.conv2d = nn.Conv2d(160, 160, kernel_size=3, stride=2, padding=0 )\n",
    "        self.bn2d = nn.BatchNorm2d(160,affine=True, eps=0.001,momentum=0.1)\n",
    "                \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #----------------------- ReductionB block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1:\n",
    "        y = self.pool1(x)\n",
    "        \n",
    "        # block 2:\n",
    "        z = self.conv1a(x)\n",
    "        z = self.bn1a(z)\n",
    "        z = F.relu(z) \n",
    "        z = self.conv1b(z)\n",
    "        z = self.bn1b(z)\n",
    "        z = F.relu(z) \n",
    "        \n",
    "        #block 3:\n",
    "        w = self.conv2a(x)\n",
    "        w = self.bn2a(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv2b(w)\n",
    "        w = self.bn2b(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv2c(w)\n",
    "        w = self.bn2c(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv2d(w)\n",
    "        w = self.bn2d(w)\n",
    "        w = F.relu(w)\n",
    "                \n",
    "        xFC = torch.cat((y, z, w), 1)\n",
    "        \n",
    "        return xFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_v4_convnet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Inception_v4_convnet, self).__init__()\n",
    "        \n",
    "\n",
    "        # Special attributs\n",
    "        self.input_space = None\n",
    "        self.input_size = (32, 32, 3)\n",
    "        self.num_classes = 1000;\n",
    "\n",
    "        # Modules\n",
    "        self.features = nn.Sequential(\n",
    "            Stem(),\n",
    "            InceptionA(),\n",
    "            InceptionA(),\n",
    "            InceptionA(),\n",
    "            InceptionA(),\n",
    "            ReductionA(), \n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            ReductionB(), \n",
    "            InceptionC(),\n",
    "            InceptionC(),\n",
    "            InceptionC()\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.AvgPool2d(kernel_size=5, stride=1, padding=0 )\n",
    "        self.linear = nn.Linear(768, 10)\n",
    "        self.dropout = nn.Dropout(0.2) \n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.features(input)\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception_v4_convnet(\n",
      "  (features): Sequential(\n",
      "    (0): Stem(\n",
      "      (conv1a): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1b): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1b): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pool1): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      (conv2a): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(80, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn3b): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(80, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(32, 32, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4b): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(32, 32, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4c): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn4d): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv5a): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn5a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): InceptionA(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn3b): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4b): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4c): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): InceptionA(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn3b): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4b): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4c): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): InceptionA(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn3b): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4b): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4c): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): InceptionA(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn3b): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4b): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4c): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): ReductionA(\n",
      "      (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (conv1a): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn1a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2b): Conv2d(96, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2b): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2c): Conv2d(112, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn2c): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(96, 112, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(112, 128, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(96, 96, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(96, 112, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(112, 112, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(112, 128, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(96, 112, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(112, 128, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(96, 96, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(96, 112, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(112, 112, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(112, 128, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(96, 112, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(112, 128, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(96, 96, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(96, 112, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(112, 112, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(112, 128, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(96, 112, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(112, 128, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(96, 96, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(96, 112, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(112, 112, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(112, 128, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (10): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(96, 112, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(112, 128, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(96, 96, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(96, 112, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(112, 112, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(112, 128, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(96, 112, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(112, 128, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(96, 96, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(96, 112, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(112, 112, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(112, 128, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(96, 112, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(112, 128, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(96, 96, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(96, 112, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(112, 112, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(112, 128, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (13): ReductionB(\n",
      "      (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (conv1a): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1b): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn1b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2b): Conv2d(128, 128, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn2b): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2c): Conv2d(128, 160, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn2c): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2d): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn2d): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (14): InceptionC(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(192, 128, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn3b): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(192, 128, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn3c): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(192, 224, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(224, 256, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(256, 128, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4d): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(256, 128, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4e): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (15): InceptionC(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(192, 128, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn3b): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(192, 128, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn3c): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(192, 224, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(224, 256, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(256, 128, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4d): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(256, 128, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4e): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (16): InceptionC(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(192, 128, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn3b): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(192, 128, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn3c): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(192, 224, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(224, 256, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(256, 128, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4d): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(256, 128, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4e): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=5, stride=1, padding=0)\n",
      "  (linear): Linear(in_features=768, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2)\n",
      ")\n",
      "There are 10406074 (10.41 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "net=Inception_v4_convnet()\n",
    "\n",
    "print(net)\n",
    "utils.display_num_param(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "my_lr=0.01 \n",
    "bs= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test_set():\n",
    "\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "\n",
    "    for i in range(0,10000,bs):\n",
    "\n",
    "        minibatch_data =  test_data[i:i+bs]\n",
    "        minibatch_label= test_label[i:i+bs]\n",
    "\n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        #inputs = (minibatch_data - mean)/std    # ONLY CHANGE IS HERE!\n",
    "        \n",
    "        inputs = minibatch_data\n",
    "\n",
    "        scores=net( inputs ) \n",
    "\n",
    "        error = utils.get_error( scores , minibatch_label)\n",
    "\n",
    "        running_error += error.item()\n",
    "\n",
    "        num_batches+=1\n",
    "\n",
    "\n",
    "    total_error = running_error/num_batches\n",
    "    print( 'error rate on test set =', total_error*100 ,'percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 \t time= 2.068599232037862 min \t lr= 0.01 \t loss= 2.0313381154537202 \t error= 77.23600071668625 percent\n",
      "error rate on test set = 66.34000051021576 percent\n",
      " \n",
      "epoch= 2 \t time= 4.254257726669311 min \t lr= 0.01 \t loss= 1.6183126668930055 \t error= 59.90600101947784 percent\n",
      "error rate on test set = 52.84000098705292 percent\n",
      " \n",
      "epoch= 3 \t time= 6.438330550988515 min \t lr= 0.01 \t loss= 1.3722742655277251 \t error= 49.7540009021759 percent\n",
      "error rate on test set = 46.87000095844269 percent\n",
      " \n",
      "epoch= 4 \t time= 8.619998927911123 min \t lr= 0.01 \t loss= 1.1964349547624589 \t error= 42.90600115060806 percent\n",
      "error rate on test set = 41.36000108718872 percent\n",
      " \n",
      "epoch= 5 \t time= 10.800750720500947 min \t lr= 0.005 \t loss= 1.0229569079875946 \t error= 36.170001482963556 percent\n",
      "error rate on test set = 37.76000154018402 percent\n",
      " \n",
      "epoch= 6 \t time= 12.982594613234202 min \t lr= 0.005 \t loss= 0.9460993807315826 \t error= 33.35400153398514 percent\n",
      "error rate on test set = 35.420001447200775 percent\n",
      " \n",
      "epoch= 7 \t time= 15.164617065588633 min \t lr= 0.005 \t loss= 0.8852824674844741 \t error= 30.754001784324647 percent\n",
      "error rate on test set = 33.55000191926956 percent\n",
      " \n",
      "epoch= 8 \t time= 17.34904283285141 min \t lr= 0.005 \t loss= 0.8252129807472229 \t error= 28.476001679897305 percent\n",
      "error rate on test set = 32.540001571178436 percent\n",
      " \n",
      "epoch= 9 \t time= 19.53245583375295 min \t lr= 0.005 \t loss= 0.7714866175055504 \t error= 26.624001824855803 percent\n",
      "error rate on test set = 31.510001718997955 percent\n",
      " \n",
      "epoch= 10 \t time= 21.7154855688413 min \t lr= 0.0025 \t loss= 0.6500055158734321 \t error= 21.924001944065093 percent\n",
      "error rate on test set = 28.90000146627426 percent\n",
      " \n",
      "epoch= 11 \t time= 23.897988192240398 min \t lr= 0.0025 \t loss= 0.5941627361774444 \t error= 20.164002060890198 percent\n",
      "error rate on test set = 28.730001628398895 percent\n",
      " \n",
      "epoch= 12 \t time= 26.078954136371614 min \t lr= 0.0025 \t loss= 0.5523487576842308 \t error= 18.496001970767974 percent\n",
      "error rate on test set = 28.270001888275146 percent\n",
      " \n",
      "epoch= 13 \t time= 28.26274069547653 min \t lr= 0.0025 \t loss= 0.5165213099420071 \t error= 17.458002066612245 percent\n",
      "error rate on test set = 28.690001666545868 percent\n",
      " \n",
      "epoch= 14 \t time= 30.446286563078562 min \t lr= 0.0025 \t loss= 0.48220594036579134 \t error= 16.192002058029175 percent\n",
      "error rate on test set = 29.060001611709595 percent\n",
      " \n",
      "epoch= 15 \t time= 32.63032025893529 min \t lr= 0.00125 \t loss= 0.37700023609399796 \t error= 12.050001883506775 percent\n",
      "error rate on test set = 27.390001714229584 percent\n",
      " \n",
      "epoch= 16 \t time= 34.81710782051086 min \t lr= 0.00125 \t loss= 0.3282271146774292 \t error= 10.308001923561095 percent\n",
      "error rate on test set = 27.870001673698425 percent\n",
      " \n",
      "epoch= 17 \t time= 37.00083206097285 min \t lr= 0.00125 \t loss= 0.29815975391864774 \t error= 9.20400195121765 percent\n",
      "error rate on test set = 28.060001790523533 percent\n",
      " \n",
      "epoch= 18 \t time= 39.18314892848333 min \t lr= 0.00125 \t loss= 0.2750570728927851 \t error= 8.556001758575439 percent\n",
      "error rate on test set = 27.720001578330994 percent\n",
      " \n",
      "epoch= 19 \t time= 41.36764884789785 min \t lr= 0.00125 \t loss= 0.25602243100106714 \t error= 7.914001834392548 percent\n",
      "error rate on test set = 28.070001542568207 percent\n",
      " \n",
      "epoch= 20 \t time= 43.554615084330244 min \t lr= 0.000625 \t loss= 0.19762575118243694 \t error= 5.68600195646286 percent\n",
      "error rate on test set = 27.750001788139343 percent\n",
      " \n",
      "epoch= 21 \t time= 45.740198930104576 min \t lr= 0.000625 \t loss= 0.1744502069801092 \t error= 4.682002127170563 percent\n",
      "error rate on test set = 27.800001621246338 percent\n",
      " \n",
      "epoch= 22 \t time= 47.925967919826505 min \t lr= 0.000625 \t loss= 0.1574704743027687 \t error= 4.15400241613388 percent\n",
      "error rate on test set = 27.710001468658447 percent\n",
      " \n",
      "epoch= 23 \t time= 50.11114919583003 min \t lr= 0.000625 \t loss= 0.1448287651836872 \t error= 3.7340026617050173 percent\n",
      "error rate on test set = 27.660001814365387 percent\n",
      " \n",
      "epoch= 24 \t time= 52.2921405673027 min \t lr= 0.000625 \t loss= 0.1293366862460971 \t error= 3.260002648830414 percent\n",
      "error rate on test set = 27.840001583099365 percent\n",
      " \n",
      "epoch= 25 \t time= 54.478038875261944 min \t lr= 0.0003125 \t loss= 0.11612325869128108 \t error= 2.7900028705596926 percent\n",
      "error rate on test set = 27.73000138998032 percent\n",
      " \n",
      "epoch= 26 \t time= 56.660176698366804 min \t lr= 0.0003125 \t loss= 0.10608011208474637 \t error= 2.4760029554367065 percent\n",
      "error rate on test set = 28.160001516342163 percent\n",
      " \n",
      "epoch= 27 \t time= 58.84368872642517 min \t lr= 0.0003125 \t loss= 0.10091442843154073 \t error= 2.3120028734207154 percent\n",
      "error rate on test set = 27.72000169754028 percent\n",
      " \n",
      "epoch= 28 \t time= 61.026856390635174 min \t lr= 0.0003125 \t loss= 0.09704721711203455 \t error= 2.1780030369758605 percent\n",
      "error rate on test set = 27.280001938343045 percent\n",
      " \n",
      "epoch= 29 \t time= 63.21429747343063 min \t lr= 0.0003125 \t loss= 0.08985614816471935 \t error= 1.986003077030182 percent\n",
      "error rate on test set = 27.80000150203705 percent\n",
      " \n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "for epoch in range(1,30):\n",
    "    \n",
    "    if not epoch%5:\n",
    "        my_lr = my_lr / 2\n",
    "        \n",
    "    optimizer=torch.optim.SGD( net.parameters() , lr=my_lr )\n",
    "        \n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    \n",
    "    shuffled_indices=torch.randperm(50000)\n",
    " \n",
    "    for count in range(0,50000,bs):\n",
    "        \n",
    "        # FORWARD AND BACKWARD PASS\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "             \n",
    "        indices=shuffled_indices[count:count+bs]\n",
    "        minibatch_data =  train_data[indices]\n",
    "        minibatch_label=  train_label[indices]\n",
    "        \n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        #inputs = (minibatch_data - mean)/std      # ONLY CHANGE IS HERE!\n",
    "        \n",
    "        inputs = minibatch_data\n",
    "        \n",
    "        inputs.requires_grad_()\n",
    "\n",
    "        scores=net( inputs ) \n",
    "\n",
    "        loss =  criterion( scores , minibatch_label) \n",
    "          \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # COMPUTE STATS\n",
    "        \n",
    "        running_loss += loss.detach().item()\n",
    "        \n",
    "        error = utils.get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "        \n",
    "        num_batches+=1        \n",
    "    \n",
    "    \n",
    "    # AVERAGE STATS THEN DISPLAY\n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    elapsed = (time.time()-start)/60\n",
    "    \n",
    "    print('epoch=',epoch, '\\t time=', elapsed,'min', '\\t lr=', my_lr  ,'\\t loss=', total_loss , '\\t error=', total_error*100 ,'percent')\n",
    "    eval_on_test_set() \n",
    "    print(' ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# choose a picture at random\n",
    "idx=randint(0, 10000-1)\n",
    "im=test_data[idx]\n",
    "\n",
    "# diplay the picture\n",
    "utils.show(im)\n",
    "\n",
    "# send to device, rescale, and view as a batch of 1 \n",
    "im = im.to(device)\n",
    "#im= (im-mean) / std\n",
    "im=im.view(1,3,32,32)\n",
    "\n",
    "# feed it to the net and display the confidence scores\n",
    "scores =  net(im) \n",
    "probs= F.softmax(scores, dim=1)\n",
    "utils.show_prob_cifar(probs.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
