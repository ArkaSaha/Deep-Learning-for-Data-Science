{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "TITAN V\n"
     ]
    }
   ],
   "source": [
    "device= torch.device(\"cuda:1\")\n",
    "#device= torch.device(\"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 3, 32, 32])\n",
      "torch.Size([10000, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "from utils import check_cifar_dataset_exists\n",
    "data_path=check_cifar_dataset_exists()\n",
    "\n",
    "train_data=torch.load(data_path+'cifar/train_data.pt')\n",
    "train_label=torch.load(data_path+'cifar/train_label.pt')\n",
    "test_data=torch.load(data_path+'cifar/test_data.pt')\n",
    "test_label=torch.load(data_path+'cifar/test_label.pt')\n",
    "\n",
    "print(train_data.size())\n",
    "print(test_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stem(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Stem, self).__init__()\n",
    "        \n",
    "        #----------------------- stem block start ----------------------------\n",
    "        \n",
    "        #self.padding = nn.ZeroPad2d((133,134,133,134))\n",
    "        #self.padding = nn.ReplicationPad2d((133,134,133,134))\n",
    "        \n",
    "        self.resize = nn.UpsamplingBilinear2d(size=(299,299))\n",
    "        \n",
    "        #3 x 299 x 299 --> 32 x 149 x 149  , VALID Padding \n",
    "        self.conv1a = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=0 ) \n",
    "        \n",
    "        self.bn1a = nn.BatchNorm2d(32,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #32 x 149 x 149 --> 32 x 147 x 147  , VALID Padding \n",
    "        self.conv1b = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0 )\n",
    "        \n",
    "        self.bn1b = nn.BatchNorm2d(32,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #32 x 147 x 147 --> 64 x 147 x 147  , SAME Padding \n",
    "        self.conv1c = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1 )\n",
    "        \n",
    "        self.bn1c = nn.BatchNorm2d(64,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #======================== Filter concat 1 =============================\n",
    "        \n",
    "        #64 x 147 x 147 --> 64 x 73 x 73, kernel size = 3, VALID Padding  \n",
    "        self.pool1  = nn.MaxPool2d(kernel_size=3, stride=2, padding=0 )\n",
    "        \n",
    "        #64 x 147 x 147 --> 96 x 73 x 73  , VALID Padding\n",
    "        self.conv2a = nn.Conv2d(64, 96, kernel_size=3, stride=2, padding=0 )\n",
    "        \n",
    "        self.bn2a = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #======================== Filter concat 1 =============================\n",
    "        \n",
    "        #======================== Filter concat 2 =============================       \n",
    "        \n",
    "        #160 x 73 x 73 --> 64 x 73 x 73  , SAME Padding   Find out the size of output\n",
    "        self.conv3a = nn.Conv2d(160, 64, kernel_size=1, padding=0 )\n",
    "        \n",
    "        self.bn3a = nn.BatchNorm2d(64,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #64 x 73 x 73 --> 96 x 71 x 71  , VALID Padding   Find out the size of output\n",
    "        self.conv3b = nn.Conv2d(64, 96, kernel_size=3, padding=0 )\n",
    "        \n",
    "        self.bn3b = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #160 x 73 x 73 --> 64 x 73 x 73  , SAME Padding   Might be combined with self.conv1e1\n",
    "        self.conv4a = nn.Conv2d(160, 64, kernel_size=1, padding=0 )\n",
    "        \n",
    "        self.bn4a = nn.BatchNorm2d(64,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #64 x 73 x 73 --> 64 x 73 x 73  , SAME Padding   Find out the size of output\n",
    "        self.conv4b = nn.Conv2d(64, 64, kernel_size=[7,1], padding=[3,0] )\n",
    "        \n",
    "        self.bn4b = nn.BatchNorm2d(64,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #64 x 73 x 73 --> 64 x 73 x 73  , SAME Padding   Find out the size of output\n",
    "        self.conv4c = nn.Conv2d(64, 64, kernel_size=[1,7], padding=[0,3]  )\n",
    "        \n",
    "        self.bn4c = nn.BatchNorm2d(64,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #64 x 73 x 73 --> 96 x 71 x 71  , VALID Padding   Might be combined with self.conv1e2\n",
    "        self.conv4d = nn.Conv2d(64, 96, kernel_size=3, padding=0 )\n",
    "        \n",
    "        self.bn4d = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #======================== Filter concat 2 ============================= \n",
    "        \n",
    "        #======================== Filter concat 3 =============================\n",
    "        \n",
    "        #192 x 71 x 71 --> 192 x 35 x 35  , VALID Padding \n",
    "        self.conv5a = nn.Conv2d(192, 192, kernel_size=3, stride=2, padding=0 )\n",
    "        \n",
    "        self.bn5a = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "         \n",
    "        #192 x 71 x 71 --> 192 x 35 x 35, kernel size = 3, VALID Padding\n",
    "        self.pool2  = nn.MaxPool2d(kernel_size=3, stride=2, padding=0 )\n",
    "        \n",
    "        #======================== Filter concat 3 =============================\n",
    "        \n",
    "        #----------------------- stem block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1: \n",
    "        #x = self.padding(x)\n",
    "        x= self.resize(x)\n",
    "        \n",
    "        x = self.conv1a(x)\n",
    "        x = self.bn1a(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv1b(x)\n",
    "        x = self.bn1b(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        \n",
    "        x = self.conv1c(x)\n",
    "        x = self.bn1c(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        \n",
    "        xP = self.pool1(x)\n",
    "        xC = self.conv2a(x)\n",
    "        xC = self.bn2a(xC)\n",
    "        xC = F.relu(xC)\n",
    "        xFC1 = torch.cat((xP, xC), 1)\n",
    "        \n",
    "        y = self.conv3a(xFC1)\n",
    "        y = self.bn3a(y)\n",
    "        y = F.relu(y)\n",
    "        \n",
    "        y = self.conv3b(y)\n",
    "        y = self.bn3b(y)\n",
    "        y = F.relu(y)\n",
    "\n",
    "        z = self.conv4a(xFC1)\n",
    "        z = self.bn4a(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.conv4b(z)\n",
    "        z = self.bn4b(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.conv4c(z)\n",
    "        z = self.bn4c(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.conv4d(z)\n",
    "        z = self.bn4d(z)\n",
    "        z = F.relu(z)\n",
    "        \n",
    "        # Above code or this one?\n",
    "        #z = self.conv3a(xFC1)\n",
    "        #z = F.relu(z)\n",
    "        #z = self.conv4b(z)\n",
    "        #z = F.relu(z)\n",
    "        #z = self.conv4c(xFC1)\n",
    "        #z = F.relu(z)\n",
    "        #z = self.conv3b(z)\n",
    "        #z = F.relu(z)\n",
    "        \n",
    "        xFC2 = torch.cat((y, z), 1)\n",
    "        \n",
    "        xP = self.pool2(xFC2)\n",
    "        xC = self.conv5a(xFC2)\n",
    "        xC = self.bn5a(xC)\n",
    "        xC = F.relu(xC)\n",
    "        xFC3 = torch.cat((xP, xC), 1)   \n",
    "        #print('Stem Done')\n",
    "        \n",
    "        return xFC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionA(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(InceptionA, self).__init__()\n",
    "        \n",
    "        #----------------------- InceptionA block start ----------------------------\n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #block 1\n",
    "        #384 x 35 x 35 --> 384 x 35 x 35  , kernel size = 3, SAME Padding\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=3, stride=1, padding=1 )\n",
    "        \n",
    "        #384 x 35 x 35 --> 96 x 35 x 35  , SAME Padding \n",
    "        self.conv1a = nn.Conv2d(384, 96, kernel_size=1, padding=0 ) \n",
    "        self.bn1a = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 2\n",
    "        #384 x 35 x 35 --> 96 x 35 x 35  , SAME Padding \n",
    "        self.conv2a = nn.Conv2d(384, 96, kernel_size=1, padding=0 ) \n",
    "        self.bn2a = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 3\n",
    "        #384 x 35 x 35 --> 64 x 35 x 35  , SAME Padding \n",
    "        self.conv3a = nn.Conv2d(384, 64, kernel_size=1, padding=0 )\n",
    "        self.bn3a = nn.BatchNorm2d(64,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #64 x 35 x 35 --> 96 x 35 x 35  , SAME Padding \n",
    "        self.conv3b = nn.Conv2d(64, 96, kernel_size=3, padding=1 )\n",
    "        self.bn3b = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 4\n",
    "        #384 x 35 x 35 --> 64 x 35 x 35  , SAME Padding \n",
    "        self.conv4a = nn.Conv2d(384, 64, kernel_size=1, padding=0 )\n",
    "        self.bn4a = nn.BatchNorm2d(64,affine=True, eps=0.001,momentum=0.1)\n",
    "\n",
    "        #64 x 35 x 35 --> 96 x 35 x 35  , SAME Padding \n",
    "        self.conv4b = nn.Conv2d(64, 96, kernel_size=3, padding=1 )\n",
    "        self.bn4b = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #96 x 35 x 35 --> 96 x 35 x 35  , SAME Padding \n",
    "        self.conv4c = nn.Conv2d(96, 96, kernel_size=3, padding=1 )\n",
    "        self.bn4c = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #----------------------- InceptionA block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1:\n",
    "        y = self.pool1(x)\n",
    "        y = self.conv1a(y)\n",
    "        y = self.bn1a(y)\n",
    "        y = F.relu(y)   # Do we need Relu here (after last operation)?\n",
    "        \n",
    "        # block 2:\n",
    "        z = self.conv2a(x)\n",
    "        z = self.bn2a(z)\n",
    "        z = F.relu(z) \n",
    "        \n",
    "        #block 3:\n",
    "        w = self.conv3a(x)\n",
    "        w = self.bn3a(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv3b(w)\n",
    "        w = self.bn3b(w)\n",
    "        w = F.relu(w)\n",
    "        \n",
    "        #block 4:\n",
    "        v = self.conv4a(x)\n",
    "        v = self.bn4a(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4b(v)\n",
    "        v = self.bn4b(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4c(v)\n",
    "        v = self.bn4c(v)\n",
    "        v = F.relu(v)\n",
    "        \n",
    "        xFC = torch.cat((y, z, w, v), 1)\n",
    "        #print('InceptionA Done')\n",
    "        \n",
    "        return xFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionB(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(InceptionB, self).__init__()\n",
    "        \n",
    "        #----------------------- InceptionB block start ----------------------------\n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #block 1\n",
    "        #1024 x 17 x 17 --> 1024 x 17 x 17  , kernel size = 1, SAME Padding\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=3, stride=1, padding=1 )\n",
    "        \n",
    "        #1024 x 17 x 17 --> 128 x 17 x 17  , SAME Padding \n",
    "        self.conv1a = nn.Conv2d(1024, 128, kernel_size=1, padding=0 ) \n",
    "        self.bn1a = nn.BatchNorm2d(128,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 2\n",
    "        #1024 x 17 x 17 --> 384 x 17 x 17  , SAME Padding \n",
    "        self.conv2a = nn.Conv2d(1024, 384, kernel_size=1, padding=0 ) \n",
    "        self.bn2a = nn.BatchNorm2d(384,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 3\n",
    "        #1024 x 17 x 17 --> 192 x 17 x 17  , SAME Padding \n",
    "        self.conv3a = nn.Conv2d(1024, 192, kernel_size=1, padding=0 )\n",
    "        self.bn3a = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #192 x 17 x 17 --> 224 x 17 x 17  , SAME Padding \n",
    "        self.conv3b = nn.Conv2d(192, 224, kernel_size=[7,1], padding=[3,0] )\n",
    "        self.bn3b = nn.BatchNorm2d(224,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #224 x 17 x 17 --> 256 x 17 x 17  , SAME Padding \n",
    "        self.conv3c = nn.Conv2d(224, 256, kernel_size=[1,7], padding=[0,3] )\n",
    "        self.bn3c = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 4\n",
    "        #1024 x 17 x 17 --> 192 x 17 x 17  , SAME Padding \n",
    "        self.conv4a = nn.Conv2d(1024, 192, kernel_size=1, padding=0 )\n",
    "        self.bn4a = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #192 x 17 x 17 --> 192 x 17 x 17  , SAME Padding \n",
    "        self.conv4b = nn.Conv2d(192, 192, kernel_size=[1,7], padding=[0,3] )\n",
    "        self.bn4b = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #192 x 17 x 17 --> 224 x 17 x 17  , SAME Padding \n",
    "        self.conv4c = nn.Conv2d(192, 224, kernel_size=[7,1], padding=[3,0] )\n",
    "        self.bn4c = nn.BatchNorm2d(224,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #224 x 17 x 17 --> 224 x 17 x 17  , SAME Padding \n",
    "        self.conv4d = nn.Conv2d(224, 224, kernel_size=[1,7], padding=[0,3] )\n",
    "        self.bn4d = nn.BatchNorm2d(224,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #224 x 17 x 17 --> 256 x 17 x 17  , SAME Padding \n",
    "        self.conv4e = nn.Conv2d(224, 256, kernel_size=[7,1], padding=[3,0] )\n",
    "        self.bn4e = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #----------------------- InceptionB block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # block 1:\n",
    "        y = self.pool1(x)\n",
    "        y = self.conv1a(y)\n",
    "        y = self.bn1a(y)\n",
    "        y = F.relu(y)\n",
    "        \n",
    "        # block 2:\n",
    "        z = self.conv2a(x)\n",
    "        z = self.bn2a(z)\n",
    "        z = F.relu(z) \n",
    "        \n",
    "        #block 3:\n",
    "        w = self.conv3a(x)\n",
    "        w = self.bn3a(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv3b(w)\n",
    "        w = self.bn3b(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv3c(w)\n",
    "        w = self.bn3c(w)\n",
    "        w = F.relu(w)\n",
    "        \n",
    "        #block 4:\n",
    "        v = self.conv4a(x)\n",
    "        v = self.bn4a(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4b(v)\n",
    "        v = self.bn4b(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4c(v)\n",
    "        v = self.bn4c(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4d(v)\n",
    "        v = self.bn4d(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4e(v)\n",
    "        v = self.bn4e(v)\n",
    "        v = F.relu(v)\n",
    "        \n",
    "        xFC = torch.cat((y, z, w, v), 1)\n",
    "        #print('InceptionB Done')\n",
    "        \n",
    "        return xFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionC(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(InceptionC, self).__init__()\n",
    "        \n",
    "        #----------------------- InceptionC block start ----------------------------\n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #block 1\n",
    "        #1536 x 8 x 8 --> 1536 x 8 x 8  , kernel size = 3, SAME Padding\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=3, stride=1, padding=1 )\n",
    "        \n",
    "        #1536 x 8 x 8 --> 256 x 8 x 8  , SAME Padding \n",
    "        self.conv1a = nn.Conv2d(1536, 256, kernel_size=1, padding=0 ) \n",
    "        self.bn1a = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 2\n",
    "        #1536 x 8 x 8 --> 256 x 8 x 8  , SAME Padding \n",
    "        self.conv2a = nn.Conv2d(1536, 256, kernel_size=1, padding=0 ) \n",
    "        self.bn2a = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 3\n",
    "        #1536 x 8 x 8 --> 384 x 8 x 8  , SAME Padding \n",
    "        self.conv3a = nn.Conv2d(1536, 384, kernel_size=1, padding=0 )\n",
    "        self.bn3a = nn.BatchNorm2d(384,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #384 x 8 x 8 --> 256 x 8 x 8  , SAME Padding \n",
    "        self.conv3b = nn.Conv2d(384, 256, kernel_size=[1,3], padding=[0,1] )\n",
    "        self.bn3b = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #384 x 8 x 8 --> 256 x 8 x 8  , SAME Padding \n",
    "        self.conv3c = nn.Conv2d(384, 256, kernel_size=[3,1], padding=[1,0] )\n",
    "        self.bn3c = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 4\n",
    "        #1536 x 8 x 8 --> 384 x 8 x 8  , SAME Padding \n",
    "        self.conv4a = nn.Conv2d(1536, 384, kernel_size=1, padding=0 )\n",
    "        self.bn4a = nn.BatchNorm2d(384,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #384 x 8 x 8 --> 448 x 8 x 8  , SAME Padding \n",
    "        self.conv4b = nn.Conv2d(384, 448, kernel_size=[1,3], padding=[0,1] )\n",
    "        self.bn4b = nn.BatchNorm2d(448,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #448 x 8 x 8 --> 512 x 8 x 8  , SAME Padding \n",
    "        self.conv4c = nn.Conv2d(448, 512, kernel_size=[3,1], padding=[1,0] )\n",
    "        self.bn4c = nn.BatchNorm2d(512,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #512 x 8 x 8 --> 256 x 8 x 8  , SAME Padding \n",
    "        self.conv4d = nn.Conv2d(512, 256, kernel_size=[3,1], padding=[1,0] )\n",
    "        self.bn4d = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #512 x 8 x 8 --> 256 x 8 x 8  , SAME Padding \n",
    "        self.conv4e = nn.Conv2d(512, 256, kernel_size=[1,3], padding=[0,1] )\n",
    "        self.bn4e = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #----------------------- InceptionC block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # block 1:\n",
    "        y = self.pool1(x)\n",
    "        y = self.conv1a(y)\n",
    "        y = self.bn1a(y)\n",
    "        y = F.relu(y)\n",
    "        \n",
    "        # block 2:\n",
    "        z = self.conv2a(x)\n",
    "        z = self.bn2a(z)\n",
    "        z = F.relu(z) \n",
    "        \n",
    "        #block 3:\n",
    "        w = self.conv3a(x)\n",
    "        w = self.bn3a(w)\n",
    "        w = F.relu(w)\n",
    "        w1 = self.conv3b(w)\n",
    "        w1 = self.bn3b(w1)\n",
    "        w1 = F.relu(w1)\n",
    "        w2 = self.conv3c(w)\n",
    "        w2 = self.bn3c(w2)\n",
    "        w2 = F.relu(w2)\n",
    "        \n",
    "        #block 4:\n",
    "        v = self.conv4a(x)\n",
    "        v = self.bn4a(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4b(v)\n",
    "        v = self.bn4b(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4c(v)\n",
    "        v = self.bn4c(v)\n",
    "        v = F.relu(v)\n",
    "        v1 = self.conv4d(v)\n",
    "        v1 = self.bn4d(v1)\n",
    "        v1 = F.relu(v1)\n",
    "        v2 = self.conv4e(v)\n",
    "        v2 = self.bn4e(v2)\n",
    "        v2 = F.relu(v2)\n",
    "        \n",
    "        xFC = torch.cat((y, z, w1, w2, v1, v2), 1)\n",
    "        #print('InceptionC Done')\n",
    "        \n",
    "        return xFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReductionA(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(ReductionA, self).__init__()\n",
    "        \n",
    "        #----------------------- ReductionA block start ----------------------------\n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #block 1\n",
    "        #384 x 35 x 35 --> 384 x 17 x 17  , kernel size = 3, VALID Padding\n",
    "        self.pool1  = nn.MaxPool2d(kernel_size=3, stride=2, padding=0 )\n",
    "        \n",
    "        #block 2\n",
    "        #384 x 35 x 35 --> 384 x 17 x 17  , VALID Padding -- \n",
    "        self.conv1a = nn.Conv2d(384, 384, kernel_size=3, stride=2, padding=0 ) \n",
    "        self.bn1a = nn.BatchNorm2d(384,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 3\n",
    "        #384 x 35 x 35 --> 192 x 35 x 35  , SAME Padding \n",
    "        self.conv2a = nn.Conv2d(384, 192, kernel_size=1, padding=0 )\n",
    "        self.bn2a = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #192 x 35 x 35 --> 224 x 35 x 35  , SAME Padding \n",
    "        self.conv2b = nn.Conv2d(192, 224, kernel_size=3, padding=1 )\n",
    "        self.bn2b = nn.BatchNorm2d(224,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #224 x 35 x 35 --> 256 x 17 x 17  , VALID Padding \n",
    "        self.conv2c = nn.Conv2d(224, 256, kernel_size=3, stride=2, padding=0 )\n",
    "        self.bn2c = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "                \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #----------------------- ReductionA block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1:\n",
    "        y = self.pool1(x)\n",
    "        \n",
    "        # block 2:\n",
    "        z = self.conv1a(x)\n",
    "        z = self.bn1a(z)\n",
    "        z = F.relu(z) \n",
    "        \n",
    "        #block 3:\n",
    "        w = self.conv2a(x)\n",
    "        w = self.bn2a(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv2b(w)\n",
    "        w = self.bn2b(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv2c(w)\n",
    "        w = self.bn2c(w)\n",
    "        w = F.relu(w)\n",
    "                \n",
    "        xFC = torch.cat((y, z, w), 1)\n",
    "        #print('ReductionA Done')\n",
    "        \n",
    "        return xFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReductionB(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(ReductionB, self).__init__()\n",
    "        \n",
    "        #----------------------- ReductionB block start ----------------------------\n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #block 1\n",
    "        #1024 x 17 x 17 --> 1024 x 8 x 8  , kernel size = 3, VALID Padding\n",
    "        self.pool1  = nn.MaxPool2d(kernel_size=3, stride=2, padding=0 )\n",
    "        \n",
    "        #block 2\n",
    "        #1024 x 17 x 17 --> 192 x 17 x 17  , SAME Padding -- \n",
    "        self.conv1a = nn.Conv2d(1024, 192, kernel_size=1, padding=0 ) \n",
    "        self.bn1a = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #192 x 17 x 17 --> 192 x 8 x 8  , VALID Padding -- \n",
    "        self.conv1b = nn.Conv2d(192, 192, kernel_size=3, stride=2, padding=0 ) \n",
    "        self.bn1b = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 3\n",
    "        #1024 x 17 x 17 --> 256 x 17 x 17  , SAME Padding \n",
    "        self.conv2a = nn.Conv2d(1024, 256, kernel_size=1, padding=0 )\n",
    "        self.bn2a = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #256 x 17 x 17 --> 256 x 17 x 17  , SAME Padding \n",
    "        self.conv2b = nn.Conv2d(256, 256, kernel_size=[1, 7], padding=[0,3] )\n",
    "        self.bn2b = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #256 x 17 x 17 --> 320 x 17 x 17  , SAME Padding \n",
    "        self.conv2c = nn.Conv2d(256, 320, kernel_size=[7, 1], padding=[3,0] )\n",
    "        self.bn2c = nn.BatchNorm2d(320,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #320 x 17 x 17 --> 320 x 8 x 8  , VALID Padding \n",
    "        self.conv2d = nn.Conv2d(320, 320, kernel_size=3, stride=2, padding=0 )\n",
    "        self.bn2d = nn.BatchNorm2d(320,affine=True, eps=0.001,momentum=0.1)\n",
    "                \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #----------------------- ReductionB block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1:\n",
    "        y = self.pool1(x)\n",
    "        \n",
    "        # block 2:\n",
    "        z = self.conv1a(x)\n",
    "        z = self.bn1a(z)\n",
    "        z = F.relu(z) \n",
    "        z = self.conv1b(z)\n",
    "        z = self.bn1b(z)\n",
    "        z = F.relu(z) \n",
    "        \n",
    "        #block 3:\n",
    "        w = self.conv2a(x)\n",
    "        w = self.bn2a(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv2b(w)\n",
    "        w = self.bn2b(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv2c(w)\n",
    "        w = self.bn2c(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv2d(w)\n",
    "        w = self.bn2d(w)\n",
    "        w = F.relu(w)\n",
    "                \n",
    "        xFC = torch.cat((y, z, w), 1)\n",
    "        #print('ReductionB Done')\n",
    "        \n",
    "        return xFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_v4_convnet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Inception_v4_convnet, self).__init__()\n",
    "        \n",
    "\n",
    "        # Special attributs\n",
    "        self.input_space = None\n",
    "        self.input_size = (299, 299, 3)\n",
    "        self.num_classes = 1000;\n",
    "\n",
    "        # Modules\n",
    "        self.features = nn.Sequential(\n",
    "            Stem(),\n",
    "            InceptionA(),\n",
    "            InceptionA(),\n",
    "            InceptionA(),\n",
    "            InceptionA(),\n",
    "            ReductionA(), \n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            ReductionB(), \n",
    "            InceptionC(),\n",
    "            InceptionC(),\n",
    "            InceptionC()\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.AvgPool2d(8, padding=1 )\n",
    "        self.linear = nn.Linear(1536, 10)\n",
    "        self.dropout = nn.Dropout(0.2) \n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.features(input)\n",
    "        \n",
    "        x = self.pool(x)\n",
    "       \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception_v4_convnet(\n",
      "  (features): Sequential(\n",
      "    (0): Stem(\n",
      "      (resize): UpsamplingBilinear2d(size=(299, 299), mode=bilinear)\n",
      "      (conv1a): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn1a): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn1b): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1c): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1c): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (conv2a): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn2a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn3b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(64, 64, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4b): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(64, 64, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4c): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn4d): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv5a): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn5a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): InceptionA(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn3b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4c): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): InceptionA(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn3b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4c): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): InceptionA(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn3b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4c): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): InceptionA(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn3b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4c): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): ReductionA(\n",
      "      (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (conv1a): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn1a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2b): Conv2d(192, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2c): Conv2d(224, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn2c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(224, 256, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(224, 224, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(224, 256, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(224, 256, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(224, 224, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(224, 256, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(224, 256, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(224, 224, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(224, 256, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(224, 256, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(224, 224, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(224, 256, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (10): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(224, 256, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(224, 224, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(224, 256, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(224, 256, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(224, 224, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(224, 256, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(224, 256, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(224, 224, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(224, 256, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (13): ReductionB(\n",
      "      (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (conv1a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1b): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn1b): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2b): Conv2d(256, 256, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn2b): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2c): Conv2d(256, 320, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn2c): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn2d): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (14): InceptionC(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(384, 256, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn3b): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(384, 256, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(384, 448, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4b): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(448, 512, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4c): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(512, 256, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4d): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(512, 256, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (15): InceptionC(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(384, 256, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn3b): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(384, 256, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(384, 448, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4b): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(448, 512, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4c): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(512, 256, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4d): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(512, 256, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (16): InceptionC(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(384, 256, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn3b): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(384, 256, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(384, 448, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4b): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(448, 512, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4c): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(512, 256, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4d): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(512, 256, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=8, stride=8, padding=1)\n",
      "  (linear): Linear(in_features=1536, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2)\n",
      ")\n",
      "There are 41189770 (41.19 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "net=Inception_v4_convnet()\n",
    "\n",
    "print(net)\n",
    "utils.display_num_param(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "my_lr=0.005 \n",
    "bs= 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test_set():\n",
    "\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "\n",
    "    for i in range(0,10000,bs):\n",
    "\n",
    "        minibatch_data = test_data[i:i+bs]\n",
    "        minibatch_label= test_label[i:i+bs]\n",
    "\n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        inputs = minibatch_data\n",
    "\n",
    "        scores=net( inputs ) \n",
    "\n",
    "        error = utils.get_error( scores , minibatch_label)\n",
    "\n",
    "        running_error += error.item()\n",
    "\n",
    "        num_batches+=1\n",
    "\n",
    "    total_error = running_error/num_batches\n",
    "    print( 'error rate on test set =', total_error*100 ,'percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titan/miniconda3/envs/deeplearn_project/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:225: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/titan/miniconda3/envs/deeplearn_project/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 \t time= 12.230455549558004 min \t lr= 0.005 \t loss= 1.8256688522338866 \t error= 68.56999947309494 percent\n",
      "error rate on test set = 56.659998929500574 percent\n",
      " \n",
      "epoch= 2 \t time= 24.983041508992514 min \t lr= 0.005 \t loss= 1.3314774942159653 \t error= 47.679998614788055 percent\n",
      "error rate on test set = 42.08999860286713 percent\n",
      " \n",
      "epoch= 3 \t time= 37.73377072016398 min \t lr= 0.005 \t loss= 1.0290306346416473 \t error= 36.143998687267306 percent\n",
      "error rate on test set = 32.54999883174896 percent\n",
      " \n",
      "epoch= 4 \t time= 50.49199478626251 min \t lr= 0.0025 \t loss= 0.7417028994679451 \t error= 25.637998862266542 percent\n",
      "error rate on test set = 26.489998817443848 percent\n",
      " \n",
      "epoch= 5 \t time= 63.558785390853885 min \t lr= 0.0025 \t loss= 0.6186899702489376 \t error= 21.009998769760134 percent\n",
      "error rate on test set = 23.85999881029129 percent\n",
      " \n",
      "epoch= 6 \t time= 76.3177278717359 min \t lr= 0.0025 \t loss= 0.5310492373049259 \t error= 18.05999861240387 percent\n",
      "error rate on test set = 21.209998750686644 percent\n",
      " \n",
      "epoch= 7 \t time= 89.0758650581042 min \t lr= 0.0025 \t loss= 0.4521261163368821 \t error= 15.219998519420624 percent\n",
      "error rate on test set = 20.10999861955643 percent\n",
      " \n",
      "epoch= 8 \t time= 101.82985388437906 min \t lr= 0.00125 \t loss= 0.29914624421447517 \t error= 9.819998767375946 percent\n",
      "error rate on test set = 18.559998750686646 percent\n",
      " \n",
      "epoch= 9 \t time= 114.65112407604853 min \t lr= 0.00125 \t loss= 0.23530589589700102 \t error= 7.617999079227447 percent\n",
      "error rate on test set = 18.099998712539673 percent\n",
      " \n",
      "epoch= 10 \t time= 127.39822814464569 min \t lr= 0.00125 \t loss= 0.19271125089637936 \t error= 6.177999410629273 percent\n",
      "error rate on test set = 18.36999855041504 percent\n",
      " \n",
      "epoch= 11 \t time= 140.16866593758266 min \t lr= 0.00125 \t loss= 0.16817301937937737 \t error= 5.3719995188713074 percent\n",
      "error rate on test set = 18.27999861240387 percent\n",
      " \n",
      "epoch= 12 \t time= 153.13037657737732 min \t lr= 0.000625 \t loss= 0.10067537600360811 \t error= 2.8500000190734864 percent\n",
      "error rate on test set = 16.96999864578247 percent\n",
      " \n",
      "epoch= 13 \t time= 165.95702913999557 min \t lr= 0.000625 \t loss= 0.06662271390659735 \t error= 1.674000129699707 percent\n",
      "error rate on test set = 17.229998695850373 percent\n",
      " \n",
      "epoch= 14 \t time= 178.79484843015672 min \t lr= 0.000625 \t loss= 0.05666798306610435 \t error= 1.3980001044273378 percent\n",
      "error rate on test set = 16.929998552799226 percent\n",
      " \n",
      "epoch= 15 \t time= 191.72498224576313 min \t lr= 0.000625 \t loss= 0.049410349689982834 \t error= 1.1600001120567323 percent\n",
      "error rate on test set = 16.799998569488526 percent\n",
      " \n",
      "epoch= 16 \t time= 204.71098943154018 min \t lr= 0.0003125 \t loss= 0.0365238431753125 \t error= 0.7300000882148743 percent\n",
      "error rate on test set = 16.329998600482938 percent\n",
      " \n",
      "epoch= 17 \t time= 217.45729631185532 min \t lr= 0.0003125 \t loss= 0.031039311789255588 \t error= 0.6140000867843628 percent\n",
      "error rate on test set = 16.34999861717224 percent\n",
      " \n",
      "epoch= 18 \t time= 230.21475950479507 min \t lr= 0.0003125 \t loss= 0.027023307882156223 \t error= 0.46600004434585574 percent\n",
      "error rate on test set = 16.379998576641082 percent\n",
      " \n",
      "epoch= 19 \t time= 242.96832414865494 min \t lr= 0.0003125 \t loss= 0.024428683128161356 \t error= 0.438000066280365 percent\n",
      "error rate on test set = 16.239998507499696 percent\n",
      " \n",
      "epoch= 20 \t time= 255.71638398567836 min \t lr= 0.00015625 \t loss= 0.021411545507377013 \t error= 0.34000004768371583 percent\n",
      "error rate on test set = 16.27999861240387 percent\n",
      " \n",
      "epoch= 21 \t time= 268.46486037572225 min \t lr= 0.00015625 \t loss= 0.02053753886022605 \t error= 0.3420000553131104 percent\n",
      "error rate on test set = 16.209998536109925 percent\n",
      " \n",
      "epoch= 22 \t time= 281.21246600548426 min \t lr= 0.00015625 \t loss= 0.018834091151598842 \t error= 0.28400004863739015 percent\n",
      "error rate on test set = 16.139998483657834 percent\n",
      " \n",
      "epoch= 23 \t time= 294.5551081975301 min \t lr= 0.00015625 \t loss= 0.018546577548002825 \t error= 0.27800004005432133 percent\n",
      "error rate on test set = 16.36999856233597 percent\n",
      " \n",
      "epoch= 24 \t time= 308.0589700182279 min \t lr= 7.8125e-05 \t loss= 0.017271492985077203 \t error= 0.2280000305175781 percent\n",
      "error rate on test set = 16.219998526573182 percent\n",
      " \n",
      "epoch= 25 \t time= 321.3835381944974 min \t lr= 7.8125e-05 \t loss= 0.017177454081596807 \t error= 0.2520000386238098 percent\n",
      "error rate on test set = 16.03999857902527 percent\n",
      " \n",
      "epoch= 26 \t time= 334.30204273462294 min \t lr= 7.8125e-05 \t loss= 0.017002146264957264 \t error= 0.3020000505447388 percent\n",
      "error rate on test set = 16.059998524188995 percent\n",
      " \n",
      "epoch= 27 \t time= 347.2637988050779 min \t lr= 7.8125e-05 \t loss= 0.015901633044495246 \t error= 0.2180000352859497 percent\n",
      "error rate on test set = 16.019998562335967 percent\n",
      " \n",
      "epoch= 28 \t time= 360.0289576768875 min \t lr= 3.90625e-05 \t loss= 0.015382060217298568 \t error= 0.18800003290176392 percent\n",
      "error rate on test set = 16.109998536109924 percent\n",
      " \n",
      "epoch= 29 \t time= 372.8073352853457 min \t lr= 3.90625e-05 \t loss= 0.01603551923763007 \t error= 0.21800002574920654 percent\n",
      "error rate on test set = 15.879998540878296 percent\n",
      " \n",
      "epoch= 30 \t time= 385.5836729486783 min \t lr= 3.90625e-05 \t loss= 0.015501293929293752 \t error= 0.21200002908706664 percent\n",
      "error rate on test set = 15.859998619556425 percent\n",
      " \n",
      "epoch= 31 \t time= 398.48947183688483 min \t lr= 3.90625e-05 \t loss= 0.015903635807801037 \t error= 0.24200002908706664 percent\n",
      "error rate on test set = 16.009998583793642 percent\n",
      " \n",
      "epoch= 32 \t time= 411.27669272820157 min \t lr= 1.953125e-05 \t loss= 0.015711709799361415 \t error= 0.21200003385543822 percent\n",
      "error rate on test set = 15.949998533725736 percent\n",
      " \n",
      "epoch= 33 \t time= 424.03998229503634 min \t lr= 1.953125e-05 \t loss= 0.014504021060396917 \t error= 0.1900000309944153 percent\n",
      "error rate on test set = 15.909998524188996 percent\n",
      " \n",
      "epoch= 34 \t time= 436.83901607990265 min \t lr= 1.953125e-05 \t loss= 0.014636304132035002 \t error= 0.22600003719329834 percent\n",
      "error rate on test set = 15.779998552799224 percent\n",
      " \n",
      "epoch= 35 \t time= 449.60925914843875 min \t lr= 1.953125e-05 \t loss= 0.015109204430459067 \t error= 0.22800002098083494 percent\n",
      "error rate on test set = 15.93999855518341 percent\n",
      " \n",
      "epoch= 36 \t time= 462.35991727113725 min \t lr= 9.765625e-06 \t loss= 0.014795658732950688 \t error= 0.20000003814697265 percent\n",
      "error rate on test set = 15.84999850988388 percent\n",
      " \n",
      "epoch= 37 \t time= 475.37693890333173 min \t lr= 9.765625e-06 \t loss= 0.014891610783315263 \t error= 0.2160000252723694 percent\n",
      "error rate on test set = 15.939998602867126 percent\n",
      " \n",
      "epoch= 38 \t time= 488.4776496529579 min \t lr= 9.765625e-06 \t loss= 0.014190127998497337 \t error= 0.19200003623962403 percent\n",
      "error rate on test set = 15.949998497962953 percent\n",
      " \n",
      "epoch= 39 \t time= 501.4044863859812 min \t lr= 9.765625e-06 \t loss= 0.014609385341987946 \t error= 0.18000003099441528 percent\n",
      "error rate on test set = 15.909998524188996 percent\n",
      " \n",
      "epoch= 40 \t time= 514.315988989671 min \t lr= 4.8828125e-06 \t loss= 0.014871304510766641 \t error= 0.19600003480911254 percent\n",
      "error rate on test set = 15.93999866247177 percent\n",
      " \n",
      "epoch= 41 \t time= 527.215066965421 min \t lr= 4.8828125e-06 \t loss= 0.013555234077572823 \t error= 0.1600000262260437 percent\n",
      "error rate on test set = 15.949998569488525 percent\n",
      " \n",
      "epoch= 42 \t time= 540.1788902242978 min \t lr= 4.8828125e-06 \t loss= 0.015187400681432336 \t error= 0.22200003862380982 percent\n",
      "error rate on test set = 15.989998507499696 percent\n",
      " \n",
      "epoch= 43 \t time= 553.0575230320295 min \t lr= 4.8828125e-06 \t loss= 0.014418086887244136 \t error= 0.20800003290176394 percent\n",
      "error rate on test set = 15.949998593330383 percent\n",
      " \n",
      "epoch= 44 \t time= 565.9679868102073 min \t lr= 2.44140625e-06 \t loss= 0.015570986196165905 \t error= 0.23000002145767215 percent\n",
      "error rate on test set = 15.869998538494109 percent\n",
      " \n",
      "epoch= 45 \t time= 578.9329442063968 min \t lr= 2.44140625e-06 \t loss= 0.014815417726500892 \t error= 0.1980000329017639 percent\n",
      "error rate on test set = 16.039998519420624 percent\n",
      " \n",
      "epoch= 46 \t time= 591.7883927543958 min \t lr= 2.44140625e-06 \t loss= 0.0146492324373452 \t error= 0.1940000343322754 percent\n",
      "error rate on test set = 15.949998605251311 percent\n",
      " \n",
      "epoch= 47 \t time= 604.6297979235649 min \t lr= 2.44140625e-06 \t loss= 0.01491043728212826 \t error= 0.21000003576278686 percent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate on test set = 16.05999857187271 percent\n",
      " \n",
      "epoch= 48 \t time= 617.401618440946 min \t lr= 1.220703125e-06 \t loss= 0.013656075346004218 \t error= 0.16800002574920656 percent\n",
      "error rate on test set = 15.909998607635497 percent\n",
      " \n",
      "epoch= 49 \t time= 630.2265872677167 min \t lr= 1.220703125e-06 \t loss= 0.0142316330303438 \t error= 0.19600002765655516 percent\n",
      "error rate on test set = 15.929998505115508 percent\n",
      " \n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "for epoch in range(1,50):\n",
    "    \n",
    "    # divide the learning rate by 2 at epoch 10, 14 and 18\n",
    "    if (epoch%4 == 0):\n",
    "        my_lr = my_lr / 2\n",
    "    \n",
    "    # create a new optimizer at the beginning of each epoch: give the current learning rate.   \n",
    "    optimizer=torch.optim.SGD( net.parameters() , lr=my_lr )\n",
    "        \n",
    "    # set the running quatities to zero at the beginning of the epoch\n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    \n",
    "    # set the order in which to visit the image from the training set\n",
    "    shuffled_indices=torch.randperm(50000)\n",
    " \n",
    "    for count in range(0,50000,bs):\n",
    "    \n",
    "        # Set the gradients to zeros\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # create a minibatch       \n",
    "        indices=shuffled_indices[count:count+bs]\n",
    "        \n",
    "        minibatch_data =  train_data[indices]\n",
    "        minibatch_label=  train_label[indices]\n",
    "        \n",
    "        # send them to the gpu\n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        # normalize the minibatch (this is the only difference compared to before!)\n",
    "        #inputs = (minibatch_data - mean)/std\n",
    "        \n",
    "        inputs = minibatch_data\n",
    "        \n",
    "        # tell Pytorch to start tracking all operations that will be done on \"inputs\"\n",
    "        inputs.requires_grad_()\n",
    "\n",
    "        # forward the minibatch through the net \n",
    "        scores=net( inputs ) \n",
    "\n",
    "        # Compute the average of the losses of the data points in the minibatch\n",
    "        loss =  criterion( scores , minibatch_label) \n",
    "        \n",
    "        # backward pass to compute dL/dU, dL/dV and dL/dW   \n",
    "        loss.backward()\n",
    "        \n",
    "        #torch.cuda.empty_cache()\n",
    "        # do one step of stochastic gradient descent: U=U-lr(dL/dU), V=V-lr(dL/dU), ...\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # START COMPUTING STATS\n",
    "        \n",
    "        # add the loss of this batch to the running loss\n",
    "        running_loss += loss.detach().item()\n",
    "        \n",
    "        # compute the error made on this batch and add it to the running error       \n",
    "        error = utils.get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "        \n",
    "        num_batches+=1        \n",
    "    \n",
    "    \n",
    "    # compute stats for the full training set\n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    elapsed = (time.time()-start)/60\n",
    "    \n",
    "\n",
    "    print('epoch=',epoch, '\\t time=', elapsed,'min','\\t lr=', my_lr  ,'\\t loss=', total_loss , '\\t error=', total_error*100 ,'percent')\n",
    "    eval_on_test_set() \n",
    "    print(' ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titan/miniconda3/envs/deeplearn_project/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:225: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/titan/miniconda3/envs/deeplearn_project/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoYAAAGMCAYAAABH+WOCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzs3Xt8z3X/x/HHd2PfMTMytDktp6ZyzGHLOS5RzqFEzUVduQqhIxHpF666UFGuilAhUc4VJUKM5ZhijptzOY4NG9vn98d739n2/c42O/O8327f2/vb+/3+vD/vz9jldb1PH5tlWRYiIiIicttzy+sOiIiIiEj+oMBQRERERAAFhiIiIiKSSIGhiIiIiAAKDEVEREQkkQJDEREREQEUGIqIiIhIIgWGIiIiIgIoMBQRERGRRIXyugOSPz3zzDPs2rUrRd59993Hp59+mkc9EhERkZymwFBc2rVrF6GhoXndDREREclFmkoWEREREUCBoYiIiIgkUmAoIiIiIoACQxERERFJpMBQRERERAAFhiIiIiKSSIGhiIiIiAAKDEVEREQkkQJDEREREQEUGIqIiIhIIgWGIiIiIgIoMBQRERGRRAoMRURERARQYCgiIiIiiRQYioiIiAigwFBEREREEikwFBERERFAgaGIiIiIJCqU1x2QgiM0FGy23LufZeXevUREREQjhiIiIiKSSIGhiIiIiAAKDOU2dOUKjBoF1auDpyf4+0PfvnD0aObbOn8eBg+GSpXAbjfpCy+Y/LTs3g1PPQUVKkDhwlC8ODzwAHzyCSQk3PxziYiIZJXNsrSSS5wFBwcTGhqaKjcI2JhrfciJv5lXrkCrVrBhA/j5QdOmEBEBmzdD6dKwcSNUqZKxts6cgeBg2LcPKleG+vXhjz/Mp2pVsyazVKmU16xfD23awOXLcO+9cM89cPYsrFsHcXHw2GPw1VfZ/tgiIiIZcsuPGK5ZswabzUafPn1y5X6jR4/GZrMxc+bMXLmfZM7YsSYoDA6GvXth3jzYtAkmTIBTp8zIYUYNGWKCwq5dITzctLVrFwwcCPv3w9ChztcMGmSCwnfeMXW//hp++sl89/U1baxenX3PKyIikhm3fGAo4nD1KkyebL5/+CEUK3a9bOhQqFUL1q6FLVvSb+vkSZg920wFf/QRFEq2v//dd83o4+zZ8Ndf1/Ojo2HbNihaFF58MWV71apBr17me1jYzT2fiIhIVt3ygWHDhg3ZvXs348aNy+uuSB5bv96s/atSBerWdS7v1s2kS5em39b335v1gM2aQdmyKcvsdujQAeLjTT2HwoXBzS39I3/uuCP9+4uIiOSEWz4wLFq0KIGBgfj5+eV1VySP7dhh0nr1XJc78h31srstu92saYyJMVPXye3bZ0YYfXygc+f07y8iIpITCmRguHz5cvr27UuNGjUoXrw4Xl5e1K5dm7FjxxIbG5uiblprDJOvBdy8eTPt27enVKlS2Gw2tm/fDkBAQAA2mw3Lsnj//fe555578PT0pFy5cgwaNIjzN9p6msr+/fsZPXo0wcHB3HnnnXh4eFC+fHmeeuop9u7d6/Iam81GQEAA8fHxvPPOO1SvXh273U6FChV49dVXnZ7VITo6mjFjxlCzZk2KFi1K8eLFad68OYsWLcpwf29Fhw+btHx51+WOfEe9nGhr6lQoVw5eeQXuu89sNvnHP8z3MmVg5Uqz1lBERCQvFMjAsF+/fsyfPx8fHx/atm1L06ZNOXLkCK+//joPP/ww8fHxGW5r7dq1NGnShIiICNq0aUOzZs1wc0v5Yxk4cCAvv/wy5cuXp1OnTsTHxzN58mSaN2/OxYsXM3SfadOm8eabb3LhwgXq169Px44dKV68OF988QUNGjRg586daV7bq1cvxowZQ/ny5WnTpg0XL17knXfeoV+/fk51//rrLxo1asSoUaM4d+4c//jHP2jUqBFbtmyhS5cujB8/PsM/m1tNdLRJixZ1Xe7llbJeTrRVo4aZ0q5b1+xedmw+sSwTIN51V/r3FhERyTFWAbRw4UIrOjo6Rd6FCxes9u3bW4A1a9aspPzVq1dbgBUSEpKi/qhRoyzAAqz//Oc/Lu9TqVIlC7CKFy9u/fbbb0n5Fy9etB588EELsIYMGeKy3RkzZqTI37hxo7V//36ne3z22WcWYLVs2dKpzNG/GjVqWIcOHUrKP3jwoFWyZEkLcGqzXbt2FmC98sorVlxcXFL+gQMHrCpVqlju7u7Wjh07XD5vckFBQUn3v/4JskwIkzuf7Pb006bdESNcl+/da8qrV0+/rdatTd1p01yXr1xpytu0SZm/apVllShhWTVrWtbPP1vWhQuWdeiQ6ZObm7n3mTOZeiwREZFsUyBHDDt37oyXY0gmkbe3N5MmTQJg8eLFGW7rvvvu4+WXX75hnQEDBnD//fcn/XexYsWYMmUKNpuN6dOnpzmlm1xQUBBVXByQ989//pPGjRuzZs0aoqKiXF47efJkAgICkv77rrvuonfv3gCsW7cuKX/79u18//33PPDAA4wfP57ChQsnlVWuXJkJEyYQHx/PtGnT0uxnbGwsFy5cyNSoa0Hh7W3SmBjX5ZcumTT5buXsbOvcOejeHa5dM5tSWrY07QQEwFtvwfPPmyN0/vvf9O8vIiKSEwqlXyV/2rdvH9999x379+8nJiaGhIQErMQTkfft25fhdjp06IAtnW2ijz/+uFNejRo1qF27Ntu3b2fnzp00aNAg3XtFR0ezdOlStm/fztmzZ7l69SoAJ06cwLIsDhw4QL1UuxkKFy5MixYtnNqqXr160rUOP/74IwCdOnVy+UxNmjQBIOwG56GMGzeON998M91nKYgqVjRpWm84ceQ76mV3W8uWmcOsW7c26wxT69HDHKezZk369xcREckJBS4wtCyLl156iUmTJiUFgqlldN0fQMUMRAGVKlVymR8QEMD27ds5fvx4um38/PPPPP7445w6dSrNOq767efnh7u7u1N+scShqOSjlREREQC8+uqrvPrqq2ne5/Tp02mWDRs2jKFDh9K6desbBpAFUe3aJt261XW5I79WrZxpyxEsFi/u+hpH/tmz6d9fREQkJxS4wHDevHlMnDiR8uXL89577xEcHEzp0qUpXLgwcXFx2O32NANGVzw9PW+6Lxm9T3R0ND169ODMmTOMHDmSnj17UqlSJYoUKYLNZuOJJ55g7ty5LttLbzQzOcf0b9OmTalcuXKa9XxvsO3Vbrdjt9tdBqMFXePG5jiYAwfMQdOpzzJcsMCk7dun31bbtuZMwnXr4O+/zY5ih9hYcxaimxu0a3c9/847TbptmznjMPWP2BGHJ1s1ICIikqsKXGC4cOFCAKZOnUr7VP+CHzx4MEfuGRkZSc2aNZ3yDyeeReLv73/D69etW8eZM2d49NFHGTNmjFN5dvW7fOIZKd26dWPQoEHZ0uatxMMDBgyAt9826cqV13cPT5wIO3dCkyaQfFXAlCnm06ULJD8j3c8PevY0Zw8+95x5v7Hj7SevvGJer9e79/VgEEwwabfDoUMwciT83/+Z4BHMK/XeeMN8dxy0LSIiktsK3OaTc+fOAVChQgWnsq+//jpH7jlv3jynvD179rB9+3a8vb2plc7c4436vH//framNR+ZSa1btwa47c8rvJERI6BRI/O+5GrVzDmCQUHmFXWlSsGMGSnrnz5tgrZkSzmTvPeeeYvKN99AYCA8/jjUrAkffGDyE/dCJfHzMxtLbDYTZFarZoLAli3N1PTx4/Dww5BLr/UWERFxUuACQ8emi08++STF1Ou6det49913c+SeU6ZMYdu2bUn/HRMTw8CBA7Esi759+2K32zPU52+//TbFGsPz58/Tr1+/pE0oWRUUFESrVq1YvXo1Q4YMITrVIXoJCQmsXLmS9evXZ8v9CiJPT1i92ozYFS0KixZBRASEhJgp3qpVM96Wr6+Z/h04EOLiYOFCiIoyo5GbN7s+qHrAAPj5Z/N2k0uXYPFisx6xbl3z/uYlS1K+d1lERCQ3Fbh/ggYNGsTMmTP56KOPWLNmDbVq1eLYsWOsX7+eF198kf/mwFkfvXv3plGjRjz44IP4+Piwdu1aTp48yb333puhHbz169fnH//4Bz/++CPVq1dP2mW8Zs0afH196dSpU6aO2LmR2bNn06ZNG9577z0+//xz6tSpQ+nSpTl27Bjh4eGcOnWKSZMmJe1Qvh0VKQJjxphPekaPNp+0lCxpRgg/+CDj92/RwnxERETymwI5YhgWFkaHDh04ffo0S5YsITo6mo8//jjHRgwnT57MuHHjiIyMZPHixdhsNp5//nnWrVuHj49PhtpYvHgxr7/+OqVLl+b7779ny5YtPP7444SGhlKiRIls62vZsmUJDQ1l4sSJVKtWjbCwMBYtWsTRo0epW7cuH374YdIZiCIiIiLJ2azMbOG9zQQEBBAZGZmpXc63iuDgYEJDQ1PlBgEbc60Pt+GPXUREJE8VuBFDEREREckZCgxFREREBFBgKCIiIiKJCtyu5NzkeMWciIiIyO1AI4aSYUFBZkNIbn1EREQkdykwFBERERFAgaGIiIiIJFJgKCIiIiKAAkMRERERSaTAUEREREQABYYiIiIikkiBoYiIiIgAOuBaMiE0FGy2jNXVOYQiIiIFj0YMRURERARQYCgiIiIiiRQYioiIiAigwFAKmCtXYNQoqF4dPD3B3x/69oWjRzPf1vnzMHgwVKoEdrtJX3jB5LsycyY8/jjUqAF33AEeHub+3brBhg1ZeiwREZF8wWZZ2iYgzoKDgwkNDU2VGwRszND1OfG36soVaNXKBGF+ftC0KUREwObNULo0bNwIVapkrK0zZyA4GPbtg8qVoX59+OMP86la1Wy0KVUq5TX168OOHVCzJpQvbwLT8HDYudNsyvnkE3j66Wx/bBERkVyjEcNcMnPmTGw2G6NHj87UdTabjYCAgBR5ERER2Gw2WrRokW39KwjGjjVBYXAw7N0L8+bBpk0wYQKcOmVGDjNqyBATFHbtaoK7efNg1y4YOBD274ehQ52v+fBDOHsWtm6FJUvg669NoLh4Mbi7w6BBplxERKSgyneB4Zo1a7DZbPTp0yevuyL5yNWrMHmy+f7hh1Cs2PWyoUOhVi1Yuxa2bEm/rZMnYfZsKFwYPvoICiU7tOndd83o4+zZ8NdfKa9r1Ai8vZ3b69gRWrSAy5fNSKOIiEhBle8CQ0lp9+7drFq1Kq+7kefWrzdr/6pUgbp1ncu7dTPp0qXpt/X995CQAM2aQdmyKcvsdujQAeLjTb2Mcnc3qYdHxq8RERHJbxQY5nOBgYFUyejCuVvYjh0mrVfPdbkj31Evt9oCWLUKVq82G1IaNszYNSIiIvlRpgPD5cuX07dvX2rUqEHx4sXx8vKidu3ajB07ltjY2BR1R48ejc1mY+bMmS7bCggIwJbsVRp9+vShZcuWAMyaNQubzZb0Sb02b+PGjXTq1InSpUtjt9sJCAjgueee4/jx4073Sb6+78CBA/To0QNfX1+KFy9Ou3bt+PPPPwG4du0aY8eOpXr16nh6elK1alU++uijNH8WmelDcnv37uXRRx+lVKlSeHl50bhxY7777juXdV2tMUzP+vXr6dKlC2XKlEnq16BBgzh16lSm2slPDh82afnyrssd+Y56OdnWjBnQp4/ZodygAbRubTaizJkDxYunf38REZH8KtOvxOvXrx8xMTHce++91KxZkwsXLrB582Zef/11Vq1axcqVK3F3zKtlUpMmTTh58iQrVqygSpUqNGnSJKmsTp06Sd+//PJL+vTpQ0JCAg888AAVKlRg69atTJ06lW+//ZY1a9YQGBjo1P6hQ4do2LAhJUqUoHnz5uzbt48ffviBLVu2sHPnTvr378/PP/9McHAwlStXZvXq1Tz//PMULlyYZ555JkVbN9uHAwcO0LBhQ+644w7atGnD8ePHWbduHe3bt+ezzz7L8trKDz74gMGDB+Pm5kbDhg0pV64cu3btYvLkySxbtoxff/0VPz+/LN0jL0RHm7RoUdflXl4p6+VkW7/+CrNmXf/vkiXh00/hoYfSv7eIiEi+ZmXSwoULrejo6BR5Fy5csNq3b28B1qxZs5LyR40aZQHWjBkzXLZVqVIlK3UXVq9ebQFWSEiIy2sOHz5sFSlSxCpUqJC1dOnSpPz4+Hhr8ODBFmA1aNAgxTUzZsywAAuwhg4dasXHx1uWZVkJCQlWnz59LMC65557rPvuu886cuRI0nU//fSTBViVKlXK1j489dRT1tWrV5PKli5darm7u1teXl7W8ePHU1zn6v6HDh2yAKt58+Yp8jdu3Gi5ublZlSpVsnbs2JGUn5CQYI0ZM8YCrG7durn8uTpcuXLFioqKsho0aJDU3+ufIMscRJP+J7s9/bRpd8QI1+V795ry6tXTb6t1a1N32jTX5StXmvI2bW7czsWLlvXbb5bVo4ep/8wz6d9bREQkP8v0VHLnzp3xcgypJPL29mbSpEkALF68+CbC04ybNm0aly9fpmfPnrRv3z4p383NjfHjx+Pv709YWJiLM/igSpUq/Oc//8HNzTy2zWZjaOK5JH/++ScffPAB5ZPNL7Zq1Yq6desSGRlJREREtvShWLFivPfeexRKthW2ffv2dOvWjZiYmDSn3TNi/PjxJCQk8Mknn1CrVq2kfJvNxogRI6hbty7ffvstp0+fTrONcePG4ePjQ1hY2E33Iyc4dgPHxLguv3TJpMl3K+d0W8WKwf33m6NuOnY0o4bffJP+/UVERPKrm9p8sm/fPt5//30GDhxI37596dOnD2+99VZSWU5at24dAL169XIqs9vtdO/ePUW95Fq0aJEiIAOoXLkyAB4eHjRv3tzpGsfGjxMnTmRLH9q0aUPJkiWd8nv27AmY9YE3IyEhgVWrVuHt7U2rVq2cym02G40bNyYhIYEtNzjTZdiwYURFRdGgQYOb6kdOqVjRpGm94cSR76iXW2059O5t0hz+/0UiIiI5KlNrDC3L4qWXXmLSpElYabza4uLFi9nSsbQ4NnaktSHDke9qA0i5cuWc8hyjn3feeWfSSKKr8uQba7LSh0qVKmX6mow4c+YM0YmL4lIHv6ndaMTQbrdjt9tvep1oTqld26Rbt7oud+QnGyjNlbYcfH1NWoD394iIiGQuMJw3bx4TJ06kfPnyvPfeewQHB1O6dGkKFy5MXFwcdrs9zYDRlYSEhEx32CH5buaMlt/omvTay64+pCUzPzdX4uPjATOt37Vr1xvWTSs4zc8aNwYfHzhwALZtcz7LcMECkyab2U9T27bg5gbr1sHff0OZMtfLYmPNWYhubtCuXcb798svJtXJQiIiUpBlKjBcuHAhAFOnTk2xtg7g4MGDTvU9Ek/7jXaxvTM+Pp6TJ09m5vYA+Pv7Ex4ezqFDh6hevbpTeWRkJECO7rzNSh8cZakdTjwbxd/f/6b65Ovri91up3Dhwllap5hfeXjAgAHw9tsmXbny+u7hiRPN+4qbNDHHxzhMmWI+XbrAuHHX8/38oGdP83aT556Dr766/vaTV14xo369e8Odd16/5s8/zW7k3r2hSJHr+ZZl1hi+8455X3JISM79DERERHJaptYYnjt3DoAKFSo4lX399ddOeY7AaO/evU5lP//8M1evXnXKdwST165dc9mHpk2bAjB79mynsri4OObPn5+iXk7ISh9WrlzJ+fPnnfLnzp0LQOPGjW+qT4UKFaJFixacPXuWtWvX3lQb+d2IEea1dBs2QLVq8NhjEBQEL74IpUqZ8wWTO33avAc52fLQJO+9Z0b3vvkGAgPNmYQ1a8IHH5j8xL1USf7+G/71LxMstmoFvXrBI49A5comyIyNNe9szmdLM0VERDIlU4GhY3Tsk08+STH1uW7dOt59912n+o7NHF9++WWKXb0HDx5k4MCBLu/hGDELDw93Wd6vXz+KFCnC3LlzWb58eVJ+QkICw4cP59ixYzRo0ICgoKDMPFqmZKUP0dHRDB06NEXg+9133zF//nyKFi1KSBaGnIYPH46bmxshISEuN7EcP36cDz/88Kbbz2uenuYNIyNHmjMIFy2CiAgzSrdtG1StmvG2fH0hLAwGDoS4OFi4EKKizGjk5s3X1ww63HsvjBkD9evD3r0moFy92rxvuW9f09aQIdn6uCIiIrkvM2fbhIeHW15eXknn/j3++ONW06ZNLZvNZr300ksuz9x76qmnLMDy8fGxOnToYD344INW0aJFre7du7s8x9CyLKtWrVpJZwH26dPH6tevn7V48eKk8i+++MJyd3e3bDab1aRJE6tnz57W3XffbQFW2bJlrd27d6doz3GG4KhRo1w+l6t+O4SEhFiAtXr16hT5N9uHXr16WT4+PtZdd91lPf7441bz5s0tm81mAdann36aob6ldY6hZVnW5MmTLXd3dwuwatWqZT366KPWI488Yt13332Wu7u75ePj4/I5UwsKCspX5xiKiIhIzsv0iGFYWBgdOnTg9OnTLFmyhOjoaD7++GOXI4YAn376Ka+99hrFixdnxYoVREZGMnz48KSpU1e++eYbOnfuzMGDB/n888+ZPn06W5NtIe3duzdr166lffv27N69mwULFnD58mX+/e9/s2XLFpdvHMluN9uHqlWrsnHjRmrVqsWKFSvYvHkzQUFBLF26lKeffjrL/RowYACbNm2iV69enDt3jiVLlrBx40bc3Nzo379/jp8zKSIiIgWXzbKyuB1WbknBwcEuDugOAjZm6Hr9rRIRESl4buqAaxERERG59SgwFBERERFAgaGIiIiIJFJgKBkWFJTRPcl53VMRERG5GQoMRURERARQYCgiIiIiiRQYioiIiAigwFBEREREEikwFBERERFAgaGIiIiIJFJgKCIiIiKAAkMRERERSVQorzsgBUdoKNhsed2LvKODu0VE5FanEUMRERERARQYioiIiEgiBYYieezKFRg1CqpXB09P8PeHvn3h6NHMtfPLL/Dmm/DII1C6tJn2DwxMu35EhKmT3qdv3yw9noiIFCBaYyiSh65cgVatYMMG8PODTp1MwDZjBixbBhs3QpUqGWvrhRdgx46M37tYMQgJSbt83jzTv6ZNM96miIgUbAoMc5jNxW6NwoULU7ZsWZo1a8Zrr71GzZo1neq0aNGCX375hUOHDhEQEJBt/QkICCAyMhJLOynyhbFjTVAYHAwrV5pgDWDiRHjxRTNa98svGWurTRvo0QMaNABfX6hX78b1fX1h5kzXZXv2wKxZUKQIPPpohh9HREQKOAWGuSQk2dBMVFQUW7ZsYc6cOSxYsIAffviBli1b5mHvJC9cvQqTJ5vvH354PSgEGDrUBGZr18KWLXD//em39847179HRGStb198YdJOnaB48ay1JSIiBYcCw1wyM9XQzNWrV+nXrx9ffPEFL7zwAjt37kxR/vnnn3Pp0iXKlSuXi72U3LR+PZw/b6aK69Z1Lu/WDXbuhKVLMxYYZhfLgjlzzPcnn8y9+4qISN7T5pM8UrhwYUaPHg3A77//zvnz51OUV6xYkcDAQAoXLpwHvZPc4FgPmNaUryM/M+sGs8P69WbEsXRpMz0tIiK3DwWGeahs2bJJ369du5airEWLFthsNiJSzQnabDYCAgKIi4tjzJgxBAYGYrfb6dy5c4q2xo0bR7Vq1fD09KRy5cqMHDmSuLi4HH0eyZzDh01avrzrcke+o15u+fJLk/bsCYU0pyAiclvR/+znoS1btgDg6+uLr69vhq9LSEigc+fOrF27lubNm1OrVi1KlSqVVN6zZ08WLFhAsWLFaNu2LZZlMXHiRLZt26ZNJ/lIdLRJixZ1Xe7llbJeboiLg/nzzXdNI4uI3H4UGOaBqKgoNm/ezIABAwAYPnx4pq4/cuQIdrud8PBwpzWIc+fOZcGCBVSuXJm1a9cmlR86dIhmzZpxNLOH40mOccToab1mMC9i+GXL4Nw5c/5h/fq5f38REclbCgxziatja8qUKcOcOXPo2bNnptsbN26cy40pU6dOBeCtt95KUX7XXXcxcuRInn322Ru2GxsbS2xsLPHx8Znuk2SOt7dJY2Jcl1+6ZNLku5VzmmMaWaOFIiK3JwWGuST5cTWxsbFERkayadMmXnnlFfz9/WnevHmG27LZbHTo0MEp/+rVq2zatAk3Nze6devmVN6zZ890A8Nx48bx5ptvZrgvcvMqVjRpWoO4jnxHvZx2/jx8950ZwezVK3fuKSIi+YsCw1yS+rgagG3bttG8eXMeeughdu/ezV133ZWhtsqUKYPdbnfKP3PmDHFxcfj5+eHh4eFU7u3tTYkSJZx2QCc3bNgwhg4dSuvWrQkLC8tQf+Tm1K5t0q1bXZc78mvVyp3+fP01xMZCs2ZQqVLu3FNERPIX7UrOQ3Xr1uXZZ58lNjaWKVOmZPg6T09Pl/mOjSWupq0zym63U7x4cdzd3W+6DcmYxo3BxwcOHIBt25zLFywwafv2udMfTSOLiIgCwzzmGCUMDw/Pclu+vr54eHhw8uRJl0fTXLx48YajhZK7PDwgcf8RAwakXGs4caI53LpJE/OKO4cpU8zGkGHDsrcvkZHm/EK7Hbp3z962RUSk4FBgmMcOHjwIgJfjbJIsKFy4MA0bNiQhIYFvvvnGqfyrr77K8j0ke40YAY0amfclV6sGjz0GQUHmPcmlSsGMGSnrnz4N4eFw4oRzW9OmmWuDgqBLF5MXGXk9Lygo7Wnr2bPNLuiOHc0opoiI3J4UGOahbdu28cknnwDw8MMPZ0ubjs0lb7zxBieSRQ+RkZG89dZb2XIPyT6enrB6NYwcac4zXLTIvHUkJMRML1etmvG2jh6FTZvMZ/t2k3flyvW8TZvgwgXX186ebdLevbP0OCIiUsDZLJ14nKMc6/2S70qOi4sjMjKS0NBQEhIS6NChA4sWLcLN7Xqc3qJFC3755RcOHTpEQEBAivYqVark9EYUB8uyePTRR1m4cCHe3t60atUKy7L46aefaN68Obt27eLw4cPpHnQdHBxMaGhoqtwgYGNmHv+Wot8UERG51WlXci6ZNWtW0nc3NzdKlChBs2bNePLJJ+nTp0839UnrAAAgAElEQVSKoDArbDYb8+bN491332X69Ol89913+Pn5MXDgQEaPHs3dd9+dLfcRERGRW49GDMUljRg602+KiIjc6rTGUEREREQABYYiIiIikkiBoYiIiIgA2nwimRAUBBtv3yWGIiIitzyNGIqIiIgIoMBQRERERBIpMBQRERERQIGhiIiIiCRSYCgiIiIigAJDEREREUmkwFBEREREAAWGIiIiIpJIB1xLhoWGgs2W17249VlWXvdARERuVxoxFBERERFAgaGIiIiIJFJgKCIiIiKAAkOR28aVKzBqFFSvDp6e4O8PffvC0aMZb+P8eZgzB554Au65B7y8wNsbGjWC99+Hq1cz1k5cnLneZjN9ERGR/EGBocht4MoVaNUKxoyB6Gjo1AkqVIAZM6BePThwIGPt/Pe/0KsXzJsHRYtChw7QsCHs2AGDB8ODD8KlS+m3M3Ys7NmTtWcSEZHsp8Awj8XExDBp0iRatmxJ2bJl8fDwoGTJkgQHB/PGG29w+PDhvO6i3ALGjoUNGyA4GPbuNYHdpk0wYQKcOmVGDjOiWDEYPhwOH4bffoOvvoJVq+D336FiRVi/Hv7v/27cxu7dMG4cPPNM1p9LRESyl82ydDhGXgkNDaVr166cOHGCokWLEhQURNmyZYmKiiIsLIxTp05ht9tZtmwZrVu3vql7BAQEEBkZSWb/mIODgwkNDU2VGwRsvKl+SMZl92/k1atQpoyZBt66FerWTVleuzbs3GkCvfvvv/n7zJ1rppgDAuDQIdd1LAuaNTPB6Z49cMcdYLebEU0REcl7Oscwj+zcuZMHH3yQy5cv8+qrrzJy5Ei8vLySyhMSEli0aBGvvPIKRzOzCEwklfXrTVBYpYpzUAjQrZsJDJcuzVpgWLu2SY8fT7vOxx+b/nzxBZQsefP3EhGRnKHAMA9YlkXv3r25fPkyo0ePZtSoUU513Nzc6Nq1K61ateLIkSN50Eu5VezYYdJ69VyXO/Id9W7WwYMmvfNO1+UnTsBrr5l1iL17Z+1eIiKSM7TGMA+sWLGC33//nfLly/P666/fsK6Pjw/33XcfACdOnOCdd96hefPmlCtXDg8PD+688066du1KWFhYiuvWrFmDzWYjMjISAJvNlvQJCAjIkeeS/MmxTLV8edfljvysLmd9/32TdurkunzAADNlPHVq1u4jIiI5RyOGeWD58uUAdO/enUKFMv5HsHjxYl599VWqVq1KzZo1KV68OPv372fhwoUsW7aMZcuW0aZNGwDuvPNOQkJCWLBgATExMYSEhCS14+vrm70PJPladLRJixZ1Xe5YweCodzP+9z/46ScoUcKMCqa2eDF8++3143JERCR/UmCYB7Zt2wZAvbTm9tLQuHFjduzYQa1atVLkr1ixgo4dO/Lcc8+xb98+bDYbgYGBzJw5kzVr1hATE8PMmTMzdI/Y2FhiY2OJj4/PVN8k/3JsZknrPddZ3ezyyy/wwgum/c8+M+cjJnfxohktrFYNhg3L2r1ERCRnaSo5D5w5cwaA0qVLZ+q6mjVrOgWFAA899BDdu3fnwIED7Nq1K0t9GzduHD4+Pk5T01JweXubNCbGdbnj3MFixTLf9s6d0LmzObD6/fehSxfnOsOHm0O0p041O5BFRCT/0ohhHsjKCUGxsbH88MMPbN68mVOnThEXFwfA77//DsC+ffuoWbPmTbc/bNgwhg4dSuvWrRUc3iIqVjRpWpvbHfmOehl14AA89JDZ8Tx6NAwc6Lre0qXm7SZvvWU+qcXFQYsW5vu0aVC1aub6ISIi2UeBYR7w9fUlPDycU6dOZeq633//nY4dOxIREZFmnYsXL2apb3a7Hbvdjru7e5bakfzDcYzM1q2uyx35Lgaj03T8OPzjH3DypJlGdrGxPoUrV8yUsyuWdb0sK+scRUQk6zSVnAfq1KkDwNa0/qV2wbIsevToQUREBP3792f79u1cuHCBhIQELMtiWOLiLZ1XLqk1bgw+PmaEL3F5awoLFpi0ffuMtXfunBkpPHQI/vlPmDTpxvUjIkzw5+oDZnrZ8d+JvxoiIpJHFBjmgUceeQSA+fPnc+3atQxds2fPHvbs2UP9+vWZOnUqtWvXxtvbG1vijoKDjkPkRFLx8DCbP8CkydcaTpxo1gk2aQINGlzPnzIFAgOdN4tcugQPPwy7dkGPHvDpp2lvahERkYJHU8l5oG3bttx777388ccfvP322y4PuHa4cOECR44cISoqCoDyLg6jO3fuHD/++KPL6z08PAC4du1apo7GkVvLiBHmOJkNG8zu4KZNITLSvC+5VCmYMSNl/dOnITzcHEqd3OuvQ2gouLtDoULQr5/r+2VwE7yIiOQzGjHMAzabjS+//BJPT09Gjx7NsGHDiEm1ZdSyLJYsWUL9+vUJCwujatWquLm58fPPP7Nv376keleuXKF///6cPXvW5b38E88OCQ8Pz7kHknzP0xNWr4aRI815hosWmSnekBAzvZzRDR/nzpk0Ph7mzIFZs1x/RESkYLJZWpSWZ3799VceffRR/vrrL4oWLUpwcDBly5YlKiqK3377jb/++gtPT0+WLVtGq1at+Ne//sWnn35KkSJFePDBBylSpAjr1q0jPj6e9u3bM3PmTGbMmEGfPn2S7jFx4kRefPFFypYtS8uWLfHy8sLX15fx48ffsG/BwcGEhoamyg0CNmb7z0FS0m+kiIjkFc0t5qHGjRuzf/9+Pv74Y5YuXcrOnTs5d+4cxYoV4+6776Z///48/fTTSdPHU6dOJTAwkOnTp7Nq1Sp8fHxo3bo1b7/9NjNSzwUmGjRoEOfOnWPu3Ll88803XL16lUqVKqUbGIqIiMjtRyOG4pJGDPOOfiNFRCSvaI2hiIiIiAAKDEVEREQkkQJDEREREQG0+UQyISgINmqJoYiIyC1LI4YiIiIiAigwFBEREZFECgxFREREBFBgKCIiIiKJFBiKiIiICKDAUEREREQSKTAUEREREUCBoYiIiIgk0gHXkmGhoWCz5fx9LCvn7yEiIiLONGIoIiIiIoACQxERERFJpMBQbitXrsCoUVC9Onh6gr8/9O0LR49mvq3z52HwYKhUCex2k77wgslPLSLCTMOn9+nbN8uPKCIictO0xlBuG1euQKtWsGED+PlBp04mYJsxA5Ytg40boUqVjLV15gwEB8O+fVC5MnTuDH/8AR98AN99Z9Zjlip1vX6xYhASknZ78+aZ/jVtmqVHFBERyRIFhllgS7UTo1ChQvj4+ODn58f9999Phw4d6NSpE4UK6cecH4wda4LC4GBYudIEawATJ8KLL5rRul9+yVhbQ4aYoLBrVxPUOf6IBw2CyZNh6FCYNet6fV9fmDnTdVt79pi6RYrAo4/e9OOJiIhkmc2ytAf0ZjkCw5DEoaCEhASioqLYu3cv4eHhWJZF1apVmT17Ng0bNszLrmZacHAwoaGhqXKDgI05fu+c+Bt59SqUKWOmebduhbp1U5bXrg07d8Jvv8H999+4rZMnoVw5cHeHI0egbNnrZbGxUKECnD0Lx46lLEvL66+boPXxx2Hu3Mw/m4iISHbRGsNsMHPmTGbOnMnnn3/O4sWL2b17N/v27aNHjx7s37+fli1bsn379rzu5m1t/XoTFFap4hwUAnTrZtKlS9Nv6/vvISEBmjVzDvzsdujQAeLjTb30WBbMmWO+P/lk+vVFRERykgLDHFKlShXmzZtHv379uHTpEn21qyBP7dhh0nr1XJc78h31cqut9evNOsfSpaFNm/Tri4iI5CQFhjlswoQJeHl5sW3bNtavX+9UHhERwbPPPktAQAB2u53SpUvTrVs3du7cmWab69evp0uXLpQpUwa73U5AQACDBg3i1KlTTnX79OmDzWZjzZo1rFixgpYtW1KiRAlsNhvnXW2fvUUdPmzS8uVdlzvyHfVyq60vvzRpz57X1ymKiIjkFQWGOczHx4d27doBsHr16hRl69evp3bt2nzyyScUK1aMjh07Uq1aNb799luCgoKc6gN88MEHNGvWjKVLl1K1alU6duxIkSJFmDx5Mo0aNeLEiRMu+zFnzhzatWtHTEwM7dq1o0GDBk6bZ25l0dEmLVrUdbmXV8p6udFWXBzMn2++axpZRETyAwWGuaBOnToA7N69OynvwoULdO/encuXLzN//nx27drF/Pnz2bBhAytXriQ+Pp4nn3ySuLi4pGtCQ0MZMmQIFStWZOvWrWzYsIH58+fz559/MmbMGA4dOsSgQYNc9uHTTz9l7ty5bN68OSn18fFxqhcbG8uFCxeIj4/P5p9C3nJsaEkrFs7MhpfsamvZMjh3DgIDoX79jN9fREQkpygwzAW+vr4AnDt3Linvs88+4+TJk7z00kt0c+x8SNS6dWuee+45jh07xrJly5Lyx48fT0JCAp988gm1atVKyrfZbIwYMYK6devy7bffcvr0aac+PPLIIzz22GPp9nXcuHH4+PgQFhaW6efMz7y9TRoT47r80iWTOo6wyY22HNPIGi0UEZH8QoFhLnCcCJR86vbHH38EoHPnzi6vadKkCUBSgJaQkMCqVavw9vamVatWTvVtNhuNGzcmISGBLVu2OJV37NgxQ30dNmwYUVFRNGjQIEP1C4qKFU2a1htOHPmOejnd1vnz5iBsmw169Ur/niIiIrlBy91zgWME74477kjKi4iIAKBRo0YZuvbMmTNEJy5aS+/AbFcjhhUzEvEAdrsdu92Ou7t7huoXFLVrm3TrVtfljvxkA7E52tbXX5szD5s1M6/SExERyQ8UGOYCxxmG99xzT1KeYw1f9+7dKZrWLgauB46O+t7e3nTt2vWG96vkItLw9PTMXKdvMY0bg48PHDgA27Y5n2W4YIFJ27dPv622bcHNDdatg7//NgdnO8TGmrMQ3dwgcc+RS5pGFhGR/EiBYQ6Liorihx9+AKBly5ZJ+eXLlyc8PJwRI0akWC+YFl9fX+x2O4ULF2ZmWu9WkzR5eMCAAfD22yZdufL67uGJE81bT5o0geQz6FOmmE+XLjBu3PV8Pz9zvMzs2fDcc/DVV9ePmnnlFTh1Cnr3hjvvdN2XyEhzfqHdDt2758zzioiI3AytMcxhL774IjExMTRo0IDg4OCk/NatWwOwaNGiDLVTqFAhWrRowdmzZ1m7dm2O9PVWN2IENGpk3pdcrRo89hgEBZn3JJcqBTNmpKx/+jSEh4OrE4Dee8+8ReWbb8yu4scfh5o14YMPTP6kSWn3Y/Zss3O5Y0cziikiIpJfKDDMIQcPHuSxxx5j+vTpeHl5MX369BTlzz77LKVLl2bs2LHMmDGD1K+sjomJ4fPPP+dosh0Ow4cPx83NjZCQEJeHZR8/fpwPP/wwZx7oFuDpCatXw8iR5gzCRYvMW0dCQsz0ctWqGW/L1xfCwmDgQHMe4cKFEBVlRiM3bzblaZk926S9e2fpcURERLKdzUodkUiGOXYZh4SEAGbn8IULF9i7dy979uzBsiyqVavGnDlzqO/ioLpff/2Vjh07cvbsWSpVqsR9992H3W7n8OHD7N69m5iYGLZt25Z0DiLAlClTGDx4MPHx8dSqVYtq1apx5coVIiMj2b17N8WKFUvxRpM+ffowa9YsVq9eTYsWLTL8bMHBwYSGhqbKDQI2ZriNm6W/kSIiInlDawyzwaxZswAz3Vu8eHH8/f156qmn6NixIx07dkxzF3Hjxo35/fffmThxIsuXL+fnn3/G3d0df39/2rdvT9euXVNsWAEYMGAAwcHBTJo0ibVr17JkyRK8vb0pX748/fv3p7sWrYmIiMhN0oihuKQRQxERkduP1hiKiIiICKDAUEREREQSKTAUEREREUCBoWRCUJBZ/5fTHxEREckbCgxFREREBFBgKCIiIiKJFBiKiIiICKDAUEREREQSKTAUEREREUCBoYiIiIgkUmAoIiIiIoACQxERERFJVCivOyAFR2go2Gx53YvcpQO3RUTkdqIRQxEREREBFBiKiIiISCIFhiIiIiICKDAUyRNXrsCoUVC9Onh6gr8/9O0LR49mrp1ffoE334RHHoHSpc0a0MDAjF174QK88Qbcdx94eYGPj/n+/PMQHZ35ZxIRkYLPZllaXi/OgoODCQ0NTZUbBGzMi+7kmZz47bhyBVq1gg0bwM8PmjaFiAjYvNkEdxs3QpUqGWurTh3YsSNl3t13w549N75u715o3RqOHIG77oL774fYWAgPN2VHjkD58jf1eCIiUoBpV3IOs6XaxluoUCF8fHzw8/Pj/vvvp0OHDnTq1IlChfRHcbsYO9YEhcHBsHIlFCtm8idOhBdfNCOHv/ySsbbatIEePaBBA/D1hXr10r8mJgbatoVjx+DDD+Hf/06523zXLrjjjsw/l4iIFHwaMcxhjsAwJCQEgISEBKKioti7dy/h4eFYlkXVqlWZPXs2DRs2zMuupqARQyO7fzuuXoUyZeD8edi6FerWTVleuzbs3Am//WZG8TIjIsKM/qU3YvjGG/DWWyYI/e9/M/0IIiJyC9MwVS6ZOXOmU96BAwcYPnw4X3/9NS1btuTXX3+lTp06ud85yTXr15ugsEoV56AQoFs3ExguXZr5wDAjEhJg2jQzQjhkSPa3LyIiBZsCwzxUpUoV5s2bh7e3N9OnT6dv375s3bo1r7slOcixHjCtKV9Hfup1g9nlzz/hxAm4914oVw5WrIAffzTTy1WqwKOPmlFHERG5PWlXcj4wYcIEvLy82LZtG+vXr3cq37hxI506daJ06dLY7XYCAgJ47rnnOH78uMv2rl69yttvv03VqlXx9PSkcuXKjB49mqtXrxIQEOC07lFyz+HDJk1rY4cj31Evu/3xh0nvugs6dzZrDSdMgP/9D15+2UxDv/9+ztxbRETyPwWG+YCPjw/t2rUDYPXq1SnKvvzyS5o2bcrSpUu5++676dq1K3a7nalTp1KvXj32pFpMZlkW3bt3Z8SIEfz999+0a9eOmjVrMmHCBLp3755rzySuOY6BKVrUdbmXV8p62e3cOZP+8AMsXw7vvAPHj5uNKOPHmzWVgwfD99/nzP1FRCR/U2CYTzjWFu7evTsp78iRI/zrX//CZrOxZMkS1q9fz9y5c9m9ezeDBw/mr7/+4qmnnkrRzuzZs1m8eDFVq1YlPDychQsXsnjxYv7880+2b99OZGTkDfsRGxvLhQsXiI+Pz/6HlKTNLGkN2ub0VjDHH+u1a2aE8OWXzZE5/v7w6qsmKAR4++2c7YeIiORPCgzzCV9fXwDOOYZ0gGnTpnH58mV69uxJ+/btk/Ld3NwYP348/v7+hIWFpdg9/L///Q+At956Cz8/v6T8ChUqMGrUqHT7MW7cOHx8fAgLC8vyM4kzb2+TxsS4Lr90yaSOI2xy6v5gjsVJzZEXGmrONRQRkduLAsN8wnFqUPL1f+vWrQOgV69eTvXtdnvS1LCj3tWrVwkLC8PNzY2uXbs6XZORqeRhw4YRFRVFgwYNMv8Qkq6KFU2a1htOHPmOetktIOD690qV0i6Pj4czZ3KmDyIikn8pMMwnTp8+DcAdyU4WdmwuCUj+r3kyjnxHvTNnzhAXF0fZsmXx8PBwql+sWDFKlix5w37Y7XaKFy+Ou7t7Zh9BMqB2bZOmtfnckV+rVs7cv1YtcPzRnj3rXJ48GMypUUsREcm/FBjmE9u3bwfgnnvucSpLbxdx6vIb1dd55nmrcWPzTuIDB2DbNufyBQtMmmzlQLYqUcK8gg8g1T4nANasMWmVKlC8eM70QURE8i8FhvlAVFQUP/zwAwAtW7ZMyvf39wfg0KFDLq9zbCRxrCUsVaoUhQsX5uTJk8TFxTnVj46O5vz589nad8kcDw8YMMB8HzAg5VrDiRPN4dZNmphX3DlMmQKBgTBsWPb04bXXTPr665D8r9aBAzBypPnev3/23EtERAoWBYb5wIsvvkhMTAwNGjQgODg4Kb9p4tDO7Nmzna6Ji4tj/vz5KeoVLlyYBg0akJCQwMKFC52uWeAYjpI8NWIENGpk3pdcrRo89hgEBZlX1JUqBTNmpKx/+jSEh5uDqVObNs1cGxQEXbqYvMjI63lBQc7T1g89ZO518KCZWm7b1uTVrm1eq9eund6KIiJyu1JgmIcOHjzIY489xvTp0/Hy8mL69Okpyvv160eRIkWYO3cuy5cvT8pPSEhg+PDhHDt2jAYNGhAUFJRU9uyzzwLwxhtvcPLkyaT8o0ePMmbMmBx+IskIT08zjTtypDnPcNEiE5CFhJjp5apVM97W0aOwaZP5JK5G4MqV63mbNsGFC87X/fe/MHeuCQx//RXWrYPq1c3h1kuWXF+HKCIitxebpUVnOcqx3i8kJAQwQd2FCxfYu3cve/bswbIsqlWrxpw5c6hfv77T9V9++SV9+vQhISGBxo0bU6FCBbZu3Up4eDhly5ZlzZo1BAYGJtW3LItOnTqxdOlSihcvTqtWrUhISGDVqlW0bNmSHTt2cOLECZdTzckFBwenOAbHCAI2ZunnUdDot0NERG4nCgxzWOqNIIUKFaJ48eL4+/tz//3307FjRzp27EihQmm/tnrDhg2MHz+eDRs2cOHCBfz8/HjkkUd4/fXXKVeunFP9uLg4/vOf/zBz5kyOHj2Kv78/vXv35vXXX6dEiRKULFmSE67mJZNRYGjot0NERG4nCgxvI5s2bSIoKIi2bdvyfTrvPFNgaOi3Q0REbidaY3gL+v3337l69WqKvIiICP79738D8MQTT+RFt0RERCSfS3v+Ugqsl19+md9++43atWtTpkwZjh49ym+//caVK1d4+OGH6d27d153UURERPIhBYa3IMdmld9//53169fj4eFBzZo1eeKJJ3j++efTPTBbREREbk9aYyguuVpjGBQUxMaNt9caQxERkduJ1hiKiIiICKDAUEREREQSKTAUEREREUCBoYiIiIgkUmAoIiIiIoACQxERERFJpMBQRERERAAdcC2ZEBoK+eFsbJ28KSIikjM0YigiIiIigAJDEREREUmkwFBEREREAAWGIkmuXIFRo6B6dfD0BH9/6NsXjh7NfFvnz8PgwVCpEtjtJn3hBZOflt27oVcv8PMz1wQEwMCBcPr0TT+SiIhIpigwFMEEha1awZgxEB0NnTpBhQowYwbUqwcHDmS8rTNnoGFDeP99KFQIOncGb2/44ANo0MCUp/bzz1C/PsyZAyVLQvv24OEBU6aY+x87ln3PKiIikhYFhtnIZrPd8NOiRYu87qKkYexY2LABgoNh716YNw82bYIJE+DUKTNymFFDhsC+fdC1K4SHm7Z27TKjf/v3w9ChKetfugRPPGHSUaPgzz/hm29gzx4z6njkCDz9dPY+r4iIiCs2y9LhH9nFlniWS0hIiMvywMBAXnvttdzs0k0LDg4mNDQ0VW4QsDEvupNCdv+NvXoVypQx07xbt0LduinLa9eGnTvht9/g/vtv3NbJk1CuHLi7m4CubNnrZbGxZhTy7FkzAugo+/JLePJJuPtuExS6uaW8pkoVU3/HDqhVK3ueWURExBWdY5gDZs6cmdddkExYv94EhVWqOAeFAN26mcBw6dL0A8Pvv4eEBGjZMmVQCGbdYIcO8Nlnpl6fPiZ/yxaTNmuWMih0XBMcDAsWwOLFCgxFRCRnaSpZbns7dpi0Xj3X5Y58R73sbismxqQlS7q+5o47Mn5/ERGRrFBgmEf279+PzWajdevWREVFMWTIEAICAihcuDAvvfRSUr2rV6/y3nvvUa9ePby8vPD29qZRo0Z8/PHHJCQkpNl29+7dueOOO/D29qZp06b8+OOP/PTTT9hsNp7WgrUUDh82afnyrssd+Y562d1W6dImjYx0fY0jPyIi/fuLiIhkhaaS89ilS5do2rQpx44do3nz5tSrV48SJUoAcO3aNTp06MCKFSvw8fGhTZs2JCQk8PPPP9O/f39++uknvv7666S1jQDh4eE88MADnD17lsDAQOrUqcOhQ4do27Ytzz33XF49Zr4WHW3SokVdl3t5payX3W01b242vyxfbo6m8fW9Xnb4MKxebb5fvJj+/UVERLJCgWEe27hxI02aNGHdunX4+PikKJswYQIrVqygTp06/Pjjj/gmRgzHjh2jZcuWLFiwgE8//ZR//etfSdc8++yznD17lsGDBzNx4sSkoHHGjBn0zcDW2tjYWGJjY4mPj8/Gp8zfHJtZ0noPdGY2u9xMW//4hzmq5rffoF07+OgjqFHDTB0/+6xZswjO6w9FRESym/6pyQFpHVdzPo3TjSdPnuwUFDryAd5///2koBCgXLly/Oc//wHggw8+SMrfs2cPv/zyC76+vowdOzbFSOI///lPHnjggXT7Pm7cOHx8fAgLC8vYw94CvL1N6ljrl9qlSyYtVixn2rLZ4NtvoWZNExw2bGjaadLE7HJ+4w1TL601iCIiItlFI4Y5IK3jajw8PJzyKlSoQJ06dZzyDx48yLFjxyhfvjzNmjVzKu/cuTPFihXjjz/+4Ny5c5QsWZINGzYA0L59e4oUKeJ0Tffu3ZPqpGXYsGEMHTqU1q1b3zbBYcWKJk3rDSeOfEe9nGirQgVzVM7ixfDrryaADAw0b0JZsMDUuffe9O8vIiKSFQoMc0BmjqupmEa0cfz4cQACAgJclttsNipVqsQff/zB8ePHKVmyZNI1FSpUyNS9krPb7djtdtzd3TPQ+1tD7dom3brVdbkjPyNHxWSlrUKF4NFHzSe5n34yqc5HFxGRnKap5Dzm6el5w3JbWovVblAnrWt0lrlrjRuDj4957d22bc7ljhG79u3Tb6ttW7MWcN06+PvvlGWxseYsRDc3s5YwI/btg2XLoFQp8yYVERGRnKTAMJ/y9/cH4NChQy7LLcvicOKZJ35+finSw2mcq3LkyJHs7uYtwcMDBgww3wcMSLk+cOJEc7h1kybmPccOU6aYqd5hw1K25RQ2BD0AAB4dSURBVOcHPXtCXBw89xxcu3a97JVXzOv1nngC7rwz5XV//GHe15zcgQPQpYtpa8IEcLE6QEREJFtpKjmfqly5MuXKlePo0aOsXbvWaZ3hkiVLuHjxIvfeey8lE3clODaXLF++nCtXrjiNRi5wDH2JkxEjzJTthg1QrRo0bWrOD9y0yYzWzZiRsv7p0+Y9yCdOOLf13nsQGmredxwYaHYc//GHeV9ylSowaZLzNe++C4sWmQOw77zTtPvrr+Z1fSNHQhrLVkVERLKVRgzzsQGJw1iDBw/mzJkzSfknTpzg1VdfBWDgwIFJ+TVq1KBp06acOnWKESNGpJg6/vzzz/n1119zqecFj6enOS9w5EhzBuGiReZA6ZAQM71ctWrG2/L1hbAwGDjQjPYtXAhRUWY0cvPmlOcUOnTuDEFBsHu3mbr+8094+GHTpzFjsu0xRUREbshmaeFZtnGs7cvIj3T//v1Uq1aNVq1a8ZNjd0Eq165d45FHHmHlypWUKFGCli1bYlkWq1at4uLFi3Tr1s3pgOvdu3fTuHFjzp07R40aNZIOuN68eTP9+/fno48+4t///jcfffTRDfsXHBxMaGhoqtwgYGO6z5bT9DdWREQkZ2jEMB8rVKgQy5YtY9KkSQQEBPDDDz+wcuVKAgMDmTp1Kl999ZXTRpMaNWoQGhpK165dOX78OEuWLMHNzY3ly5fTsGFDAEqVKpUXjyMiIiL5nEYMbyPPPPMM06ZNY8GCBTya+kyUVDRiKCIicvvRiOEt5vLly+zZs8cp/+uvv2bGjBmULFmSdhk9K0VERERuK9qVfIs5c+YMNWrUoEaNGlSrVg13d3d2797Nnj17cHd353//+x9FixbN626KiIhIPqQRw1vMHXfcwZAhQyhUqBBr165l6dKlnDt3ji5durB27Vp69OiR110UERGRfEojhreYokWLMnHixBxpOygINub9EkMREfn/9u49vKYr4eP49yTixCUTl0glSEIkVNMEQQV1GUZptVVvOqN0hl4800EUnVLqEmFQtIpqO63B02n71rSuqZZqaUqJuNWlb12LKDrENZhEK+f9Y52DOCdX58hlfp/nOc9O9tp77b3j/PGz1l5riXiIWgxFREREBFAwFBERERE7BUMRERERARQMRURERMROwVBEREREAAVDEREREbFTMBQRERERQMFQREREROw0wbUUWmoqWCzurdNmc299IiIiUnxqMRQRERERQMFQREREROwUDKXcysqC8eMhMhJ8fSE4GJ5+Gn76qeh1nT8PQ4dCaChYrWb7/PNmf34uXoRx4yAqCqpUAX9/8/OgQXDpUvGeS0RExFMsNpve8hJncXFxpKam3rK3NbDJrdfx1LcvKws6d4aNGyEoCO6/H44cgbQ0qFULNm2C8PDC1XXmDMTFwYED0KABtGgB339vPg0bmncva9Z0Pm//fujSBY4dg/r1ITYWsrNh3z5TduwY1K3r1scWERG5LWoxdMFisWApYJRFYmIiFouFxMTEO3NTUiSTJ5tQGBdnQtiiRbB5M7z6Kpw+bVoOC2vYMBMKe/UyoW7RItizBxIS4OBBGD7c+ZzLl6FbNzh+HObOhUOH4OOPYcUKU8fu3VCjhvueV0RExB0UDKXc+eUXmDPH/Dx3LlSteqNs+HCIjoZvvoFt2wqu6+ef4YMPwMcH3nwTKtw0jn/6dNP6+MEH8O9/5z7vlVfg8GETKgcOdB7NHRUFlSsX7/lEREQ8RcFQyp0NG8y7f+Hh0KyZc3l8vNkmJxdc1+efQ04OtG8Pd92Vu8xqhYcfhmvXzHEOOTkwb54Jg8OGFf85RERE7jTNYyjlzs6dZtu8uetyx37Hcbdb1/z5uev6v/+DkyfhnnugTh1YvRrWrDHdy+Hh8D//Y945FBERKW3UYugBV65cYeLEiURFRVGpUiX8/f1p3749H330kcvjw8LCsFgs2Gw25syZQ0xMDJUrV6Zp06bXj9m8eTOPPfYYoaGhWK1WateuTatWrRg1ahSXXAxv3bBhA4899hiBgYFYrVbCwsIYMmQIp0+f9thzlxbp6Wab18AOx37Hce6u6/vvzbZ+fejZ07xr+Oqr8Pbb8OKL0KgRzJpV8LVFRETuNAVDN8vMzKR9+/aMGzeOU6dO0aNHD9q2bUtaWhpPPPEEQ4cOzfPc5557jhdeeIHAwEAeeeQRGjRoAMDKlStp06YNycnJhIWF0atXL5o2bUpGRgZTp04lIyMjVz2zZ8+mffv2JCcn07BhQx555BEqVarEnDlzuO+++zh58qRH/wYlzZGT83qHr0qV3Me5u65z58x21SpYuRKmTYMTJ8xAlKlTzUjsoUNzdz+LiIiUBupKdrPRo0ezbds2unTpwtKlS6lqH/mwd+9eOnTowKxZs+jatSsPPvig07lLlixhx44d3HPPPbn2T58+HZvNRlpaGrGxsbnK0tLSqHnTXCmpqakMGzaMkJAQVqxYQXR0NAA2m41JkyYxbtw4hgwZwscff+zuRy81HFPg5DWwvChT5BSnrmvXzPbXX2HUKNNK6DByJGRkwIwZ8Le/Qffuhb8XERERT1OLYT4c09a4+kyYMMHp+MuXL/OPf/wDLy8v3nzzzeuhEKBx48aMGTMGMC16rowcOdIpFAKcOnUKf39/p1AI0KpVK/z8/K7/PnXqVHJycnjnnXeuh0LHs4wZM4ZmzZqxZMkSp1ZGh+zsbC5evMg1R7opgxx/jsuXXZdfuWK2N49WdmddN/1zuJwWx7EvNdXMaygiIlJaqMUwH/369cuz7LvvvmPnLaMXtm3bxn/+8x9at25NRESE0zl//OMfGTJkCN9++y02m81prsRHHnnE5bViY2N5//33eeaZZxg2bBhRUVEuj8vJyeGrr77Cz8+Pzp07O5VbLBbatm3Ljh072LZtGw888IDTMVOmTHEZesuSkBCzzWuFE8d+x3Huriss7MbPoaHO5zjKr10zk2cHBxd8HyIiIneCgmE+Fi5cmGdZYmKiUzA8ceIEYAaTuFKtWjX8/f25cOECFy9exN/fP1d5SB5JZfLkyezevZv58+czf/58AgICaNOmDT179qRPnz5YrVYAzpw5c30gSoUK+f/T5tViOGrUKIYPH06XLl3YsmVLvnWUVjExZrt9u+tyx/6bGlTdWld0NHh7m+B39qzzNDdnztz4uTCtliIiIneKgqEHFLRqSl7H+Pr6ujy2Xr16bN26lbVr1/Lpp5+SkpJCcnIyK1asYNq0aWzcuJHq1atf7/718/OjV69e+V4/1FVTFmC1WrFarXh7exf4DKVV27ZmTeJDh2DHDue5DD/5xGx79Ci4rm7dwMsL1q+HU6cgMPBGWXa2mQvRyyv3u4LVqpkl+L7+Gtatg969c9f59ddmGx4Ov/lNUZ9ORETEcxQM3SjY3id4+PBhl+UXLlzgwoULVKlSJdd7gYVRoUIFunbtSteuXQFIT0/nqaeeYu3atUydOpVXXnmFgIAArFYrPj4++bZ2lncVK8LgwWZwx+DB8MUXN0YPv/Ya7NoF7dpBy5Y3znnjDfN57DGYMuXG/qAgeOIJs7rJwIHw0Uc3Vj8ZMcIsr/fkk1C7du57eOklEwBffhnuu+/GvIWHDsHYsebn557zyOOLiIgUmwafuFFsbCyVKlUiLS2NAwcOOJW///77ALRr165QrYr5CQkJYeTIkQDs3r0bMOGxY8eOnD17lm+++ea26i/rxowxgWzjRoiIgD/8AVq3hhdegJo1YcGC3MdnZJg1jF3N5PP666Z1b/FiaNzYtADeey/Mnm32z5zpfM4DD5hr/fij6Vru1s3si4mBI0dMC6NWRRERkdJGwdCNqlSpwtNPP01OTg6DBg3i8k1DWffv38+kSZMASEhIKFK9M2fO5N+3LsYLrFq1Csj9buLo0aPx8vKiX79+bNiwwemcEydOMHfu3CJdvyzy9TXduGPHmjkIly0zgaxfP9O93LBh4esKCIAtWyAhAa5ehaVL4cIF0xqZlmbKXZkxA/73f00w/PZb0x0dGWkmt16xwryHKCIiUppYbLaizOr238HRmpffnyYxMZEJEyYwfvx4EhMTr+/PzMykU6dObNu2jcDAQDp06MDly5dZu3YtWVlZDBkyhFm3LHsRFhbG0aNH87xetWrVyMzMJCYmhoiICGw2G7t27WLfvn0EBASQmppKeHj49ePfeOMNhg4dyrVr14iOjiYiIoKsrCyOHj3KDz/8QNWqVTl//ny+f4O4uDhSU1Nv2dsa2JTveUWlb5+IiEjpoRZDN/Pz8yMlJYUJEyYQEBDAihUrWL9+PS1atODDDz90CoWFMWfOHHr37s2VK1f4/PPPWbVqFd7e3vz1r39l165duUIhwODBg9m8eTN9+/bl3LlzrFixgk2bNuHl5cVzzz3H8uXL3fW4IiIiUo6oxVBcUouhiIjIfx+1GIqIiIgIoGAoIiIiInYKhiIiIiICKBiKiIiIiJ2CoRRa69ZmsIg7PyIiIlJ6KBiKiIiICKBgKCIiIiJ2CoYiIiIiAigYioiIiIidgqGIiIiIAAqGIiIiImKnYCgiIiIiAFQo6RuQsiM1FSyW4p2rOQtFRERKP7UYioiIiAigYCgiIiIidgqGIiIiIgIoGEo5kJUF48dDZCT4+kJwMDz9NPz0U9HrOn8ehg6F0FCwWs32+efN/sK4ehWaNDHvYvr6Fv36IiIiJUnBUMq0rCzo3BmSkuDSJXj0UahXDxYsgObN4dChwtd15gy0agWzZkGFCtCzJ/j5wezZ0LKlKS/I5Mmwd2/xn0dERKQkKRh6yJo1a+jZsye1a9emYsWK1KxZkyZNmtC3b1/effddrl69ev1Yi8VCWFhYkerv2LEjFouFI0eOuPfGy5jJk2HjRoiLg/37YdEi2LwZXn0VTp82LYeFNWwYHDgAvXrBvn2mrj17ICEBDh6E4cPzP/+HH2DKFBgw4PaeSUREpKRYbDZNJOJu48ePJykpCYCoqCgiIyPx9vZm37597N69G5vNxsmTJ6lduzZggmFoaGiRQl7Hjh1JSUnh8OHDRQ6VhREXF0dqauote1sDm4pVnye+Zb/8AoGBppt3+3Zo1ix3eUwM7NoFW7dCbGz+df38M9SpA97ecOwY3HXXjbLsbNMKefYsHD+eu8zBZoP27U043bsXatQwXdFZWbf/nCIiIneK5jF0s61bt5KUlETFihVZunQpDz74YK7y48eP8+6772K1Wm/rOu+99x5XrlyhTp06t1VPWbZhgwmF4eHOoRAgPt4Ew+TkgoPh559DTg506uQc/KxWePhhmD/fHNe/v/P5f/+7uZ9//hOqVy/2I4mIiJQodSW72dKlSwH4/e9/7xQKAerUqUNiYiLVbzM9hISE0LhxY3x8fG6rnrJs506zbd7cdbljv+M4T9V18iS89BL89rfw5JMFX0tERKS0UjB0s9OnTwNQq1atIp977do1pk2bRmRkJFarlXr16jFy5Eiys7Odjs3rHUPH+4pXr15l/PjxhIeH4+vrS4MGDRg3bhxZ5ahvMz3dbOvWdV3u2O84zlN1DR5suozfeqvg64iIiJRmCoZuVteeIBYvXnw9JBZW3759SUpKom7dunTt2pXMzEymTZvGM888U6R6bDYb8fHxTJ8+nSZNmvDQQw9x9uxZJk6cSI8ePbh27VqR6iutLl0y28qVXZdXqZL7OE/UtXw5LFliWgwjIwu+joiISGmmYOhmffv2xdfXl/T0dBo2bEi/fv2YN28e33//PfmN8zl69Ci7du1iz549rF27luTkZHbs2EH16tX54IMPOFSEeVfS09PZsWMHe/bsITk5mcWLF3PgwAGioqL46quvmDt3bp7nZmdnc/HixTIRHh1/zrzWby7KgJfi1JWZaVoLIyJg1KjCX0tERKS0UjB0s/DwcJYvX05wcDAXL17kvffeY8CAAURFRVG7dm1GjBjB+TxmS54zZ06uEcb169fnSftLa+vXry/SfYwbN44GDRpc/71WrVpMnz4dIN9gOGXKFPz9/dmyZUuRrlcS/PzM9vJl1+VXrpht1aqeqWv0aDOJ9ltvmQEqIiIiZZ2CoQd07dqVH3/8kX/9618MGDCA6OhovLy8OHXqFNOnT6dly5ZO3cw+Pj507NjRqa5Ie//kyZMni3QPvXv3dtrXrVs3qlevzv79+/Ps5h41ahQXLlygZcuWRbpeSQgJMdu8Vjhx7Hcc5+66kpPN6iYTJ0LHjrk/YFZBcfx+8GDB9yAiIlLSNF2Nh1itVh5//HEef/xxwAxKWbhwIYmJiRw8eJDRo0fz7rvvXj8+KCgIb29vp3qq2puoXA1AyUv16tXxczSB3SI0NJRz585x4sQJlwNkrFYrVqvV5b2UNjExZrt9u+tyx/7oaM/VlZUFKSmuz7HZbpQV5j1HERGRkqYWwzukVq1avPjii7zyyisArFy5Mle5Ja+X29ysPM1n3rYt+PubZe927HAu/+QTs+3Ro+C6unUDLy9Yvx5Oncpdlp1tWge9vKB79xv7jxwx4c/VB0z3suP3pk2L9YgiIiJ3lILhHeboLs7IyPDYNc6dO0dmZqbLsnT7fCtBQUEeu/6dUrGiGfwBZnvz+4GvvWYmt27Xzqxz7PDGG9C4sfNgkaAgeOIJ0/07cCD8+uuNshEjzPJ6ffqAfbEaERGRckldyW5ms9nybf1zjC4ODg726H0sWrSIZ599Nte+1atXc+7cOSIiIggMDPTo9e+UMWPgyy/NeskREXD//XD0qFkvuWZNWLAg9/EZGWYdZFevbL7+OqSmwuLFJjy2aAHff2/WSw4Ph5kz78wziYiIlBS1GLrZ2LFjGTFiBIcPH3YqO3DgAC+88AIAvXr18uh9JCUl5Zr8OiMjgxEjRgAwcOBAj177TvL1hXXrYOxYMwfhsmWmi7dfP9O93LBh4esKCIAtWyAhwbQcLl0KFy6Y1si0NFMuIiJSnqnF0M0uXbrErFmzmDFjBo0aNeLuu+/Gx8eH9PR00tLSyMnJITY2lvHjx3vsHkJCQoiOjuaee+6hc+fO+Pj4sHbtWs6fP0+nTp0Y7Oh/LScqVYKkJPMpSGKi+eSlenWYPdt8bkc5epVTRET+iygYutmYMWOIjY1l9erV7Ny5k5SUFC5evEi1atXo0KED8fHxPPvss1SsWNFj92CxWPjkk09ISkriww8/5MSJEwQFBTFo0CBefvllKlTQP7uIiIg4s9jK0zBVwWKxEBoa6rSGclHFxcWRmpp6y97WwKZi1advmYiISOmndwxFREREBFAwFBERERE7BUMRERERATT4pNzx5CujrVvDpuK9YigiIiJlgFoMRURERARQMBQREREROwVDEREREQEUDEVERETETsFQRERERAAFQxERERGxUzAUEREREUDBUERERETsNMG1FFpqKlgsxTvXg/Nui4iIiJuoxVBEREREAAVDEREREbFTMJQyLSsLxo+HyEjw9YXgYHj6afjpp6LXdf48DB0KoaFgtZrt88+b/YVx9So0aWK62319i359ERGRkqZgKGVWVhZ07gxJSXDpEjz6KNSrBwsWQPPmcOhQ4es6cwZatYJZs6BCBejZE/z8YPZsaNnSlBdk8mTYu7f4zyMiIlLSFAzzYLFYivQJCwsr6Vu+bs+ePVgsFnr06FHSt+JRkyfDxo0QFwf798OiRbB5M7z6Kpw+bVoOC2vYMDhwAHr1gn37TF179kBCAhw8CMOH53/+Dz/AlCkwYMDtPZOIiEhJsthsGi/qSv/+/Z32bdiwgUOHDhETE0PTpk1zlQUEBDBjxow7dHf527NnD/feey8PPfQQn376abHqiIuLIzU19Za9rYFNxarP3d+yX36BwEDTzbt9OzRrlrs8JgZ27YKtWyE2Nv+6fv4Z6tQBb284dgzuuutGWXa2aYU8exaOH89d5mCzQfv2Jpzu3Qs1apiu6Kys239OERGRO0nT1eRh4cKFTvv69+/PoUOH6NmzJ4mJiXf8nuSGDRtMKAwPdw6FAPHxJhgmJxccDD//HHJyoFMn5+BntcLDD8P8+eY4F/9f4O9/N/fzz39C9erFfiQREZESp65kKZN27jTb5s1dlzv2O47zVF0nT8JLL8FvfwtPPlnwtUREREozBUM3+/TTT7FYLAwePJhjx47Rr18/goOD8fb2Zt68eQC0aNECi8VCRkaG0/kFvR+4bNkyunfvTkBAAFarldDQUOLj41mzZk2h7m/VqlVUqVKFGjVquOgqLjvS0822bl3X5Y79juM8VdfgwabL+K23Cr6OiIhIaaeuZA85fvw4LVq0wMfHh/vvv59Lly7he5tzmPz5z3/mnXfeoUKFCrRt25agoCB++uknVq9eTVZWFr/73e/yPf+jjz7iT3/6E7Vq1WL16tVERUXd1v2UpEuXzLZyZdflVarkPs4TdS1fDkuW3JguR0REpKxTMPSQZcuW0bdvX+bPn0/FihVvu763336bd955hwYNGvDZZ5/RqFGj62WZmZls37493/PffPNNEhISqF+/PmvWrKF+/fq3fU8lyTGYJa8l+ooy2KU4dWVmmtbCiAgYNarw1xIRESnNFAw9pEqVKsyaNcstoRBgypQpgAl4N4dCAD8/Pzp06JDnuZMmTWLs2LFER0ezevVqateuneex2dnZZGdnc+3aNbfct6f4+Znt5cuuy69cMduqVT1T1+jRZhLtL780A1RERETKAwVDD2nTpg01a9Z0S1379+8nPT2dkJAQHnjggUKfZ7PZGDp0KLNmzaJNmzasXLmSatWq5XvOlClTmDBhwu3esseFhJhtXiucOPY7jnN3XcnJZnWTiRPN51ZXr0LHjubnefOgYcOC70NERKSkKRh6SEhhEkkhHTt2DICGRUwXX3zxBZ999hlhYWGsWbOGynm9RHeTUaNGMXz4cLp06cKWLVuKdb93QkyM2ebVg+7YHx3tubqysiAlxfU5NtuNssK85ygiIlIaaFSyhxR3oElOTk6eZZa8XoLLQ7NmzWjUqBFHjhy53hVdEKvVym9+8xu8vb2LdK07rW1b8Pc3y97t2OFc/sknZluYxV+6dQMvL1i/Hk6dyl2WnW1aB728oHv3G/uPHDHhz9UHTPey4/db5kIXEREptRQMS4DjvcNLLpqSHK2DN6tXrx4ABw8eLNJ1AgMDWbt2LREREUyaNKlcTcpdsaIZ/AFme/P7ga+9Zia3btfOrHPs8MYb0Lix82CRoCB44gnT/TtwIPz6642yESPM8np9+kA+r2aKiIiUCwqGJSAoKAgw7w7e6osvvnDaFxkZSUhICEePHnVZnp/g4GDWrVtHw4YNmTBhAhNdvRBXRo0ZA/fdZ9ZLjoiAP/wBWreGF16AmjVhwYLcx2dkmHWQT550ruv1180qKosXm/DYuzfcey/Mnm32z5x5Z55JRESkJCkYlgDHCOLp06eTnZ19fX9ycjJvv/22y3NGjhwJwKBBg5wCZWZmJil5vewG1KlTh3Xr1tGgQQPGjRtX6G7l0s7XF9atg7FjzRyEy5aZLt5+/Uz3clFeyQwIgC1bICHBtBwuXQoXLpjWyLQ0Uy4iIlLeKRiWgKeeeorQ0FC+/PJL7r77buLj42nRogWPPvooCQkJLs/5y1/+wlNPPcXBgweJioqiU6dO9OnTh/bt2xMcHMz06dPzvWbdunX5+uuvqV+/PqNHjy7w+LKiUiVISoKDB837gD//DAsXgr33PZfERPPOn4tlsAGzzvHs2WaFk+xss50zB2rUKNo92WxmYIqIiEhZo2BYAvz8/EhJSSE+Pp5z587x2Wef4ePjw4oVK+jfv7/LcywWC/Pnz2fRokW0a9eO7777jiVLlpCenk737t0ZNmxYgdetV68e69atIywsjBEjRjBT/aMiIiJyE4vNVpQ1IuS/RVxcnIu1lFsDm4pVn75lIiIipZ9aDEVEREQEUDAUERERETsFQxEREREBFAxFRERExE7BUAqtdeu8l4Er6CMiIiKln4KhiIiIiAAKhiIiIiJip2AoIiIiIoCCoYiIiIjYKRiKiIiICKBgKCIiIiJ2CoYiIiIiAigYioiIiIidgqGIiIiIAAqGIiIiImKnYCgiIiIigIKhiIiIiNgpGIqIiIgIoGAoIiIiInYKhiIiIiICKBiKiIiIiJ2CoYiIiIgACoYiIiIiYlehpG9ASqeoqKhC7RMREZHyw2Kz2WwlfRMiIiIiUvLUlSwiIiIigIKhiIiIiNgpGIqIiIgIoGAoIiIiInYKhiIiIiICKBiKiIiIiJ2CoYiIiIgACoYiIiIiYqdgKCIiIiIA/D+ZPcIVUOOdMgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# choose a picture at random\n",
    "idx=randint(0, 10000-1)\n",
    "im=test_data[idx]\n",
    "\n",
    "# diplay the picture\n",
    "utils.show(im)\n",
    "\n",
    "# send to device, rescale, and view as a batch of 1 \n",
    "im = im.to(device)\n",
    "#im= (im-mean) / std\n",
    "im=im.view(1,3,32,32)\n",
    "\n",
    "# feed it to the net and display the confidence scores\n",
    "scores =  net(im) \n",
    "probs= F.softmax(scores, dim=1)\n",
    "utils.show_prob_cifar(probs.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "\n",
    "from random import randint\n",
    "import utils as ut \n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import flags\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "#from util import get_normalized_data\n",
    "\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.model import CallableModelWrapper\n",
    "from cleverhans.utils import AccuracyReport\n",
    "from cleverhans.utils_pytorch import convert_pytorch_model_to_tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 3, 32, 32])\n",
      "torch.Size([10000, 3, 32, 32])\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "from utils import check_cifar_dataset_exists\n",
    "data_path=check_cifar_dataset_exists()\n",
    "\n",
    "train_data=torch.load(data_path+'cifar/train_data.pt')\n",
    "train_label=torch.load(data_path+'cifar/train_label.pt')\n",
    "test_data=torch.load(data_path+'cifar/test_data.pt')\n",
    "test_label=torch.load(data_path+'cifar/test_label.pt')\n",
    "\n",
    "print(train_data.size())\n",
    "print(test_data.size())\n",
    "print(train_data.type())\n",
    "print(test_data.type())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device= torch.device(\"cuda:1\")\n",
    "#device= torch.device(\"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_convnet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(VGG_convnet, self).__init__()\n",
    "\n",
    "        # block 1:         3 x 32 x 32 --> 64 x 16 x 16        \n",
    "        self.conv1a = nn.Conv2d(3,   64,  kernel_size=3, padding=1 )\n",
    "        self.conv1b = nn.Conv2d(64,  64,  kernel_size=3, padding=1 )\n",
    "        self.pool1  = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # block 2:         64 x 16 x 16 --> 128 x 8 x 8\n",
    "        self.conv2a = nn.Conv2d(64,  128, kernel_size=3, padding=1 )\n",
    "        self.conv2b = nn.Conv2d(128, 128, kernel_size=3, padding=1 )\n",
    "        self.pool2  = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # block 3:         128 x 8 x 8 --> 256 x 4 x 4        \n",
    "        self.conv3a = nn.Conv2d(128, 256, kernel_size=3, padding=1 )\n",
    "        self.conv3b = nn.Conv2d(256, 256, kernel_size=3, padding=1 )\n",
    "        self.pool3  = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        #block 4:          256 x 4 x 4 --> 512 x 2 x 2\n",
    "        self.conv4a = nn.Conv2d(256, 512, kernel_size=3, padding=1 )\n",
    "        self.pool4  = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # linear layers:   512 x 2 x 2 --> 2048 --> 4096 --> 4096 --> 10\n",
    "        self.linear1 = nn.Linear(2048, 4096)\n",
    "        self.linear2 = nn.Linear(4096,4096)\n",
    "        self.linear3 = nn.Linear(4096, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1:         3 x 32 x 32 --> 64 x 16 x 16\n",
    "        x = self.conv1a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv1b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # block 2:         64 x 16 x 16 --> 128 x 8 x 8\n",
    "        x = self.conv2a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # block 3:         128 x 8 x 8 --> 256 x 4 x 4\n",
    "        x = self.conv3a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        #block 4:          256 x 4 x 4 --> 512 x 2 x 2\n",
    "        x = self.conv4a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        # linear layers:   512 x 2 x 2 --> 2048 --> 4096 --> 4096 --> 10\n",
    "        x = x.view(-1, 2048)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x) \n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG_convnet(\n",
      "  (conv1a): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv1b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2a): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3a): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4a): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "  (linear2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (linear3): Linear(in_features=4096, out_features=10, bias=True)\n",
      ")\n",
      "There are 27540554 (27.54 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "net_vgg=VGG_convnet()\n",
    "\n",
    "print(net_vgg)\n",
    "ut.display_num_param(net_vgg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "my_lr=0.25 \n",
    "bs= 128\n",
    "\n",
    "net_vgg = net_vgg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 \t time= 0.1771658976872762 min \t lr= 0.25 \t loss= 2.3033349861574295 \t error= 90.08671674886932 percent\n",
      "error rate on test set = 90.04153481012658 percent\n",
      " \n",
      "epoch= 2 \t time= 0.3557172934214274 min \t lr= 0.25 \t loss= 2.3017202167559767 \t error= 89.46930945986678 percent\n",
      "error rate on test set = 90.11075949367088 percent\n",
      " \n",
      "epoch= 3 \t time= 0.5366153200467427 min \t lr= 0.25 \t loss= 2.3031061287121393 \t error= 89.96403452075656 percent\n",
      "error rate on test set = 89.97231012658227 percent\n",
      " \n",
      "epoch= 4 \t time= 0.7162699023882548 min \t lr= 0.25 \t loss= 2.3010089055961354 \t error= 89.36580882962707 percent\n",
      "error rate on test set = 90.11075949367088 percent\n",
      " \n",
      "epoch= 5 \t time= 0.8868489503860474 min \t lr= 0.25 \t loss= 2.301330021275279 \t error= 89.71867007977518 percent\n",
      "error rate on test set = 90.04153481012658 percent\n",
      " \n",
      "epoch= 6 \t time= 1.0547482212384542 min \t lr= 0.25 \t loss= 2.2946108271703696 \t error= 88.97298592740619 percent\n",
      "error rate on test set = 90.04153481012658 percent\n",
      " \n",
      "epoch= 7 \t time= 1.2237481951713562 min \t lr= 0.25 \t loss= 2.303199783920327 \t error= 90.04595587625528 percent\n",
      "error rate on test set = 90.11075949367088 percent\n",
      " \n",
      "epoch= 8 \t time= 1.3956722935040793 min \t lr= 0.25 \t loss= 2.303238797980501 \t error= 89.99520460967823 percent\n",
      "error rate on test set = 90.11075949367088 percent\n",
      " \n",
      "epoch= 9 \t time= 1.562945294380188 min \t lr= 0.25 \t loss= 2.303272707078158 \t error= 90.1422634301588 percent\n",
      "error rate on test set = 90.04153481012658 percent\n",
      " \n",
      "epoch= 10 \t time= 1.7310177524884542 min \t lr= 0.125 \t loss= 2.302939348513513 \t error= 90.0407608665164 percent\n",
      "error rate on test set = 89.90308544303798 percent\n",
      " \n",
      "epoch= 11 \t time= 1.8987337629000345 min \t lr= 0.125 \t loss= 2.302958682370003 \t error= 90.44757032638316 percent\n",
      "error rate on test set = 90.11075949367088 percent\n",
      " \n",
      "epoch= 12 \t time= 2.072193443775177 min \t lr= 0.125 \t loss= 2.302940141819322 \t error= 90.15425192120739 percent\n",
      "error rate on test set = 89.90308544303798 percent\n",
      " \n",
      "epoch= 13 \t time= 2.2455113609631856 min \t lr= 0.125 \t loss= 2.302967469100757 \t error= 90.24176789671564 percent\n",
      "error rate on test set = 90.04153481012658 percent\n",
      " \n",
      "epoch= 14 \t time= 2.4212162693341575 min \t lr= 0.125 \t loss= 2.30298205775678 \t error= 90.2349744306501 percent\n",
      "error rate on test set = 89.90308544303798 percent\n",
      " \n",
      "epoch= 15 \t time= 2.5923702001571653 min \t lr= 0.0625 \t loss= 2.3027663419923514 \t error= 90.25735294117648 percent\n",
      "error rate on test set = 90.04153481012658 percent\n",
      " \n"
     ]
    }
   ],
   "source": [
    "def eval_on_test_set():\n",
    "\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "\n",
    "    for i in range(0,10000,bs):\n",
    "\n",
    "        minibatch_data =  test_data[i:i+bs]\n",
    "        minibatch_label= test_label[i:i+bs]\n",
    "\n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        #inputs = (minibatch_data - mean)/std\n",
    "        inputs = minibatch_data\n",
    "\n",
    "        scores=net_vgg( inputs ) \n",
    "\n",
    "        error = ut.get_error( scores , minibatch_label)\n",
    "\n",
    "        running_error += error.item()\n",
    "\n",
    "        num_batches+=1\n",
    "\n",
    "    total_error = running_error/num_batches\n",
    "    print( 'error rate on test set =', total_error*100 ,'percent')\n",
    "\n",
    "\n",
    "# ### Do 20 passes through the training set. Divide the learning rate by 2 at epoch 10, 14 and 18.\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "for epoch in range(1,35):\n",
    "    \n",
    "    # divide the learning rate by 2 at epoch 10, 14 and 18\n",
    "    if epoch==10 or epoch == 15 or epoch==25 or epoch==30:\n",
    "        my_lr = my_lr / 2\n",
    "    \n",
    "    # create a new optimizer at the beginning of each epoch: give the current learning rate.   \n",
    "    optimizer=torch.optim.SGD( net_vgg.parameters() , lr=my_lr )\n",
    "        \n",
    "    # set the running quatities to zero at the beginning of the epoch\n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    \n",
    "    # set the order in which to visit the image from the training set\n",
    "    shuffled_indices=torch.randperm(50000)\n",
    " \n",
    "    for count in range(0,50000,bs):\n",
    "    \n",
    "        # Set the gradients to zeros\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # create a minibatch       \n",
    "        indices=shuffled_indices[count:count+bs]\n",
    "        minibatch_data =  train_data[indices]\n",
    "        minibatch_label=  train_label[indices]\n",
    "        \n",
    "        # send them to the gpu\n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        # normalize the minibatch (this is the only difference compared to before!)\n",
    "        #inputs = (minibatch_data - mean)/std\n",
    "        inputs = minibatch_data\n",
    "        \n",
    "        # tell Pytorch to start tracking all operations that will be done on \"inputs\"\n",
    "        inputs.requires_grad_()\n",
    "\n",
    "        # forward the minibatch through the net \n",
    "        scores=net_vgg( inputs ) \n",
    "\n",
    "        # Compute the average of the losses of the data points in the minibatch\n",
    "        loss =  criterion( scores , minibatch_label) \n",
    "        \n",
    "        # backward pass to compute dL/dU, dL/dV and dL/dW   \n",
    "        loss.backward()\n",
    "\n",
    "        # do one step of stochastic gradient descent: U=U-lr(dL/dU), V=V-lr(dL/dU), ...\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # START COMPUTING STATS\n",
    "        \n",
    "        # add the loss of this batch to the running loss\n",
    "        running_loss += loss.detach().item()\n",
    "        \n",
    "        # compute the error made on this batch and add it to the running error       \n",
    "        error = ut.get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "        \n",
    "        num_batches+=1        \n",
    "    \n",
    "    \n",
    "    # compute stats for the full training set\n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    elapsed = (time.time()-start)/60\n",
    "    \n",
    "\n",
    "    print('epoch=',epoch, '\\t time=', elapsed,'min','\\t lr=', my_lr  ,'\\t loss=', total_loss , '\\t error=', total_error*100 ,'percent')\n",
    "    eval_on_test_set() \n",
    "    print(' ')\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_data, train_label))\n",
    "     \n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_data, test_label))\n",
    "\n",
    "sess = tf.Session()\n",
    "x_op1 = tf.placeholder(tf.float32, shape=(None,3, 32, 32,))\n",
    "#x_op2 = tf.placeholder(tf.float32, shape=(None,3, 32, 32,))\n",
    "\n",
    "\n",
    "# Convert pytorch model to a tf_model and wrap it in cleverhans\n",
    "tf_net = convert_pytorch_model_to_tf(net_vgg)\n",
    "cleverhans_model = CallableModelWrapper(tf_net, output_layer='logits')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an FGSM attack\n",
    "fgsm_op = FastGradientMethod(cleverhans_model, sess=sess)\n",
    "fgsm_params = {'eps': 0.3,\n",
    "                 'clip_min': 0.,\n",
    "                 'clip_max': 1.}\n",
    "adv_x_op = fgsm_op.generate(x_op1, **fgsm_params)\n",
    "adv_preds_op = tf_net(adv_x_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial accuracy with FGSM attack: 10.000\n"
     ]
    }
   ],
   "source": [
    "no_runs = 10000\n",
    "correct = 0\n",
    "for xs, ys in test_loader:\n",
    "    xs, ys = Variable(xs), Variable(ys)\n",
    "    adv_example = sess.run(adv_x_op, feed_dict={x_op1: xs})\n",
    "    adv_preds = sess.run(adv_preds_op, feed_dict={adv_x_op: adv_example})\n",
    "    correct += (np.argmax(adv_preds, axis=1) == ys).sum()\n",
    "   \n",
    "acc = float(correct) / no_runs\n",
    "\n",
    "print('Adversarial accuracy with FGSM attack: {:.3f}'.format(acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
