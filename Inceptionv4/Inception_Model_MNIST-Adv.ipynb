{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device= torch.device(\"cuda\")\n",
    "#device= torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "from utils import check_mnist_dataset_exists\n",
    "data_path=check_mnist_dataset_exists()\n",
    "\n",
    "train_data=torch.load(data_path+'mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'mnist/train_label.pt')\n",
    "test_data=torch.load(data_path+'mnist/test_data.pt')\n",
    "test_label=torch.load(data_path+'mnist/test_label.pt')\n",
    "\n",
    "print(train_data.size())\n",
    "print(test_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stem(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Stem, self).__init__()\n",
    "        \n",
    "        #----------------------- stem block start ----------------------------\n",
    "        \n",
    "        #self.padding = nn.ZeroPad2d((133,134,133,134))\n",
    "        #self.padding = nn.ReplicationPad2d((133,134,133,134))\n",
    "        \n",
    "        self.resize = nn.UpsamplingBilinear2d(size=(299,299))\n",
    "        \n",
    "        #1 x 299 x 299 --> 32 x 149 x 149  , VALID Padding \n",
    "        self.conv1a = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=0 ) \n",
    "        \n",
    "        self.bn1a = nn.BatchNorm2d(32,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #32 x 149 x 149 --> 32 x 147 x 147  , VALID Padding \n",
    "        self.conv1b = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0 )\n",
    "        \n",
    "        self.bn1b = nn.BatchNorm2d(32,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #32 x 147 x 147 --> 64 x 147 x 147  , SAME Padding \n",
    "        self.conv1c = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1 )\n",
    "        \n",
    "        self.bn1c = nn.BatchNorm2d(64,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #======================== Filter concat 1 =============================\n",
    "        \n",
    "        #64 x 147 x 147 --> 64 x 73 x 73, kernel size = 3, VALID Padding  \n",
    "        self.pool1  = nn.MaxPool2d(kernel_size=3, stride=2, padding=0 )\n",
    "        \n",
    "        #64 x 147 x 147 --> 96 x 73 x 73  , VALID Padding\n",
    "        self.conv2a = nn.Conv2d(64, 96, kernel_size=3, stride=2, padding=0 )\n",
    "        \n",
    "        self.bn2a = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #======================== Filter concat 1 =============================\n",
    "        \n",
    "        #======================== Filter concat 2 =============================       \n",
    "        \n",
    "        #160 x 73 x 73 --> 64 x 73 x 73  , SAME Padding   Find out the size of output\n",
    "        self.conv3a = nn.Conv2d(160, 64, kernel_size=1, padding=0 )\n",
    "        \n",
    "        self.bn3a = nn.BatchNorm2d(64,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #64 x 73 x 73 --> 96 x 71 x 71  , VALID Padding   Find out the size of output\n",
    "        self.conv3b = nn.Conv2d(64, 96, kernel_size=3, padding=0 )\n",
    "        \n",
    "        self.bn3b = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #160 x 73 x 73 --> 64 x 73 x 73  , SAME Padding   Might be combined with self.conv1e1\n",
    "        self.conv4a = nn.Conv2d(160, 64, kernel_size=1, padding=0 )\n",
    "        \n",
    "        self.bn4a = nn.BatchNorm2d(64,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #64 x 73 x 73 --> 64 x 73 x 73  , SAME Padding   Find out the size of output\n",
    "        self.conv4b = nn.Conv2d(64, 64, kernel_size=[7,1], padding=[3,0] )\n",
    "        \n",
    "        self.bn4b = nn.BatchNorm2d(64,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #64 x 73 x 73 --> 64 x 73 x 73  , SAME Padding   Find out the size of output\n",
    "        self.conv4c = nn.Conv2d(64, 64, kernel_size=[1,7], padding=[0,3]  )\n",
    "        \n",
    "        self.bn4c = nn.BatchNorm2d(64,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #64 x 73 x 73 --> 96 x 71 x 71  , VALID Padding   Might be combined with self.conv1e2\n",
    "        self.conv4d = nn.Conv2d(64, 96, kernel_size=3, padding=0 )\n",
    "        \n",
    "        self.bn4d = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #======================== Filter concat 2 ============================= \n",
    "        \n",
    "        #======================== Filter concat 3 =============================\n",
    "        \n",
    "        #192 x 71 x 71 --> 192 x 35 x 35  , VALID Padding \n",
    "        self.conv5a = nn.Conv2d(192, 192, kernel_size=3, stride=2, padding=0 )\n",
    "        \n",
    "        self.bn5a = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "         \n",
    "        #192 x 71 x 71 --> 192 x 35 x 35, kernel size = 3, VALID Padding\n",
    "        self.pool2  = nn.MaxPool2d(kernel_size=3, stride=2, padding=0 )\n",
    "        \n",
    "        #======================== Filter concat 3 =============================\n",
    "        \n",
    "        #----------------------- stem block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1: \n",
    "        #x = self.padding(x)\n",
    "        x= self.resize(x)\n",
    "        \n",
    "        x = self.conv1a(x)\n",
    "        x = self.bn1a(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv1b(x)\n",
    "        x = self.bn1b(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        \n",
    "        x = self.conv1c(x)\n",
    "        x = self.bn1c(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        \n",
    "        xP = self.pool1(x)\n",
    "        xC = self.conv2a(x)\n",
    "        xC = self.bn2a(xC)\n",
    "        xC = F.relu(xC)\n",
    "        xFC1 = torch.cat((xP, xC), 1)\n",
    "        \n",
    "        y = self.conv3a(xFC1)\n",
    "        y = self.bn3a(y)\n",
    "        y = F.relu(y)\n",
    "        \n",
    "        y = self.conv3b(y)\n",
    "        y = self.bn3b(y)\n",
    "        y = F.relu(y)\n",
    "\n",
    "        z = self.conv4a(xFC1)\n",
    "        z = self.bn4a(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.conv4b(z)\n",
    "        z = self.bn4b(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.conv4c(z)\n",
    "        z = self.bn4c(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.conv4d(z)\n",
    "        z = self.bn4d(z)\n",
    "        z = F.relu(z)\n",
    "        \n",
    "        # Above code or this one?\n",
    "        #z = self.conv3a(xFC1)\n",
    "        #z = F.relu(z)\n",
    "        #z = self.conv4b(z)\n",
    "        #z = F.relu(z)\n",
    "        #z = self.conv4c(xFC1)\n",
    "        #z = F.relu(z)\n",
    "        #z = self.conv3b(z)\n",
    "        #z = F.relu(z)\n",
    "        \n",
    "        xFC2 = torch.cat((y, z), 1)\n",
    "        \n",
    "        xP = self.pool2(xFC2)\n",
    "        xC = self.conv5a(xFC2)\n",
    "        xC = self.bn5a(xC)\n",
    "        xC = F.relu(xC)\n",
    "        xFC3 = torch.cat((xP, xC), 1)   \n",
    "        #print('Stem Done')\n",
    "        \n",
    "        return xFC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionA(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(InceptionA, self).__init__()\n",
    "        \n",
    "        #----------------------- InceptionA block start ----------------------------\n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #block 1\n",
    "        #384 x 35 x 35 --> 384 x 35 x 35  , kernel size = 3, SAME Padding\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=3, stride=1, padding=1 )\n",
    "        \n",
    "        #384 x 35 x 35 --> 96 x 35 x 35  , SAME Padding \n",
    "        self.conv1a = nn.Conv2d(384, 96, kernel_size=1, padding=0 ) \n",
    "        self.bn1a = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 2\n",
    "        #384 x 35 x 35 --> 96 x 35 x 35  , SAME Padding \n",
    "        self.conv2a = nn.Conv2d(384, 96, kernel_size=1, padding=0 ) \n",
    "        self.bn2a = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 3\n",
    "        #384 x 35 x 35 --> 64 x 35 x 35  , SAME Padding \n",
    "        self.conv3a = nn.Conv2d(384, 64, kernel_size=1, padding=0 )\n",
    "        self.bn3a = nn.BatchNorm2d(64,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #64 x 35 x 35 --> 96 x 35 x 35  , SAME Padding \n",
    "        self.conv3b = nn.Conv2d(64, 96, kernel_size=3, padding=1 )\n",
    "        self.bn3b = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 4\n",
    "        #384 x 35 x 35 --> 64 x 35 x 35  , SAME Padding \n",
    "        self.conv4a = nn.Conv2d(384, 64, kernel_size=1, padding=0 )\n",
    "        self.bn4a = nn.BatchNorm2d(64,affine=True, eps=0.001,momentum=0.1)\n",
    "\n",
    "        #64 x 35 x 35 --> 96 x 35 x 35  , SAME Padding \n",
    "        self.conv4b = nn.Conv2d(64, 96, kernel_size=3, padding=1 )\n",
    "        self.bn4b = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #96 x 35 x 35 --> 96 x 35 x 35  , SAME Padding \n",
    "        self.conv4c = nn.Conv2d(96, 96, kernel_size=3, padding=1 )\n",
    "        self.bn4c = nn.BatchNorm2d(96,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #----------------------- InceptionA block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1:\n",
    "        y = self.pool1(x)\n",
    "        y = self.conv1a(y)\n",
    "        y = self.bn1a(y)\n",
    "        y = F.relu(y)   # Do we need Relu here (after last operation)?\n",
    "        \n",
    "        # block 2:\n",
    "        z = self.conv2a(x)\n",
    "        z = self.bn2a(z)\n",
    "        z = F.relu(z) \n",
    "        \n",
    "        #block 3:\n",
    "        w = self.conv3a(x)\n",
    "        w = self.bn3a(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv3b(w)\n",
    "        w = self.bn3b(w)\n",
    "        w = F.relu(w)\n",
    "        \n",
    "        #block 4:\n",
    "        v = self.conv4a(x)\n",
    "        v = self.bn4a(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4b(v)\n",
    "        v = self.bn4b(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4c(v)\n",
    "        v = self.bn4c(v)\n",
    "        v = F.relu(v)\n",
    "        \n",
    "        xFC = torch.cat((y, z, w, v), 1)\n",
    "        #print('InceptionA Done')\n",
    "        \n",
    "        return xFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionB(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(InceptionB, self).__init__()\n",
    "        \n",
    "        #----------------------- InceptionB block start ----------------------------\n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #block 1\n",
    "        #1024 x 17 x 17 --> 1024 x 17 x 17  , kernel size = 1, SAME Padding\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=3, stride=1, padding=1 )\n",
    "        \n",
    "        #1024 x 17 x 17 --> 128 x 17 x 17  , SAME Padding \n",
    "        self.conv1a = nn.Conv2d(1024, 128, kernel_size=1, padding=0 ) \n",
    "        self.bn1a = nn.BatchNorm2d(128,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 2\n",
    "        #1024 x 17 x 17 --> 384 x 17 x 17  , SAME Padding \n",
    "        self.conv2a = nn.Conv2d(1024, 384, kernel_size=1, padding=0 ) \n",
    "        self.bn2a = nn.BatchNorm2d(384,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 3\n",
    "        #1024 x 17 x 17 --> 192 x 17 x 17  , SAME Padding \n",
    "        self.conv3a = nn.Conv2d(1024, 192, kernel_size=1, padding=0 )\n",
    "        self.bn3a = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #192 x 17 x 17 --> 224 x 17 x 17  , SAME Padding \n",
    "        self.conv3b = nn.Conv2d(192, 224, kernel_size=[7,1], padding=[3,0] )\n",
    "        self.bn3b = nn.BatchNorm2d(224,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #224 x 17 x 17 --> 256 x 17 x 17  , SAME Padding \n",
    "        self.conv3c = nn.Conv2d(224, 256, kernel_size=[1,7], padding=[0,3] )\n",
    "        self.bn3c = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 4\n",
    "        #1024 x 17 x 17 --> 192 x 17 x 17  , SAME Padding \n",
    "        self.conv4a = nn.Conv2d(1024, 192, kernel_size=1, padding=0 )\n",
    "        self.bn4a = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #192 x 17 x 17 --> 192 x 17 x 17  , SAME Padding \n",
    "        self.conv4b = nn.Conv2d(192, 192, kernel_size=[1,7], padding=[0,3] )\n",
    "        self.bn4b = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #192 x 17 x 17 --> 224 x 17 x 17  , SAME Padding \n",
    "        self.conv4c = nn.Conv2d(192, 224, kernel_size=[7,1], padding=[3,0] )\n",
    "        self.bn4c = nn.BatchNorm2d(224,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #224 x 17 x 17 --> 224 x 17 x 17  , SAME Padding \n",
    "        self.conv4d = nn.Conv2d(224, 224, kernel_size=[1,7], padding=[0,3] )\n",
    "        self.bn4d = nn.BatchNorm2d(224,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #224 x 17 x 17 --> 256 x 17 x 17  , SAME Padding \n",
    "        self.conv4e = nn.Conv2d(224, 256, kernel_size=[7,1], padding=[3,0] )\n",
    "        self.bn4e = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #----------------------- InceptionB block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # block 1:\n",
    "        y = self.pool1(x)\n",
    "        y = self.conv1a(y)\n",
    "        y = self.bn1a(y)\n",
    "        y = F.relu(y)\n",
    "        \n",
    "        # block 2:\n",
    "        z = self.conv2a(x)\n",
    "        z = self.bn2a(z)\n",
    "        z = F.relu(z) \n",
    "        \n",
    "        #block 3:\n",
    "        w = self.conv3a(x)\n",
    "        w = self.bn3a(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv3b(w)\n",
    "        w = self.bn3b(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv3c(w)\n",
    "        w = self.bn3c(w)\n",
    "        w = F.relu(w)\n",
    "        \n",
    "        #block 4:\n",
    "        v = self.conv4a(x)\n",
    "        v = self.bn4a(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4b(v)\n",
    "        v = self.bn4b(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4c(v)\n",
    "        v = self.bn4c(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4d(v)\n",
    "        v = self.bn4d(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4e(v)\n",
    "        v = self.bn4e(v)\n",
    "        v = F.relu(v)\n",
    "        \n",
    "        xFC = torch.cat((y, z, w, v), 1)\n",
    "        #print('InceptionB Done')\n",
    "        \n",
    "        return xFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionC(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(InceptionC, self).__init__()\n",
    "        \n",
    "        #----------------------- InceptionC block start ----------------------------\n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #block 1\n",
    "        #1536 x 8 x 8 --> 1536 x 8 x 8  , kernel size = 3, SAME Padding\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=3, stride=1, padding=1 )\n",
    "        \n",
    "        #1536 x 8 x 8 --> 256 x 8 x 8  , SAME Padding \n",
    "        self.conv1a = nn.Conv2d(1536, 256, kernel_size=1, padding=0 ) \n",
    "        self.bn1a = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 2\n",
    "        #1536 x 8 x 8 --> 256 x 8 x 8  , SAME Padding \n",
    "        self.conv2a = nn.Conv2d(1536, 256, kernel_size=1, padding=0 ) \n",
    "        self.bn2a = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 3\n",
    "        #1536 x 8 x 8 --> 384 x 8 x 8  , SAME Padding \n",
    "        self.conv3a = nn.Conv2d(1536, 384, kernel_size=1, padding=0 )\n",
    "        self.bn3a = nn.BatchNorm2d(384,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #384 x 8 x 8 --> 256 x 8 x 8  , SAME Padding \n",
    "        self.conv3b = nn.Conv2d(384, 256, kernel_size=[1,3], padding=[0,1] )\n",
    "        self.bn3b = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #384 x 8 x 8 --> 256 x 8 x 8  , SAME Padding \n",
    "        self.conv3c = nn.Conv2d(384, 256, kernel_size=[3,1], padding=[1,0] )\n",
    "        self.bn3c = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 4\n",
    "        #1536 x 8 x 8 --> 384 x 8 x 8  , SAME Padding \n",
    "        self.conv4a = nn.Conv2d(1536, 384, kernel_size=1, padding=0 )\n",
    "        self.bn4a = nn.BatchNorm2d(384,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #384 x 8 x 8 --> 448 x 8 x 8  , SAME Padding \n",
    "        self.conv4b = nn.Conv2d(384, 448, kernel_size=[1,3], padding=[0,1] )\n",
    "        self.bn4b = nn.BatchNorm2d(448,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #448 x 8 x 8 --> 512 x 8 x 8  , SAME Padding \n",
    "        self.conv4c = nn.Conv2d(448, 512, kernel_size=[3,1], padding=[1,0] )\n",
    "        self.bn4c = nn.BatchNorm2d(512,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #512 x 8 x 8 --> 256 x 8 x 8  , SAME Padding \n",
    "        self.conv4d = nn.Conv2d(512, 256, kernel_size=[3,1], padding=[1,0] )\n",
    "        self.bn4d = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #512 x 8 x 8 --> 256 x 8 x 8  , SAME Padding \n",
    "        self.conv4e = nn.Conv2d(512, 256, kernel_size=[1,3], padding=[0,1] )\n",
    "        self.bn4e = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #----------------------- InceptionC block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # block 1:\n",
    "        y = self.pool1(x)\n",
    "        y = self.conv1a(y)\n",
    "        y = self.bn1a(y)\n",
    "        y = F.relu(y)\n",
    "        \n",
    "        # block 2:\n",
    "        z = self.conv2a(x)\n",
    "        z = self.bn2a(z)\n",
    "        z = F.relu(z) \n",
    "        \n",
    "        #block 3:\n",
    "        w = self.conv3a(x)\n",
    "        w = self.bn3a(w)\n",
    "        w = F.relu(w)\n",
    "        w1 = self.conv3b(w)\n",
    "        w1 = self.bn3b(w1)\n",
    "        w1 = F.relu(w1)\n",
    "        w2 = self.conv3c(w)\n",
    "        w2 = self.bn3c(w2)\n",
    "        w2 = F.relu(w2)\n",
    "        \n",
    "        #block 4:\n",
    "        v = self.conv4a(x)\n",
    "        v = self.bn4a(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4b(v)\n",
    "        v = self.bn4b(v)\n",
    "        v = F.relu(v)\n",
    "        v = self.conv4c(v)\n",
    "        v = self.bn4c(v)\n",
    "        v = F.relu(v)\n",
    "        v1 = self.conv4d(v)\n",
    "        v1 = self.bn4d(v1)\n",
    "        v1 = F.relu(v1)\n",
    "        v2 = self.conv4e(v)\n",
    "        v2 = self.bn4e(v2)\n",
    "        v2 = F.relu(v2)\n",
    "        \n",
    "        xFC = torch.cat((y, z, w1, w2, v1, v2), 1)\n",
    "        #print('InceptionC Done')\n",
    "        \n",
    "        return xFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReductionA(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(ReductionA, self).__init__()\n",
    "        \n",
    "        #----------------------- ReductionA block start ----------------------------\n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #block 1\n",
    "        #384 x 35 x 35 --> 384 x 17 x 17  , kernel size = 3, VALID Padding\n",
    "        self.pool1  = nn.MaxPool2d(kernel_size=3, stride=2, padding=0 )\n",
    "        \n",
    "        #block 2\n",
    "        #384 x 35 x 35 --> 384 x 17 x 17  , VALID Padding -- \n",
    "        self.conv1a = nn.Conv2d(384, 384, kernel_size=3, stride=2, padding=0 ) \n",
    "        self.bn1a = nn.BatchNorm2d(384,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 3\n",
    "        #384 x 35 x 35 --> 192 x 35 x 35  , SAME Padding \n",
    "        self.conv2a = nn.Conv2d(384, 192, kernel_size=1, padding=0 )\n",
    "        self.bn2a = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #192 x 35 x 35 --> 224 x 35 x 35  , SAME Padding \n",
    "        self.conv2b = nn.Conv2d(192, 224, kernel_size=3, padding=1 )\n",
    "        self.bn2b = nn.BatchNorm2d(224,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #224 x 35 x 35 --> 256 x 17 x 17  , VALID Padding \n",
    "        self.conv2c = nn.Conv2d(224, 256, kernel_size=3, stride=2, padding=0 )\n",
    "        self.bn2c = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "                \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #----------------------- ReductionA block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1:\n",
    "        y = self.pool1(x)\n",
    "        \n",
    "        # block 2:\n",
    "        z = self.conv1a(x)\n",
    "        z = self.bn1a(z)\n",
    "        z = F.relu(z) \n",
    "        \n",
    "        #block 3:\n",
    "        w = self.conv2a(x)\n",
    "        w = self.bn2a(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv2b(w)\n",
    "        w = self.bn2b(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv2c(w)\n",
    "        w = self.bn2c(w)\n",
    "        w = F.relu(w)\n",
    "                \n",
    "        xFC = torch.cat((y, z, w), 1)\n",
    "        #print('ReductionA Done')\n",
    "        \n",
    "        return xFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReductionB(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(ReductionB, self).__init__()\n",
    "        \n",
    "        #----------------------- ReductionB block start ----------------------------\n",
    "        \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #block 1\n",
    "        #1024 x 17 x 17 --> 1024 x 8 x 8  , kernel size = 3, VALID Padding\n",
    "        self.pool1  = nn.MaxPool2d(kernel_size=3, stride=2, padding=0 )\n",
    "        \n",
    "        #block 2\n",
    "        #1024 x 17 x 17 --> 192 x 17 x 17  , SAME Padding -- \n",
    "        self.conv1a = nn.Conv2d(1024, 192, kernel_size=1, padding=0 ) \n",
    "        self.bn1a = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #192 x 17 x 17 --> 192 x 8 x 8  , VALID Padding -- \n",
    "        self.conv1b = nn.Conv2d(192, 192, kernel_size=3, stride=2, padding=0 ) \n",
    "        self.bn1b = nn.BatchNorm2d(192,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #block 3\n",
    "        #1024 x 17 x 17 --> 256 x 17 x 17  , SAME Padding \n",
    "        self.conv2a = nn.Conv2d(1024, 256, kernel_size=1, padding=0 )\n",
    "        self.bn2a = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #256 x 17 x 17 --> 256 x 17 x 17  , SAME Padding \n",
    "        self.conv2b = nn.Conv2d(256, 256, kernel_size=[1, 7], padding=[0,3] )\n",
    "        self.bn2b = nn.BatchNorm2d(256,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #256 x 17 x 17 --> 320 x 17 x 17  , SAME Padding \n",
    "        self.conv2c = nn.Conv2d(256, 320, kernel_size=[7, 1], padding=[3,0] )\n",
    "        self.bn2c = nn.BatchNorm2d(320,affine=True, eps=0.001,momentum=0.1)\n",
    "        \n",
    "        #320 x 17 x 17 --> 320 x 8 x 8  , VALID Padding \n",
    "        self.conv2d = nn.Conv2d(320, 320, kernel_size=3, stride=2, padding=0 )\n",
    "        self.bn2d = nn.BatchNorm2d(320,affine=True, eps=0.001,momentum=0.1)\n",
    "                \n",
    "        #======================== Filter concat =============================\n",
    "        \n",
    "        #----------------------- ReductionB block finish ----------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1:\n",
    "        y = self.pool1(x)\n",
    "        \n",
    "        # block 2:\n",
    "        z = self.conv1a(x)\n",
    "        z = self.bn1a(z)\n",
    "        z = F.relu(z) \n",
    "        z = self.conv1b(z)\n",
    "        z = self.bn1b(z)\n",
    "        z = F.relu(z) \n",
    "        \n",
    "        #block 3:\n",
    "        w = self.conv2a(x)\n",
    "        w = self.bn2a(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv2b(w)\n",
    "        w = self.bn2b(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv2c(w)\n",
    "        w = self.bn2c(w)\n",
    "        w = F.relu(w)\n",
    "        w = self.conv2d(w)\n",
    "        w = self.bn2d(w)\n",
    "        w = F.relu(w)\n",
    "                \n",
    "        xFC = torch.cat((y, z, w), 1)\n",
    "        #print('ReductionB Done')\n",
    "        \n",
    "        return xFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_v4_convnet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Inception_v4_convnet, self).__init__()\n",
    "        \n",
    "\n",
    "        # Special attributs\n",
    "        self.input_space = None\n",
    "        self.input_size = (299, 299, 3)\n",
    "        self.num_classes = 1000;\n",
    "\n",
    "        # Modules\n",
    "        self.features = nn.Sequential(\n",
    "            Stem(),\n",
    "            InceptionA(),\n",
    "            InceptionA(),\n",
    "            InceptionA(),\n",
    "            InceptionA(),\n",
    "            ReductionA(), \n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            InceptionB(),\n",
    "            ReductionB(), \n",
    "            InceptionC(),\n",
    "            InceptionC(),\n",
    "            InceptionC()\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.AvgPool2d(8, padding=1 )\n",
    "        self.linear = nn.Linear(1536, 10)\n",
    "        self.dropout = nn.Dropout(0.2) \n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.features(input)\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception_v4_convnet(\n",
      "  (features): Sequential(\n",
      "    (0): Stem(\n",
      "      (resize): UpsamplingBilinear2d(size=(299, 299), mode=bilinear)\n",
      "      (conv1a): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn1a): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn1b): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1c): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1c): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (conv2a): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn2a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn3b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(64, 64, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4b): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(64, 64, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4c): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (bn4d): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv5a): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn5a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): InceptionA(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn3b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4c): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): InceptionA(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn3b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4c): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): InceptionA(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn3b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4c): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): InceptionA(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn3b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4b): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn4c): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): ReductionA(\n",
      "      (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (conv1a): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn1a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2b): Conv2d(192, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2c): Conv2d(224, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn2c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(224, 256, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(224, 224, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(224, 256, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(224, 256, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(224, 224, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(224, 256, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(224, 256, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(224, 224, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(224, 256, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(224, 256, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(224, 224, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(224, 256, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (10): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(224, 256, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(224, 224, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(224, 256, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(224, 256, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(224, 224, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(224, 256, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): InceptionB(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn3b): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(224, 256, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(192, 192, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4b): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(192, 224, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4c): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(224, 224, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn4d): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(224, 256, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (13): ReductionB(\n",
      "      (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (conv1a): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1b): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn1b): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2b): Conv2d(256, 256, kernel_size=[1, 7], stride=(1, 1), padding=[0, 3])\n",
      "      (bn2b): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2c): Conv2d(256, 320, kernel_size=[7, 1], stride=(1, 1), padding=[3, 0])\n",
      "      (bn2c): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (bn2d): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (14): InceptionC(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(384, 256, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn3b): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(384, 256, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(384, 448, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4b): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(448, 512, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4c): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(512, 256, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4d): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(512, 256, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (15): InceptionC(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(384, 256, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn3b): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(384, 256, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(384, 448, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4b): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(448, 512, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4c): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(512, 256, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4d): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(512, 256, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (16): InceptionC(\n",
      "      (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "      (conv1a): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1a): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2a): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn2a): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3a): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3b): Conv2d(384, 256, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn3b): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3c): Conv2d(384, 256, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn3c): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4a): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn4a): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4b): Conv2d(384, 448, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4b): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4c): Conv2d(448, 512, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4c): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4d): Conv2d(512, 256, kernel_size=[3, 1], stride=(1, 1), padding=[1, 0])\n",
      "      (bn4d): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4e): Conv2d(512, 256, kernel_size=[1, 3], stride=(1, 1), padding=[0, 1])\n",
      "      (bn4e): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=8, stride=8, padding=1)\n",
      "  (linear): Linear(in_features=1536, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2)\n",
      ")\n",
      "There are 41189194 (41.19 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "net=Inception_v4_convnet()\n",
    "\n",
    "print(net)\n",
    "utils.display_num_param(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "my_lr=0.003 \n",
    "bs= 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test_set():\n",
    "\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "\n",
    "    for i in range(0,10000,bs):\n",
    "\n",
    "        minibatch_data =  test_data[i:i+bs].unsqueeze(dim=1)\n",
    "        minibatch_label= test_label[i:i+bs]\n",
    "\n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        #inputs = (minibatch_data - mean)/std    # ONLY CHANGE IS HERE!\n",
    "        \n",
    "        inputs = minibatch_data\n",
    "\n",
    "        scores=net( inputs ) \n",
    "\n",
    "        error = utils.get_error( scores , minibatch_label)\n",
    "\n",
    "        running_error += error.item()\n",
    "\n",
    "        num_batches+=1\n",
    "\n",
    "\n",
    "    total_error = running_error/num_batches\n",
    "    print( 'error rate on test set =', total_error*100 ,'percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titan/miniconda3/envs/deeplearn_project/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:225: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/titan/miniconda3/envs/deeplearn_project/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 \t time= 11.980700365702312 min \t lr= 0.003 \t loss= 0.5329631077546626 \t error= 15.273999600410463 percent\n",
      "error rate on test set = 2.1699999570846558 percent\n",
      " \n",
      "epoch= 2 \t time= 24.648890431722005 min \t lr= 0.003 \t loss= 0.08180404005609453 \t error= 1.9460000872611998 percent\n",
      "error rate on test set = 1.1100001454353332 percent\n",
      " \n",
      "epoch= 3 \t time= 37.331858491897584 min \t lr= 0.003 \t loss= 0.05053329619988799 \t error= 1.2580001401901246 percent\n",
      "error rate on test set = 1.1600001096725463 percent\n",
      " \n",
      "epoch= 4 \t time= 50.01632684469223 min \t lr= 0.003 \t loss= 0.03588006609184667 \t error= 0.904000117778778 percent\n",
      "error rate on test set = 0.8500000834465027 percent\n",
      " \n",
      "epoch= 5 \t time= 62.69706526994705 min \t lr= 0.002 \t loss= 0.022574297449039295 \t error= 0.5460000729560852 percent\n",
      "error rate on test set = 0.7700001001358032 percent\n",
      " \n",
      "epoch= 6 \t time= 75.37308830420176 min \t lr= 0.002 \t loss= 0.014706946297129616 \t error= 0.3200000596046448 percent\n",
      "error rate on test set = 0.6300001025199891 percent\n",
      " \n",
      "epoch= 7 \t time= 88.05149175723393 min \t lr= 0.002 \t loss= 0.011790722856181674 \t error= 0.22600004434585572 percent\n",
      "error rate on test set = 0.6000001072883606 percent\n",
      " \n",
      "epoch= 8 \t time= 100.73117206494014 min \t lr= 0.002 \t loss= 0.011774463844718412 \t error= 0.27600005865097044 percent\n",
      "error rate on test set = 0.6100001096725464 percent\n",
      " \n",
      "epoch= 9 \t time= 113.40777553319931 min \t lr= 0.002 \t loss= 0.00788815216224175 \t error= 0.1640000343322754 percent\n",
      "error rate on test set = 0.5600000858306885 percent\n",
      " \n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "for epoch in range(1,10):\n",
    "    \n",
    "    if not epoch%5:\n",
    "        my_lr = my_lr / 1.5\n",
    "        \n",
    "    optimizer=torch.optim.SGD( net.parameters() , lr=my_lr )\n",
    "        \n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    \n",
    "    shuffled_indices=torch.randperm(50000)\n",
    " \n",
    "    for count in range(0,50000,bs):\n",
    "        \n",
    "        # FORWARD AND BACKWARD PASS\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "             \n",
    "        indices=shuffled_indices[count:count+bs]\n",
    "        minibatch_data =  train_data[indices].unsqueeze(dim=1)\n",
    "        minibatch_label=  train_label[indices]\n",
    "        \n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        #inputs = (minibatch_data - mean)/std      # ONLY CHANGE IS HERE!\n",
    "        \n",
    "        inputs = minibatch_data\n",
    "        \n",
    "        inputs.requires_grad_()\n",
    "\n",
    "        scores=net( inputs ) \n",
    "\n",
    "        loss =  criterion( scores , minibatch_label) \n",
    "          \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # COMPUTE STATS\n",
    "        \n",
    "        running_loss += loss.detach().item()\n",
    "        \n",
    "        error = utils.get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "        \n",
    "        num_batches+=1        \n",
    "    \n",
    "    \n",
    "    # AVERAGE STATS THEN DISPLAY\n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    elapsed = (time.time()-start)/60\n",
    "    \n",
    "    print('epoch=',epoch, '\\t time=', elapsed,'min', '\\t lr=', my_lr  ,'\\t loss=', total_loss , '\\t error=', total_error*100 ,'percent')\n",
    "    eval_on_test_set() \n",
    "    print(' ')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# choose a picture at random\n",
    "idx=randint(0, 10000-1)\n",
    "im=test_data[idx]\n",
    "\n",
    "# diplay the picture\n",
    "utils.show(im)\n",
    "\n",
    "# send to device, rescale, and view as a batch of 1 \n",
    "im = im.to(device)\n",
    "im=im.view(1,28,28).unsqueeze(dim=1)\n",
    "\n",
    "# feed it to the net and display the confidence scores\n",
    "scores =  net(im) \n",
    "probs= F.softmax(scores, dim=1)\n",
    "utils.show_prob_mnist(probs.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "\n",
    "from random import randint\n",
    "import utils as ut \n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import flags\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "#from util import get_normalized_data\n",
    "\n",
    "from cleverhans.attacks import *\n",
    "from cleverhans.model import CallableModelWrapper\n",
    "from cleverhans.utils import AccuracyReport\n",
    "from cleverhans.utils_pytorch import convert_pytorch_model_to_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device= torch.device(\"cuda\")\n",
    "#device= torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import check_mnist_dataset_exists\n",
    "data_path=check_mnist_dataset_exists()\n",
    "\n",
    "train_data=torch.load(data_path+'mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'mnist/train_label.pt')\n",
    "test_data=torch.load(data_path+'mnist/test_data.pt')\n",
    "test_label=torch.load(data_path+'mnist/test_label.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class two_layer_net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size,  output_size):\n",
    "        super(two_layer_net , self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(  input_size   , hidden_size  , bias=False  )\n",
    "        self.layer2 = nn.Linear(  hidden_size  , output_size   , bias=False  )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y       = self.layer1(x)\n",
    "        y_hat   = F.relu(y)\n",
    "        scores  = self.layer2(y_hat)\n",
    "        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_layer_net(\n",
      "  (layer1): Linear(in_features=784, out_features=50, bias=False)\n",
      "  (layer2): Linear(in_features=50, out_features=10, bias=False)\n",
      ")\n",
      "There are 39700 (0.04 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "net_basic=two_layer_net(784,50,10)\n",
    "\n",
    "print(net_basic)\n",
    "ut.display_num_param(net_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer=torch.optim.Adam( net_basic.parameters() , lr=0.01 )\n",
    "\n",
    "bs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "net_basic = net_basic.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test_set():\n",
    "\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "\n",
    "    for i in range(0,10000,bs):\n",
    "\n",
    "        minibatch_data =  test_data[i:i+bs].to(device)\n",
    "        minibatch_label= test_label[i:i+bs].to(device)\n",
    "\n",
    "        inputs = minibatch_data.view(bs,784)\n",
    "\n",
    "        scores=net_basic( inputs ) \n",
    "\n",
    "        error = ut.get_error( scores , minibatch_label)\n",
    "\n",
    "        running_error += error.item()\n",
    "\n",
    "        num_batches+=1\n",
    "\n",
    "\n",
    "    total_error = running_error/num_batches\n",
    "    print( 'test error  = ', total_error*100 ,'percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "epoch= 0 \t time= 2.5193660259246826 \t loss= 0.2690667844738734 \t error= 7.801665874322255 percent\n",
      "test error  =  5.349999535083771 percent\n",
      " \n",
      "epoch= 5 \t time= 14.930984020233154 \t loss= 0.14796791654793331 \t error= 3.69999988079071 percent\n",
      "test error  =  4.219999670982361 percent\n",
      " \n",
      "epoch= 10 \t time= 27.570799589157104 \t loss= 0.13248734433974454 \t error= 3.0833333293596903 percent\n",
      "test error  =  4.5899995803833 percent\n",
      " \n",
      "epoch= 15 \t time= 40.74290418624878 \t loss= 0.11790682019833534 \t error= 2.646666677792867 percent\n",
      "test error  =  4.699999654293061 percent\n",
      " \n",
      "epoch= 20 \t time= 53.69309449195862 \t loss= 0.11010947166443791 \t error= 2.3983334402243295 percent\n",
      "test error  =  4.10999972820282 percent\n",
      " \n",
      "epoch= 25 \t time= 66.93319535255432 \t loss= 0.111818331362951 \t error= 2.1600001414616905 percent\n",
      "test error  =  4.149999690055847 percent\n",
      " \n",
      "epoch= 30 \t time= 79.75866222381592 \t loss= 0.09584278892549558 \t error= 2.0266667644182843 percent\n",
      "test error  =  4.419999599456787 percent\n",
      " \n",
      "epoch= 35 \t time= 93.23070883750916 \t loss= 0.10400131850894673 \t error= 1.9516667763392133 percent\n",
      "test error  =  4.1299996972084045 percent\n",
      " \n",
      "epoch= 40 \t time= 106.46083521842957 \t loss= 0.10100525566913315 \t error= 1.8400001247723896 percent\n",
      "test error  =  3.859999763965607 percent\n",
      " \n",
      "epoch= 45 \t time= 120.26413631439209 \t loss= 0.09895451395923087 \t error= 1.7550001204013825 percent\n",
      "test error  =  3.9899996399879454 percent\n",
      " \n",
      "epoch= 50 \t time= 135.77876019477844 \t loss= 0.09488374644535916 \t error= 1.6600001573562622 percent\n",
      "test error  =  4.009999668598175 percent\n",
      " \n",
      "epoch= 55 \t time= 151.89670419692993 \t loss= 0.08394266668483921 \t error= 1.4966668009757995 percent\n",
      "test error  =  3.9299997210502626 percent\n",
      " \n",
      "epoch= 60 \t time= 167.84635138511658 \t loss= 0.08206385021606026 \t error= 1.4600001315275828 percent\n",
      "test error  =  4.719999647140503 percent\n",
      " \n",
      "epoch= 65 \t time= 181.5053300857544 \t loss= 0.09435286635050621 \t error= 1.4366667886575062 percent\n",
      "test error  =  4.479999554157257 percent\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(70):\n",
    "    \n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    \n",
    "    shuffled_indices=torch.randperm(60000)\n",
    " \n",
    "    for count in range(0,60000,bs):\n",
    "        \n",
    "        # forward and backward pass\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        indices=shuffled_indices[count:count+bs]\n",
    "        minibatch_data =  train_data[indices].to(device)\n",
    "        minibatch_label= train_label[indices].to(device)\n",
    "\n",
    "        inputs = minibatch_data.view(bs,784)\n",
    "\n",
    "        inputs.requires_grad_()\n",
    "\n",
    "        scores=net_basic( inputs ) \n",
    "\n",
    "        loss =  criterion( scores , minibatch_label) \n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        # compute some stats\n",
    "        \n",
    "        running_loss += loss.detach().item()\n",
    "               \n",
    "        error = ut.get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "        \n",
    "        num_batches+=1\n",
    "    \n",
    "    \n",
    "    # once the epoch is finished we divide the \"running quantities\"\n",
    "    # by the number of batches\n",
    "    \n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    elapsed_time = time.time() - start\n",
    "    \n",
    "    # every 10 epoch we display the stats \n",
    "    # and compute the error rate on the test set  \n",
    "    \n",
    "    if epoch % 5 == 0 : \n",
    "    \n",
    "        print(' ')\n",
    "        \n",
    "        print('epoch=',epoch, '\\t time=', elapsed_time,\n",
    "              '\\t loss=', total_loss , '\\t error=', total_error*100 ,'percent')\n",
    "        \n",
    "        eval_on_test_set()\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_data.view(60000,784), train_label))\n",
    "     \n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_data.view(10000,784), test_label))\n",
    "\n",
    "sess = tf.Session()\n",
    "x_op1 = tf.placeholder(tf.float32, shape=(None,784,))\n",
    "#x_op2 = tf.placeholder(tf.float32, shape=(None,3, 32, 32,))\n",
    "\n",
    "\n",
    "# Convert pytorch model to a tf_model and wrap it in cleverhans\n",
    "tf_net = convert_pytorch_model_to_tf(net_basic)\n",
    "cleverhans_model = CallableModelWrapper(tf_net, output_layer='logits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/titan/miniconda3/envs/deeplearn_project/lib/python3.6/site-packages/cleverhans/attacks.py:216: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/titan/miniconda3/envs/deeplearn_project/lib/python3.6/site-packages/cleverhans/attacks_tf.py:62: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/titan/miniconda3/envs/deeplearn_project/lib/python3.6/site-packages/cleverhans/utils_tf.py:37: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an FGSM attack\n",
    "fgsm_op = FastGradientMethod(cleverhans_model, sess=sess)\n",
    "fgsm_params = {'eps': 0.3,\n",
    "                 'clip_min': 0.,\n",
    "                 'clip_max': 1.}\n",
    "adv_x_op = fgsm_op.generate(x_op1, **fgsm_params)\n",
    "adv_preds_op = tf_net(adv_x_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_runs = 10000\n",
    "correct = 0\n",
    "\n",
    "dist_mnist_list = []\n",
    "for xs, ys in test_loader:\n",
    "    xs, ys = Variable(xs), Variable(ys)\n",
    "    adv_example = sess.run(adv_x_op, feed_dict={x_op1: xs})\n",
    "    adv_preds = sess.run(adv_preds_op, feed_dict={adv_x_op: adv_example})\n",
    "    dist_mnist_list.append( max(np.reshape(np.array(adv_example-xs), 784)))\n",
    "    correct += (np.argmax(adv_preds, axis=1) == ys).sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial accuracy with FGSM attack for MNIST: 63.090\n"
     ]
    }
   ],
   "source": [
    "dist_mnist = np.array(dist_mnist_list)  \n",
    "acc = float(correct) / no_runs\n",
    "\n",
    "print('Adversarial accuracy with FGSM attack for MNIST: {:.3f}'.format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3969.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        6031.]),\n",
       " array([0.        , 0.03      , 0.06000001, 0.09000001, 0.12000002,\n",
       "        0.15000002, 0.18000002, 0.21000002, 0.24000004, 0.27000004,\n",
       "        0.30000004], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pyplot.hist(dist_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/titan/miniconda3/envs/deeplearn_project/lib/python3.6/site-packages/cleverhans/attacks.py:549: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Adversarial accuracy with MomentumIterative method attack on MNIST: 60.480\n"
     ]
    }
   ],
   "source": [
    "mi_op = MomentumIterativeMethod(cleverhans_model, sess=sess)\n",
    "\n",
    "mi_params = { 'eps' : 0.3, 'eps_iter' : 0.06, 'nb_iter' : 10} #'y': None, 'ord' : inf, 'decay_factor' : 1.0, 'clip_min' : None, 'clip_max' : None, 'y_target' : None}\n",
    "\n",
    "adv_x_op = mi_op.generate(x_op1, **mi_params)\n",
    "adv_preds_op = tf_net(adv_x_op)\n",
    "\n",
    "no_runs = 10000\n",
    "correct = 0\n",
    "for xs, ys in test_loader:\n",
    "    xs, ys = Variable(xs), Variable(ys)\n",
    "    adv_example = sess.run(adv_x_op, feed_dict={x_op1: xs})\n",
    "    adv_preds = sess.run(adv_preds_op, feed_dict={adv_x_op: adv_example})\n",
    "    correct += (np.argmax(adv_preds, axis=1) == ys).sum()\n",
    "\n",
    "acc = float(correct) / no_runs\n",
    "\n",
    "print('Adversarial accuracy with MomentumIterative method attack on MNIST: {:.3f}'.format(acc * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
